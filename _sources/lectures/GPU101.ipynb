{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44acb20d-4df9-444e-83d3-047742275dfb",
   "metadata": {},
   "source": [
    "# Super Computer Usage 101\n",
    "\n",
    "## Accessing Resource:\n",
    "Go to the Illinois [ICRN webpage](https://docs.ncsa.illinois.edu/systems/icrn/)\n",
    "\n",
    "To use GPU resources, select \"pytorch\" + \"A100 GPU 2CPU/8GB\". \n",
    "\n",
    "\n",
    "\n",
    "## Create an environment:\n",
    "\n",
    "The point of a virtual environment is to isolate project dependencies so that different projects can use different package versions without conflict. This creates a \"sandbox\" for each project, containing its own specific Python interpreter and installed libraries, which makes development more organized and reproducible. \n",
    "\n",
    "1. First, shut down all kernels. \n",
    "2. Run the command below in a terminal: \n",
    "- ~: Your home directory, equivalent to /home/NET_ID\n",
    "- --prefix: Telling mamba where to install your environment.\n",
    "```\n",
    "mamba create --prefix ~/myenv python tensorflow[and-cuda]=2.17 ipykernel pytorch pandas seaborn tqdm matplotlib pytorch-cuda -c pytorch -c nvidia -c conda-forge\n",
    "```\n",
    "\n",
    "This will take some time. We won't use it today, but if you need to use tensorflow in the future, this is how you do on ICRN.\n",
    "\n",
    "2. Activate your environment\n",
    "```\n",
    "source activate ~/env_name\n",
    "```\n",
    "3. Run a new kernel session\n",
    "```\n",
    "python -m ipykernel install --user --name=session \n",
    "```\n",
    "Click \"+\" and you will see your session has been added. You may also open the Kernel menu and select Change kernel. You can also learn more about Mamba [here](https://mamba.readthedocs.io/en/latest/index.html)!\n",
    "\n",
    "### Common bash commands\n",
    "- pwd -P show current absolute path\n",
    "- cat print out everything in the file\n",
    "- ls (folder name) show everything in the current folder.\n",
    "- nvidia-smi show the current GPU status.\n",
    "- rm remove a file\n",
    "- source let bash run the script.\n",
    "- cp [dir1] [dir2] copy files from 1 directory to another directory. If copying a folder, use cp -r\n",
    "- In jupyter-lab, you can use these batch commands by putting a \"!\" \n",
    "\n",
    "\n",
    "## What and Why GPU?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba770ec4-cbaa-4bf8-b174-de61e9a77373",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import torch.profiler\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Helper functions\n",
    "def format_time(time_us):\n",
    "    \"\"\"Converts microseconds to a formatted ms or us string\"\"\"\n",
    "    if time_us == 0:\n",
    "        return \"0.000us\"\n",
    "    if time_us > 1000 or time_us < -1000:\n",
    "        return f\"{time_us / 1000:.3f}ms\"\n",
    "    return f\"{time_us:.3f}us\"\n",
    "    \n",
    "def to_pd(prof):\n",
    "    key_averages = prof.key_averages()\n",
    "    total_self_cpu = prof.key_averages().self_cpu_time_total\n",
    "    total_self_cuda = prof.key_averages().total_average().__dict__[\"self_device_time_total\"]\n",
    "    profiler_data = []\n",
    "    for avg in key_averages:\n",
    "        profiler_data.append({\n",
    "            \"Name\": avg.key,\n",
    "            \n",
    "            # CPU Columns\n",
    "            \n",
    "            #\"Self CPU %\": f\"{avg.self_cpu_time_total / total_self_cpu * 100:.2f}%\" if total_self_cpu > 0 else \"0.00%\",\n",
    "            \"Self CPU\": format_time(avg.self_cpu_time_total),\n",
    "            \"CPU total %\": f\"{avg.cpu_time_total / total_self_cpu * 100:.2f}%\" if total_self_cpu > 0 else \"0.00%\", # Follows profiler's table logic\n",
    "            \"CPU total\": format_time(avg.cpu_time_total),\n",
    "            \"CPU time avg\": format_time(avg.cpu_time_total / avg.count),\n",
    "            \n",
    "            # CUDA Columns\n",
    "            #\"Self CUDA %\": f\"{avg.self_device_time_total / total_self_cuda * 100:.2f}%\" if total_self_cuda > 0 else \"0.00%\",\n",
    "            \"Self CUDA\": format_time(avg.self_device_time_total),\n",
    "            \"CUDA total\": format_time(avg.device_time_total),\n",
    "            \"CUDA time avg\": format_time(avg.device_time_total / avg.count),\n",
    "            \n",
    "            \"# of Calls\": avg.count,\n",
    "            #\"_cuda_total_raw\": avg.device_time_total # Internal column just for sorting\n",
    "        })\n",
    "    print(f\"total cpu time:{format_time(total_self_cpu)}\")\n",
    "    print(f\"total gpu time:{format_time(total_self_cuda)}\")\n",
    "    return pd.DataFrame(profiler_data).sort_values(by=\"Self CUDA\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7761eca-296a-420b-8182-94be17e63d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU MatMul Time: 2.311736 seconds\n",
      "GPU MatMul Time: 0.014381 seconds\n",
      "GPU is 160.75x faster for MatMul\n"
     ]
    }
   ],
   "source": [
    "# Create two large random tensors\n",
    "a = torch.randn(5000, 5000)\n",
    "b = torch.randn(5000, 5000)\n",
    "\n",
    "# --- 1. CPU MatMul Test ---\n",
    "start_time = time.time()\n",
    "c_cpu = torch.matmul(a, b)\n",
    "cpu_time = time.time() - start_time\n",
    "print(f\"CPU MatMul Time: {cpu_time:.6f} seconds\")\n",
    "\n",
    "# --- 2. GPU MatMul Test ---\n",
    "a_gpu = a.to(\"cuda\")\n",
    "b_gpu = b.to(\"cuda\")\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "start_time = time.time()\n",
    "c_gpu = torch.matmul(a_gpu, b_gpu)\n",
    "torch.cuda.synchronize()\n",
    "gpu_time = time.time() - start_time\n",
    "\n",
    "print(f\"GPU MatMul Time: {gpu_time:.6f} seconds\")\n",
    "print(f\"GPU is {cpu_time/gpu_time:.2f}x faster for MatMul\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f39392d-57a1-4b78-ba61-5c5659f0172f",
   "metadata": {},
   "source": [
    "The GPU is faster because it has thousands of simple cores (for throughput), while the CPU has a few complex cores (for latency).\n",
    "- Jupyter Notebook Tip: You can also use %%timeit to time a cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cbb92075-b11e-4736-9b34-eec646989139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702 µs ± 26.7 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "a = np.arange(10**6) \n",
    "np.sum(a**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6522cf6-4658-44c9-b8fe-5c0d0b1efa19",
   "metadata": {},
   "source": [
    "Let's get more information from GPUs...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4dbca127-f1de-417e-a22f-692ebc0bd20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Internal Specs for NVIDIA A100-SXM4-80GB ---\n",
      "Streaming Multiprocessors (SMs): 108\n",
      "Max threads per Multiprocessors (SMs): 2048\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    props = torch.cuda.get_device_properties(0)\n",
    "    \n",
    "    print(f\"\\n--- Internal Specs for {props.name} ---\")\n",
    "    \n",
    "    # This is the \"factory count,\" the most important number for tuning.\n",
    "    print(f\"Streaming Multiprocessors (SMs): {props.multi_processor_count}\")\n",
    "\n",
    "    print(f\"Max threads per Multiprocessors (SMs): {props.max_threads_per_multi_processor}\")\n",
    "\n",
    "else:\n",
    "    print(\"CUDA device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "530789e1-a81f-45c3-b577-a8396c2416bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 26 01:12:34 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:00:05.0 Off |                    0 |\n",
      "| N/A   28C    P0             86W /  500W |    5401MiB /  81920MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            4034      C   /opt/conda/bin/python                  3744MiB |\n",
      "|    0   N/A  N/A            4255      C   /opt/conda/bin/python                  1638MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dfdfdb-96dc-4ddb-8f24-547cae46acb0",
   "metadata": {},
   "source": [
    "Your goal is to make volatile GPU-Util as busy as possible and don't fill up the memory usage. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edb4f9e-ae9d-414a-82f8-c3c9d0bf7c7d",
   "metadata": {},
   "source": [
    "## The Real Enemy: PCIe bus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "29db84f3-7a18-450d-8849-9ccc218d72ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total cpu time:891.633ms\n",
      "total gpu time:1753.928ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Self CPU</th>\n",
       "      <th>CPU total %</th>\n",
       "      <th>CPU total</th>\n",
       "      <th>CPU time avg</th>\n",
       "      <th>Self CUDA</th>\n",
       "      <th>CUDA total</th>\n",
       "      <th>CUDA time avg</th>\n",
       "      <th># of Calls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aten::copy_</td>\n",
       "      <td>379.340us</td>\n",
       "      <td>99.80%</td>\n",
       "      <td>889.817ms</td>\n",
       "      <td>44.491ms</td>\n",
       "      <td>875.846ms</td>\n",
       "      <td>875.846ms</td>\n",
       "      <td>43.792ms</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Memcpy DtoH (Device -&gt; Pageable)</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>730.451ms</td>\n",
       "      <td>730.451ms</td>\n",
       "      <td>73.045ms</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Memcpy HtoD (Pageable -&gt; Device)</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>145.395ms</td>\n",
       "      <td>145.395ms</td>\n",
       "      <td>14.540ms</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aten::add_</td>\n",
       "      <td>230.053us</td>\n",
       "      <td>0.06%</td>\n",
       "      <td>530.498us</td>\n",
       "      <td>53.050us</td>\n",
       "      <td>1.118ms</td>\n",
       "      <td>1.118ms</td>\n",
       "      <td>111.795us</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>void at::native::vectorized_elementwise_kernel...</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>1.118ms</td>\n",
       "      <td>1.118ms</td>\n",
       "      <td>111.795us</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aten::to</td>\n",
       "      <td>576.055us</td>\n",
       "      <td>99.94%</td>\n",
       "      <td>891.090ms</td>\n",
       "      <td>44.554ms</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>875.846ms</td>\n",
       "      <td>43.792ms</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aten::_to_copy</td>\n",
       "      <td>240.812us</td>\n",
       "      <td>99.87%</td>\n",
       "      <td>890.514ms</td>\n",
       "      <td>44.526ms</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>875.846ms</td>\n",
       "      <td>43.792ms</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aten::empty_strided</td>\n",
       "      <td>456.411us</td>\n",
       "      <td>0.05%</td>\n",
       "      <td>456.411us</td>\n",
       "      <td>22.821us</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cudaMemcpyAsync</td>\n",
       "      <td>889.105ms</td>\n",
       "      <td>99.72%</td>\n",
       "      <td>889.105ms</td>\n",
       "      <td>44.455ms</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cudaStreamSynchronize</td>\n",
       "      <td>332.207us</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>332.207us</td>\n",
       "      <td>16.610us</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cudaLaunchKernel</td>\n",
       "      <td>300.445us</td>\n",
       "      <td>0.03%</td>\n",
       "      <td>300.445us</td>\n",
       "      <td>30.045us</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cudaDeviceSynchronize</td>\n",
       "      <td>12.734us</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>12.734us</td>\n",
       "      <td>12.734us</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>0.000us</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name   Self CPU CPU total %  \\\n",
       "3                                         aten::copy_  379.340us      99.80%   \n",
       "10                   Memcpy DtoH (Device -> Pageable)    0.000us       0.00%   \n",
       "5                    Memcpy HtoD (Pageable -> Device)    0.000us       0.00%   \n",
       "7                                          aten::add_  230.053us       0.06%   \n",
       "9   void at::native::vectorized_elementwise_kernel...    0.000us       0.00%   \n",
       "0                                            aten::to  576.055us      99.94%   \n",
       "1                                      aten::_to_copy  240.812us      99.87%   \n",
       "2                                 aten::empty_strided  456.411us       0.05%   \n",
       "4                                     cudaMemcpyAsync  889.105ms      99.72%   \n",
       "6                               cudaStreamSynchronize  332.207us       0.04%   \n",
       "8                                    cudaLaunchKernel  300.445us       0.03%   \n",
       "11                              cudaDeviceSynchronize   12.734us       0.00%   \n",
       "\n",
       "    CPU total CPU time avg  Self CUDA CUDA total CUDA time avg  # of Calls  \n",
       "3   889.817ms     44.491ms  875.846ms  875.846ms      43.792ms          20  \n",
       "10    0.000us      0.000us  730.451ms  730.451ms      73.045ms          10  \n",
       "5     0.000us      0.000us  145.395ms  145.395ms      14.540ms          10  \n",
       "7   530.498us     53.050us    1.118ms    1.118ms     111.795us          10  \n",
       "9     0.000us      0.000us    1.118ms    1.118ms     111.795us          10  \n",
       "0   891.090ms     44.554ms    0.000us  875.846ms      43.792ms          20  \n",
       "1   890.514ms     44.526ms    0.000us  875.846ms      43.792ms          20  \n",
       "2   456.411us     22.821us    0.000us    0.000us       0.000us          20  \n",
       "4   889.105ms     44.455ms    0.000us    0.000us       0.000us          20  \n",
       "6   332.207us     16.610us    0.000us    0.000us       0.000us          20  \n",
       "8   300.445us     30.045us    0.000us    0.000us       0.000us          10  \n",
       "11   12.734us     12.734us    0.000us    0.000us       0.000us           1  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor on the CPU\n",
    "z_cpu = torch.randn(5000, 5000)\n",
    "acts=[torch.profiler.ProfilerActivity.CPU,torch.profiler.ProfilerActivity.CUDA]\n",
    "with torch.profiler.profile(\n",
    "    activities=acts\n",
    ") as prof:\n",
    "    # This loop does NO compute, just data transfer\n",
    "    for _ in range(10):\n",
    "        z_gpu = z_cpu.to(\"cuda\")\n",
    "        z_gpu+=z_gpu\n",
    "        z_back = z_gpu.to(\"cpu\")\n",
    "to_pd(prof)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e054c73d-b78d-4862-8d75-990daa6ef3e8",
   "metadata": {},
   "source": [
    "All the gpu time is spent in memory operations(copy or Memcpy). This is the data moving across the PCIe bus from RAM to VRAM. Your kernel can be infinitely fast, but you'll still be slow if you're bottlenecked by data transfer.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6840946-26b2-4f80-9080-9cb2f540ca08",
   "metadata": {},
   "source": [
    "## Kernel Launch Overhead: Vectorization (batching).\n",
    "\n",
    "A for loop in Python is not parallel. Writing \n",
    "```\n",
    "for i in range(1000):\n",
    "```\n",
    "to process your data is wrong. The correct way is to feed the GPU one big batch and let it use its 108 SMs.\n",
    "This is because it is expensive to create a stream and launch new kernels on a gpu... \n",
    "we want to minimize and have our data in a big matrix, rather than doing the same operations thousands of times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a29d853c-89ad-48c5-898c-6311f8339d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for 100,000 small launches: 0.583946s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# --- BAD: 100,000 tiny kernels ---\n",
    "a = torch.randn(1, device='cuda')\n",
    "b = torch.randn(1, device='cuda')\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "start = time.time()\n",
    "\n",
    "for _ in range(100000):\n",
    "    c = a + b  # A new kernel launch every loop!\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "print(f\"Time for 100,000 small launches: {time.time() - start:.6f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4772840a-da63-42e8-8f95-79b70bc7b45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for 1 big launch: 0.000157s\n"
     ]
    }
   ],
   "source": [
    "# --- GOOD: One big, vectorized kernel ---\n",
    "a = torch.randn(100000, device='cuda')\n",
    "b = torch.randn(100000, device='cuda')\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "start = time.time()\n",
    "\n",
    "c = a + b  # One single kernel launch\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "print(f\"Time for 1 big launch: {time.time() - start:.6f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efa0590-ebda-4b46-8aa2-4224c44107ed",
   "metadata": {},
   "source": [
    "The vectorized (one-launch) version will be dramatically faster, even though it's doing the same amount of math."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86943d5b-d892-4c77-9a08-dc1190b232ab",
   "metadata": {},
   "source": [
    "## Data Loading (The \"Starving\" GPU)?\n",
    "You've proven the GPU is fast and the PCIe bus is slow. But what about getting data from your disk to your CPU RAM in the first place?\n",
    "Your GPU is **starving**. It's spending all its time waiting for the CPU to load data (like JPEGs or CSVs) from the disk and prepare the next batch. Your 108 SMs (factories) are idle because the \"delivery trucks\" (the CPU) are stuck in traffic.\n",
    "\n",
    "### The \"Fix\": `DataLoader` Knobs\n",
    "When you use `torch.utils.data.DataLoader`, you have two magic knobs:\n",
    "\n",
    "1.  **`num_workers=...`**: This is the *most important* knob. Setting `num_workers=8` (or `16`, `32`) launches 8 parallel CPU processes. While your GPU is busy on `batch 1`, these 8 workers are *already loading and preprocessing* `batch 2`, `3`, `4`, etc. This **hides** the data-loading latency. In ICRN, you only have 2 CPUs, so don't make this number above 2. \n",
    "2.  **`pin_memory=True`**: This is a direct hardware optimization. It tells PyTorch to put the CPU-side data in a special \"page-locked\" (or \"pinned\") memory region. This makes the `HtoD` (Host-to-Device) copy over the PCIe bus **significantly faster**.\n",
    "\n",
    "### What is pinned memory?\n",
    "- Standard memory: By default, host (CPU) memory is \"pageable,\" meaning the operating system can move it to disk to free up physical RAM for other applications. \n",
    "- Pinned memory: When memory is allocated as \"pinned,\" the OS is instructed to lock it in place within physical RAM, creating a stable, predictable memory region. \n",
    "- GPU access: Because the memory is stable and its physical address is guaranteed to be constant, the GPU can use DMA to transfer data directly to and from it without CPU involvement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32648e0d-7040-4122-a03d-a0aff2cffaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading CIFAR-10 dataset...\n",
      "Dataset ready.\n",
      "\n",
      "Testing Bad Loader (num_workers=0)...\n",
      "  Time for Bad Loader: 3.596519s\n",
      "\n",
      "Testing Good Loader (pin_memory=True)...\n",
      "  Time for Good Loader: 3.586690s\n",
      "\n",
      "Speedup: 1.00x\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# --- 1. Load (CIFAR-10) ---\n",
    "# This will force the loader to read real files from disk.\n",
    "print(\"Downloading CIFAR-10 dataset...\")\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "# We'll use the training set for our test\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', \n",
    "    train=True,\n",
    "    download=True, \n",
    "    transform=transform\n",
    ")\n",
    "print(\"Dataset ready.\")\n",
    "\n",
    "# --- 2. Define a simple model to create a GPU workload ---\n",
    "# This simulates the \"compute\" part of a training loop.\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # A few simple layers to keep the GPU busy\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32*32*3, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# --- 3. The \"Bad\" Way (num_workers=0) ---\n",
    "bad_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=256,\n",
    "    num_workers=2,      # Main CPU thread does all the disk I/O\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "# --- 4. The \"Good\" Way (num_workers=8) ---\n",
    "good_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=256,\n",
    "    num_workers=2,      # 8 parallel CPU processes fetching data\n",
    "    pin_memory=True     # Speeds up the final CPU -> GPU copy\n",
    ")\n",
    "\n",
    "# --- 5. The Training Simulation ---\n",
    "def run_epoch(loader, model):\n",
    "    \"\"\"Simulates one full epoch of training.\"\"\"\n",
    "    for inputs, labels in loader:\n",
    "        # Move data to GPU\n",
    "        inputs_gpu = inputs.to(\"cuda\")\n",
    "        labels_gpu = labels.to(\"cuda\")\n",
    "        \n",
    "        # --- Simulate Compute ---\n",
    "        # Forward pass\n",
    "        outputs = model(inputs_gpu)\n",
    "        # We'll just use the output as the \"loss\" for simplicity\n",
    "        # Backward pass\n",
    "        outputs.sum().backward()\n",
    "        # --- End Compute ---\n",
    "\n",
    "# --- Test 1: Time the Bad Loader ---\n",
    "print(\"\\nTesting Bad Loader (num_workers=0)...\")\n",
    "model = SimpleModel().to(\"cuda\") # Reset model on GPU\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "start_time = time.time()\n",
    "\n",
    "run_epoch(bad_loader, model)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "bad_time = time.time() - start_time\n",
    "print(f\"  Time for Bad Loader: {bad_time:.6f}s\")\n",
    "\n",
    "\n",
    "# --- Test 2: Time the Good Loader ---\n",
    "print(\"\\nTesting Good Loader (pin_memory=True)...\")\n",
    "model = SimpleModel().to(\"cuda\") # Reset model on GPU\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "start_time = time.time()\n",
    "\n",
    "run_epoch(good_loader, model)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "good_time = time.time() - start_time\n",
    "print(f\"  Time for Good Loader: {good_time:.6f}s\")\n",
    "\n",
    "print(f\"\\nSpeedup: {bad_time / good_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1962f56-02d6-4fc6-b636-201eb94a6dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating large dummy dataset...\n",
      "Dataset created.\n",
      "\n",
      "Testing Bad Loader (num_workers=0)...\n",
      "  Time for Bad Loader: 2.561420s\n",
      "\n",
      "Testing Good Loader (pin_memory=True)...\n",
      "  Time for Good Loader: 109.136102s\n",
      "\n",
      "Speedup: 0.02x\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch.utils.data import DataLoader, TensorDataset # <- This line is fixed\n",
    "\n",
    "# --- Create a larger dataset to make the test obvious ---\n",
    "# 500,000 samples, 1024 features\n",
    "print(\"Creating large dummy dataset...\")\n",
    "dummy_dataset = TensorDataset(torch.randn(500000, 1024), torch.randn(500000))\n",
    "print(\"Dataset created.\")\n",
    "\n",
    "# --- The \"Bad\" Way (Default) ---\n",
    "bad_loader = DataLoader(\n",
    "    dummy_dataset, \n",
    "    batch_size=256,\n",
    "    num_workers=0,      # Main CPU thread does all the disk I/O\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "# --- The \"Good\" Hardware-Aware Way ---\n",
    "good_loader = DataLoader(\n",
    "    dummy_dataset, \n",
    "    batch_size=256,\n",
    "    num_workers=0,      # Main CPU thread does all the disk I/O\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# --- Test 1: Time the Bad Loader ---\n",
    "print(\"\\nTesting Bad Loader (num_workers=0)...\")\n",
    "torch.cuda.synchronize() # Wait for GPU to be idle\n",
    "start_time = time.time()\n",
    "\n",
    "for inputs, labels in bad_loader:\n",
    "    # This loop simulates a training loop by moving data to the GPU\n",
    "    inputs_gpu = inputs.to(\"cuda\")\n",
    "    labels_gpu = labels.to(\"cuda\")\n",
    "\n",
    "torch.cuda.synchronize() # Wait for all copies to finish\n",
    "bad_time = time.time() - start_time\n",
    "print(f\"  Time for Bad Loader: {bad_time:.6f}s\")\n",
    "\n",
    "\n",
    "# --- Test 2: Time the Good Loader ---\n",
    "print(\"\\nTesting Good Loader (pin_memory=True)...\")\n",
    "torch.cuda.synchronize() # Wait for GPU to be idle\n",
    "start_time = time.time()\n",
    "\n",
    "for inputs, labels in good_loader:\n",
    "    # This loop simulates a training loop by moving data to the GPU\n",
    "    inputs_gpu = inputs.to(\"cuda\")\n",
    "    labels_gpu = labels.to(\"cuda\")\n",
    "\n",
    "torch.cuda.synchronize() # Wait for all copies to finish\n",
    "good_time = time.time() - start_time\n",
    "print(f\"  Time for Good Loader: {good_time:.6f}s\")\n",
    "\n",
    "print(f\"\\nSpeedup: {bad_time / good_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df674789-a222-4c5f-8f10-df7970454b89",
   "metadata": {},
   "source": [
    "Activity:\n",
    "Play around with different parameters (same workers/pinned memory=true/false) for these 2 processes.\n",
    "\n",
    "#### The Bottleneck: num_workers=0 + pin_memory=True\n",
    "What num_workers=0 Does: This tells the DataLoader to fetch all data in the main process. No separate processes are spawned. Your for loop cannot continue until the data loading for the current batch is 100% complete.\n",
    "\n",
    "What pin_memory=True Does: This tells the DataLoader, \"After you fetch a batch, please copy it from standard (pageable) RAM into pinned (page-locked) RAM.\"\n",
    "\n",
    "The Catch: Allocating new pinned memory is a very slow, expensive operation for the operating system.\n",
    "\n",
    "Your \"Good\" Loader's Slow Loop: For every single batch, your main thread is forced to:\n",
    "\n",
    "Fetch the batch data (from RAM, which is fast).\n",
    "\n",
    "Stall: Explicitly allocate a new block of pinned memory (very, very slow).\n",
    "\n",
    "Copy the batch data into that new pinned memory (also slow).\n",
    "\n",
    "Finally, return the batch to your loop.\n",
    "\n",
    "inputs.to(\"cuda\"): This step is now fast (a direct DMA transfer), but it doesn't matter. You already spent a massive amount of time on steps 2 and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5989614-dd23-446f-a14e-8f975998d89c",
   "metadata": {},
   "source": [
    "## The A100's \"Superpower\": Tensor Cores & Mixed Precision\n",
    "Your NVIDIA A100 has specialized hardware called **Tensor Cores**. These are like special-purpose \"mini-factories\" inside your SMs that do matrix multiplication *insanely* fast.\n",
    "\n",
    "There's one catch: they **only work on `float16` (half-precision) data**, not the default `float32`.\n",
    "\n",
    "Using `float16` gives you two massive wins:\n",
    "1.  **2-3x Speedup:** By using the fast Tensor Cores.\n",
    "2.  **50% Memory Reduction:** `float16` tensors take half the VRAM of `float32`.\n",
    "\n",
    "The problem? `float16` can be unstable for some operations (like `softmax`). The solution is **Automatic Mixed Precision (AMP)**.\n",
    "\n",
    "### The Fix: `torch.cuda.amp.autocast`\n",
    "PyTorch's `autocast` will automatically run \"safe\" operations in `float32` but switch to `float16` for \"fast\" operations (like `matmul` and `conv2d`) to use the Tensor Cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2420cd39-a4c7-4fce-aaa9-c48dc865372d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on GPU: NVIDIA A100-SXM4-80GB\n",
      "Matrix Size: 4096x4096\n",
      "Iterations: 500 (after 50 warmup runs)\n",
      "\n",
      "--- Test 1: Pure FP32 (Standard CUDA Cores) ---\n",
      "Current FP32 Precision: highest\n",
      "Average Time: 7.2240 ms\n",
      "\n",
      "--- Test 2: TF32 (Tensor Cores) ---\n",
      "Current FP32 Precision: high\n",
      "Average Time: 1.0666 ms\n",
      "\n",
      "--- Test 3: FP16 (Tensor Cores) ---\n",
      "Average Time: 0.5358 ms\n",
      "\n",
      "--- Summary ---\n",
      "Pure FP32 (CUDA Cores): 7.2240 ms\n",
      "TF32 (Tensor Cores):    1.0666 ms\n",
      "FP16 (Tensor Cores):    0.5358 ms\n",
      "-----------------\n",
      "TF32 vs Pure FP32 Speedup: 6.77x\n",
      "FP16 vs Pure FP32 Speedup: 13.48x\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# --- Configuration ---\n",
    "# Use a large matrix size to make the difference obvious\n",
    "# Tensor Cores are activated for specific dimensions (multiples of 8 or 64)\n",
    "N = 4096\n",
    "# Number of benchmark iterations\n",
    "ITERATIONS = 500\n",
    "# Warmup iterations\n",
    "WARMUP = 50\n",
    "\n",
    "def benchmark(fn, *args):\n",
    "    \"\"\"\n",
    "    A simple benchmarking function with GPU warmup and synchronization.\n",
    "    \"\"\"\n",
    "    # Warmup runs\n",
    "    for _ in range(WARMUP):\n",
    "        fn(*args)\n",
    "    \n",
    "    # Wait for all GPU operations to finish\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Main benchmark loop\n",
    "    for _ in range(ITERATIONS):\n",
    "        fn(*args)\n",
    "        \n",
    "    # Wait for all GPU operations to finish\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    # Stop timing\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Calculate average time per iteration\n",
    "    avg_time = (end_time - start_time) / ITERATIONS\n",
    "    return avg_time\n",
    "\n",
    "# --- Main Comparison ---\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"CUDA is not available. This benchmark requires an NVIDIA GPU.\")\n",
    "    exit()\n",
    "\n",
    "if torch.cuda.get_device_capability()[0] < 8:\n",
    "    print(f\"Warning: Your GPU (Compute Capability {torch.cuda.get_device_capability()})\")\n",
    "    print(\"is not an Ampere architecture (A100) or newer.\")\n",
    "    print(\"Tensor Core results (TF32) may not be as dramatic.\")\n",
    "\n",
    "print(f\"Running on GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Matrix Size: {N}x{N}\")\n",
    "print(f\"Iterations: {ITERATIONS} (after {WARMUP} warmup runs)\\n\")\n",
    "\n",
    "# --- 1. Test Pure FP32 (Standard CUDA Cores) ---\n",
    "# We force 'highest' precision to *disable* TF32 and ensure\n",
    "# we are using the standard FP32 CUDA cores.\n",
    "print(\"--- Test 1: Pure FP32 (Standard CUDA Cores) ---\")\n",
    "torch.set_float32_matmul_precision('highest')\n",
    "print(f\"Current FP32 Precision: {torch.get_float32_matmul_precision()}\")\n",
    "\n",
    "# Create standard float32 tensors\n",
    "a_fp32 = torch.randn(N, N, device='cuda', dtype=torch.float32)\n",
    "b_fp32 = torch.randn(N, N, device='cuda', dtype=torch.float32)\n",
    "\n",
    "# Benchmark the matmul operation\n",
    "fp32_time = benchmark(torch.matmul, a_fp32, b_fp32)\n",
    "print(f\"Average Time: {fp32_time * 1000:.4f} ms\\n\")\n",
    "\n",
    "\n",
    "# --- 2. Test TF32 (Tensor Cores) ---\n",
    "# We set precision to 'high' to *enable* TF32.\n",
    "# The inputs are *still* float32, but PyTorch\n",
    "# will use the Tensor Cores for the internal calculation.\n",
    "print(\"--- Test 2: TF32 (Tensor Cores) ---\")\n",
    "try:\n",
    "    torch.set_float32_matmul_precision('high')\n",
    "    print(f\"Current FP32 Precision: {torch.get_float32_matmul_precision()}\")\n",
    "\n",
    "    # We can re-use the *exact same* fp32 tensors\n",
    "    tf32_time = benchmark(torch.matmul, a_fp32, b_fp32)\n",
    "    print(f\"Average Time: {tf32_time * 1000:.4f} ms\\n\")\n",
    "\n",
    "    # --- 3. Test FP16 (Tensor Cores) ---\n",
    "    # This is the fastest path. We use float16 (half-precision) data.\n",
    "    # This fully leverages the A100's FP16 Tensor Core capabilities.\n",
    "    print(\"--- Test 3: FP16 (Tensor Cores) ---\")\n",
    "    \n",
    "    # Create float16 tensors\n",
    "    a_fp16 = a_fp32.half() # .half() is a shortcut for .to(torch.float16)\n",
    "    b_fp16 = b_fp32.half()\n",
    "    \n",
    "    # Benchmark the matmul operation\n",
    "    fp16_time = benchmark(torch.matmul, a_fp16, b_fp16)\n",
    "    print(f\"Average Time: {fp16_time * 1000:.4f} ms\\n\")\n",
    "\n",
    "\n",
    "    # --- Results ---\n",
    "    print(\"--- Summary ---\")\n",
    "    print(f\"Pure FP32 (CUDA Cores): {fp32_time * 1000:.4f} ms\")\n",
    "    print(f\"TF32 (Tensor Cores):    {tf32_time * 1000:.4f} ms\")\n",
    "    print(f\"FP16 (Tensor Cores):    {fp16_time * 1000:.4f} ms\")\n",
    "    print(\"-----------------\")\n",
    "    print(f\"TF32 vs Pure FP32 Speedup: {fp32_time / tf32_time:.2f}x\")\n",
    "    print(f\"FP16 vs Pure FP32 Speedup: {fp32_time / fp16_time:.2f}x\")\n",
    "\n",
    "except RuntimeError as e:\n",
    "    print(f\"Could not complete benchmark. Your GPU may not support a required setting.\")\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab2dcbd-405c-42b8-8343-e4969ee2c4ff",
   "metadata": {},
   "source": [
    "You should see a some speedup from that one-line change.\n",
    "\n",
    "In a real training loop (like for your ANN homework), it looks like this:\n",
    "(This is pseudo-code to show you the structure)\n",
    "\n",
    "```python\n",
    "# Import the tools\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = GradScaler()\n",
    "\n",
    "# --- In your training loop ---\n",
    "for inputs, labels in good_loader:\n",
    "    inputs, labels = inputs.to(\"cuda\"), labels.to(\"cuda\")\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # --- This is the magic ---\n",
    "    # Wrap your model and loss function in autocast\n",
    "    with autocast():\n",
    "        # Runs MatMul/Conv in float16\n",
    "        # Runs Softmax/Loss in float32\n",
    "        predictions = model(inputs)\n",
    "        loss = loss_fn(predictions, labels)\n",
    "    # --- End magic ---\n",
    "    \n",
    "    # scaler handles the loss scaling to prevent errors\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d766259a-d96d-46b5-91c6-5f2fb22207a8",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "- [ICRN docs](https://docs.ncsa.illinois.edu/systems/icrn/en/latest/index.html)\n",
    "- [Cornell GPU workshop](https://cvw.cac.cornell.edu/gpu-architecture/gpu-characteristics/index)\n",
    "- [LeetGPU-- GPU version of leetcode.](https://leetgpu.com/challenges)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
