

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Finding Structure in Data &#8212; PHYS 503</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_sources/lectures/Clustering';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Homework 02: Visualization" href="../homework/Homework_02.html" />
    <link rel="prev" title="Visualizing Data" href="Visualization.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    <span style="color:Blue">Machine Learning for Physics</span>
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction to Machine Learning and Data Science</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_01.html"><span style="color: blue;"><b>Course Introduction</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1vq4b3zxrhEMJbfeCH52hufBbXvTwhufEXdSs8mWY2ec/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="JupyterNumpy.html">Jupyter Notebooks and Numerical Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="Pandas.html">Handling Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_01.html">Homework 01: Numerical python and data handling</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../Week_02.html"><span style="color: blue;"><b>Visualizing &amp; Finding Structure in Data</b></span></a><input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1_LstEfghjdZUheyrqbjx4PK9y1J0cN-_hOdCInTldp8/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="Visualization.html">Visualizing Data</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Finding Structure in Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_02.html">Homework 02: Visualization</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_03.html"><span style="color: blue;"><b>Dimensionality, Linearity and Kernel Functions</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1x4bWQr7kEAh6Z6L7iaLdaNiY6SDTHtvHxzvjFM1wYnE/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="Dimensionality.html">Measuring and Reducing Dimensionality</a></li>
<li class="toctree-l2"><a class="reference internal" href="Nonlinear.html">Adapting Linear Methods to Non-Linear Data and Kernel Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_03.html">Homework 03: K-means and Principle Component Analysis</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Probability and Statistics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_04.html"><span style="color: blue;"><b>Probability Theory</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1qW-gCHY3bQMmB0-klM0crTD9020UG3DTlT_awlOhy2A/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="ProbabilityTheory.html">Probability Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_04.html">Homework 04: Probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01.html">Project 01: Your Selected Project</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_05.html"><span style="color: blue;"><b>Kernel Density Estimation and Statistics</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1XZoeBdXzhcfezIbUrH0a9-4-QmM-5iNksLCB7X4q1wI/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="Density.html">Estimating Probability Density from Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="Statistics.html">Statistical Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_05.html">Homework 05: Kernel Density Estimation, Covariance and Correlation</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Bayesian Inference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_06.html"><span style="color: blue;"><b>Bayesian Statistics and Markov Chain Monte Carlo</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1L_lz0WbrrUu9qDPnKxYu5S_fCXKjl01Mrs2RnHN5_6E/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="Bayes.html">Bayesian Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="MCMC.html">Markov Chain Monte Carlo in Practice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_06.html">Homework 06: Bayesian Statistics and MCMC</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_07.html"><span style="color: blue;"><b>Stochastic Processes, Markov Chains &amp; Variational Inference</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/11Mzc9rBUcnEh_D3SKeDUoCW-iwIA9ilcxsx_4yuu32A/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="Markov.html">Stochastic Processes and Markov-Chain Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="Variational.html">Variational Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_07.html">Homework 07: Markov Chains</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_08.html"><span style="color: blue;"><b>Optimization and Model Selection</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1KshmOwKTWptL-3PASHrW6WT2PkH2ltU-XwoYOflhKQk/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="Optimization.html">Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="ModelSelection.html">Bayesian Model Selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_08.html">Homework 08: Model Selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_02.html">Project 02: Your Selected Project</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Supervised Learning &amp; Cross Validation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_09.html"><span style="color: blue;"><b>Supervised Learning &amp; Cross Validation</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1a2cjkREM0LYxRjrLwrfHPTotM0n_CgVrZ_WQjEyc_Jc/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="Learning.html">Learning in a Probabalistic Context</a></li>
<li class="toctree-l2"><a class="reference internal" href="Supervised.html">Supervised Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="CrossValidation.html">Cross Validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_09.html">Homework 09: Cross Validation</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Artificial Neural Networks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_10.html"><span style="color: blue;"><b>Artificial Neural Networks</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1vyg7eSo5XaUAtYDwxmLY5qeUrwKxKqJcEEHPB40yVpE/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="NeuralNetworks.html">Artificial Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_10.html">Homework 10: Artificial Neural Networks</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_11.html"><span style="color: blue;"><b>Deep Neural Networks</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1RnFI0k15C_m2j43QtFDGCFRBCcQ-Rx6EG-9U3EumOHc/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="DeepLearning.html">Deep Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_11.html">Homework 11: Deep Neural Networks</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_12.html"><span style="color: blue;"><b>Graph Neural Networks</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1fxZdnCU_8pWocQbjMQ5HUOSUL3MgbCyg3xFWxfeNaeY/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="GraphNeuralNetworks.html">Graph Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_12.html">Homework 12: Graph Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_03.html">Project 03: Your Selected Project</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_13.html"><span style="color: blue;"><b>Unsupervised Learning</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1jGxr3j5t7Ahi3Ai6501dVJXOIzvlYMGhe9ZDqHlcfjo/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="UnsupervisedLearning.html">Unsupervised Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_13.html">Homework 13: Anomaly Detection</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Accelerated Machine Learning and Inference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_14.html"><span style="color: blue;"><b>Accelerated Machine Learning and Inference</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1-_9DcO71v6fQN1kNhKRH2d2iSjhs_Ddi2wLxiXy6RNg/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="AcceleratedML.html">Accelerated Machine Learning and Inference</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/illinois-ipaml/MachineLearningForPhysics/blob/main/_sources/lectures/Clustering.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>



<a href="https://github.com/illinois-ipaml/MachineLearningForPhysics" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/_sources/lectures/Clustering.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Finding Structure in Data</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-get-data-span"><span style="color:Orange">Get Data</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-load-data-span"><span style="color:Orange">Load Data</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-scikit-learn-span"><span style="color:Orange">SciKit Learn</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-finding-structure-in-data-span"><span style="color:Orange">Finding Structure in Data</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-distance-between-samples-span"><span style="color:Lightgreen">Distance between samples</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-whitening-transformation-span"><span style="color:Lightgreen">Whitening transformation</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-why-whiten-the-inputs-span"><span style="color:Lightgreen">Why whiten the inputs?</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-what-is-a-cluster-span"><span style="color:Orange">What is a “cluster”?</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-examples-of-clustering-in-physics-span"><span style="color:Orange">Examples of Clustering in Physics</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-physics-at-the-lhc-span"><span style="color:Lightgreen">Physics at the LHC</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-astronomy-span"><span style="color:Lightgreen">Astronomy</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-k-means-clustering-span"><span style="color:Orange">K-means Clustering</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-hyperparameters-span"><span style="color:Lightgreen">Hyperparameters</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-clustering-in-many-dimensions-span"><span style="color:Lightgreen">Clustering in many dimensions</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-general-comments-on-ml-algorithms-span"><span style="color:Orange">General comments on ML Algorithms</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-supervised-vs-unsupervised-span"><span style="color:Lightgreen">Supervised vs Unsupervised</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-expectation-maximization-span"><span style="color:Orange">Expectation-Maximization</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-other-clustering-methods-span"><span style="color:Orange">Other Clustering Methods</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-acknowledgments-span"><span style="color:Orange">Acknowledgments</span></a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="finding-structure-in-data">
<h1>Finding Structure in Data<a class="headerlink" href="#finding-structure-in-data" title="Permalink to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span><span class="p">;</span> <span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">os.path</span>
<span class="kn">import</span> <span class="nn">subprocess</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Data helpers</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">wget_data</span><span class="p">(</span><span class="n">url</span><span class="p">):</span>
    <span class="n">local_path</span><span class="o">=</span><span class="s1">&#39;./tmp_data&#39;</span>
    <span class="n">subprocess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="s2">&quot;wget&quot;</span><span class="p">,</span> <span class="s2">&quot;-nc&quot;</span><span class="p">,</span> <span class="s2">&quot;-P&quot;</span><span class="p">,</span> <span class="n">local_path</span><span class="p">,</span> <span class="n">url</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">locate_data</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">check_exists</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">local_path</span><span class="o">=</span><span class="s1">&#39;./tmp_data&#39;</span>
    <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">local_path</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">check_exists</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
        <span class="k">raise</span> <span class="n">RuxntimeError</span><span class="p">(</span><span class="s1">&#39;No such data file: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">path</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">path</span>
</pre></div>
</div>
</div>
</div>
<section id="span-style-color-orange-get-data-span">
<h2><span style="color:Orange">Get Data</span><a class="headerlink" href="#span-style-color-orange-get-data-span" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">wget_data</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/data/cluster_a_data.hf5&#39;</span><span class="p">)</span>
<span class="n">wget_data</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/data/cluster_b_data.hf5&#39;</span><span class="p">)</span>
<span class="n">wget_data</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/data/cluster_c_data.hf5&#39;</span><span class="p">)</span>
<span class="n">wget_data</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/data/cluster_d_data.hf5&#39;</span><span class="p">)</span>
<span class="n">wget_data</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/data/cluster_3d_data.hf5&#39;</span><span class="p">)</span>
<span class="n">wget_data</span><span class="p">(</span><span class="s1">&#39;https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/data/cosmo_data.hf5&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-orange-load-data-span">
<h2><span style="color:Orange">Load Data</span><a class="headerlink" href="#span-style-color-orange-load-data-span" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a_data</span>     <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_hdf</span><span class="p">(</span><span class="n">locate_data</span><span class="p">(</span><span class="s1">&#39;cluster_a_data.hf5&#39;</span><span class="p">))</span>
<span class="n">b_data</span>     <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_hdf</span><span class="p">(</span><span class="n">locate_data</span><span class="p">(</span><span class="s1">&#39;cluster_b_data.hf5&#39;</span><span class="p">))</span>
<span class="n">c_data</span>     <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_hdf</span><span class="p">(</span><span class="n">locate_data</span><span class="p">(</span><span class="s1">&#39;cluster_c_data.hf5&#39;</span><span class="p">))</span>
<span class="n">d_data</span>     <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_hdf</span><span class="p">(</span><span class="n">locate_data</span><span class="p">(</span><span class="s1">&#39;cluster_d_data.hf5&#39;</span><span class="p">))</span>
<span class="n">cluster_3d</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_hdf</span><span class="p">(</span><span class="n">locate_data</span><span class="p">(</span><span class="s1">&#39;cluster_3d_data.hf5&#39;</span><span class="p">))</span>
<span class="n">cosmo_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_hdf</span><span class="p">(</span><span class="n">locate_data</span><span class="p">(</span><span class="s1">&#39;cosmo_data.hf5&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-orange-scikit-learn-span">
<h2><span style="color:Orange">SciKit Learn</span><a class="headerlink" href="#span-style-color-orange-scikit-learn-span" title="Permalink to this heading">#</a></h2>
<p>This will be our first time using the <a class="reference external" href="http://scikit-learn.org/stable/">SciKit Learn package</a>.  We don’t include it in our standard preamble since it contains many modules (sub-packages).  Instead, we import each module as we need it.  The ones we need now are:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span><span class="p">,</span> <span class="n">cluster</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="span-style-color-orange-finding-structure-in-data-span">
<h2><span style="color:Orange">Finding Structure in Data</span><a class="headerlink" href="#span-style-color-orange-finding-structure-in-data-span" title="Permalink to this heading">#</a></h2>
<p>The type of structure we can look for is “clusters” of “nearby” samples, but the definition of these terms requires some care.</p>
<section id="span-style-color-lightgreen-distance-between-samples-span">
<h3><span style="color:Lightgreen">Distance between samples</span><a class="headerlink" href="#span-style-color-lightgreen-distance-between-samples-span" title="Permalink to this heading">#</a></h3>
<p>In the simplest case, all features <span class="math notranslate nohighlight">\(x_{ij}\)</span> have the same (possibly dimensionless) units, and the natural distance between samples (rows) <span class="math notranslate nohighlight">\(j\)</span> and <span class="math notranslate nohighlight">\(k\)</span> is:</p>
<div class="math notranslate nohighlight">
\[ \Large
d(j, k) = \sum_{\text{features}\,i} (x_{ji} - x_{ki})^2 \; .
\]</div>
<p>However, what if some columns have different units?  For example, what is the distance between:</p>
<div class="math notranslate nohighlight">
\[ \Large
\left( 1.2, 0.4~\text{cm}, 5.2~\text{kPa}\right)
\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[ \Large
\left( 0.7, 0.5~\text{cm}, 4.9~\text{kPa}\right)
\]</div>
<p>?</p>
<p>ML algorithms are generally unit-agnostic, so will happily combine features with different units but that may not be what you really want.</p>
</section>
<section id="span-style-color-lightgreen-whitening-transformation-span">
<h3><span style="color:Lightgreen">Whitening transformation</span><a class="headerlink" href="#span-style-color-lightgreen-whitening-transformation-span" title="Permalink to this heading">#</a></h3>
<p>One reasonable solution is to normalize each feature with the <a class="reference external" href="https://en.wikipedia.org/wiki/Whitening_transformation">whitening transformation</a>:</p>
<div class="math notranslate nohighlight">
\[ \Large
x \rightarrow (x - \mu) / \sigma
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mu\)</span>, <span class="math notranslate nohighlight">\(\sigma\)</span> are the mean and standard deviation of the original feature values.</p>
<p>It is called “whitening” because it transforms the input vector into a <a class="reference external" href="https://en.wikipedia.org/wiki/White_noise">white noise vector</a></p>
<p><a class="reference internal" href="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Clustering-440px-White_noise.png"><img alt="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Clustering-440px-White_noise.png" class="align-left" src="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Clustering-440px-White_noise.png" style="width: 600px;" /></a></img><br></p>
<p><a class="reference internal" href="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Clustering-White-noise-mv255-240x180.png"><img alt="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Clustering-White-noise-mv255-240x180.png" class="align-left" src="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Clustering-White-noise-mv255-240x180.png" style="width: 600px;" /></a></img><br></p>
<p>Generally speaking, a whitening transformation is a linear transformation that transforms a vector of random variables with a known covariance matrix into a set of new variables whose covariance is the identity matrix, meaning that they are uncorrelated and each have unit variance.</p>
<p>Suppose that <span class="math notranslate nohighlight">\(X\)</span> is a column vector of random data with a non-singular covariance matrix <span class="math notranslate nohighlight">\(M\)</span>. Then the transformation</p>
<div class="math notranslate nohighlight">
\[ \Large
Y = WX
\]</div>
<p>with a whitening matrix <span class="math notranslate nohighlight">\(W\)</span> satisfying the condition</p>
<div class="math notranslate nohighlight">
\[ \Large
W^T W = M^{-1}
\]</div>
<p>yields the whitened random vector <span class="math notranslate nohighlight">\(Y\)</span> with unit diagonal convariance. There are an infinite nunber of possible whitening matrices that satisfy the condition above. One common choice is via the <span style="color:violet">Principle Component Analyis</span> (PCA) method which utilizes the eigen-system of <span class="math notranslate nohighlight">\(M\)</span> to whiten <span class="math notranslate nohighlight">\(X\)</span>. We will come back to this in a bit when we talk more about dimensionality reduction.</p>
</section>
<section id="span-style-color-lightgreen-why-whiten-the-inputs-span">
<h3><span style="color:Lightgreen">Why whiten the inputs?</span><a class="headerlink" href="#span-style-color-lightgreen-why-whiten-the-inputs-span" title="Permalink to this heading">#</a></h3>
<p>In general, learning algorithms benefit from standardization of the data set to minimize differences in the mean and variance of the input features. If some outliers are present in the set, robust scalers or transformers are more appropriate. We will learn more about this when we talk about the PCA method, but you can read <a class="reference external" href="http://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html#sphx-glr-auto-examples-preprocessing-plot-scaling-importance-py">Importance of Feature Scaling</a> if you want to read more now.</p>
<p>The <a class="reference external" href="http://scikit-learn.org/stable/modules/preprocessing.html">sklearn.preprocessing module</a> automates this process with:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cosmo_data</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cosmo_normed</span> <span class="o">=</span> <span class="n">cosmo_data</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">cosmo_normed</span><span class="p">[</span><span class="n">cosmo_data</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">cosmo_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cosmo_normed</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>However, this may discard useful information contained in the relative normalization between features. To normalize only certain columns use, for example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cosmo_normed</span> <span class="o">=</span> <span class="n">cosmo_data</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="k">for</span> <span class="n">colname</span> <span class="ow">in</span> <span class="s1">&#39;ln10^</span><span class="si">{10}</span><span class="s1">A_s&#39;</span><span class="p">,</span> <span class="s1">&#39;H0&#39;</span><span class="p">:</span>
    <span class="n">cosmo_normed</span><span class="p">[</span><span class="n">colname</span><span class="p">]</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">cosmo_data</span><span class="p">[</span><span class="n">colname</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="span-style-color-orange-what-is-a-cluster-span">
<h2><span style="color:Orange">What is a “cluster”?</span><a class="headerlink" href="#span-style-color-orange-what-is-a-cluster-span" title="Permalink to this heading">#</a></h2>
<p>In the simplest case (a), clusters are well separated by a line (in 2D, or hyperplane in more dimensions) and can be unambiguously identified by looking only at the distance between pairs of samples.</p>
<p>In practice, clusters might overlap leading to ambiguities (b), or the clusters we expect to find might require considering groups of more than two samples at a time (c), or might have a non-linear separation boundary (d).</p>
<p><a class="reference internal" href="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Clustering-cluster_types.png"><img alt="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Clustering-cluster_types.png" class="align-left" src="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Clustering-cluster_types.png" style="width: 800px;" /></a></img><br></p>
</section>
<section id="span-style-color-orange-examples-of-clustering-in-physics-span">
<h2><span style="color:Orange">Examples of Clustering in Physics</span><a class="headerlink" href="#span-style-color-orange-examples-of-clustering-in-physics-span" title="Permalink to this heading">#</a></h2>
<p>The ability to cluster data from physics instruments is critical to being able to extract important features from the data on the road to making inference about nature.</p>
<section id="span-style-color-lightgreen-physics-at-the-lhc-span">
<h3><span style="color:Lightgreen">Physics at the LHC</span><a class="headerlink" href="#span-style-color-lightgreen-physics-at-the-lhc-span" title="Permalink to this heading">#</a></h3>
<p>There are many examples of data clustering in the study of particle collisions at the LHC. One important exampe is the clustering of data from calorimeter detectors to find the remants of quark or gluon production – called “jets”. A jet is a narrow cone of hadrons and other particles produced by the hadronization of a quark or gluon in a particle physics or heavy ion experiment. Particles carrying a color charge, such as quarks, cannot exist in free form because of QCD confinement which only allows for colorless states.</p>
<p><a class="reference internal" href="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Clustering-ATLAS_event_display_vp1_run266904_evt25855182_2015-06-03T13-41-48_b.png"><img alt="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Clustering-ATLAS_event_display_vp1_run266904_evt25855182_2015-06-03T13-41-48_b.png" class="align-left" src="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Clustering-ATLAS_event_display_vp1_run266904_evt25855182_2015-06-03T13-41-48_b.png" style="width: 800px;" /></a></img><br></p>
<p><a class="reference internal" href="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Clustering-2jets.jpg"><img alt="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Clustering-2jets.jpg" class="align-left" src="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Clustering-2jets.jpg" style="width: 800px;" /></a></img><br></p>
</section>
<section id="span-style-color-lightgreen-astronomy-span">
<h3><span style="color:Lightgreen">Astronomy</span><a class="headerlink" href="#span-style-color-lightgreen-astronomy-span" title="Permalink to this heading">#</a></h3>
<p>Astrophysical objects have a variety of distinct objects and emissions that reflect the richness and beauty of our Universe. So, its not surprising that clustering algorthims to identify and ultimately understand astrophysical objects play a central role in Astronomy.</p>
<p>As an example, astronomers use properties of Gamma Ray Bursts (GRBs) such as their location in the sky, arrival time, duration, fluence, spectral hardness to find subtypes/classes of events:</p>
<p><a class="reference internal" href="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Clustering-GRBs.png"><img alt="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Clustering-GRBs.png" class="align-left" src="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Clustering-GRBs.png" style="width: 800px;" /></a></img><br></p>
<p><a class="reference internal" href="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Clustering-times.png"><img alt="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Clustering-times.png" class="align-left" src="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Clustering-times.png" style="width: 800px;" /></a></img><br></p>
</section>
</section>
<section id="span-style-color-orange-k-means-clustering-span">
<h2><span style="color:Orange">K-means Clustering</span><a class="headerlink" href="#span-style-color-orange-k-means-clustering-span" title="Permalink to this heading">#</a></h2>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/K-means_clustering">K-means algorithm</a> is fast and robust, but assumes that your data consists of roughly round clusters of the same size (where the meanings of “round” and “size” depend on how your data is scaled). The algorithm aims to partition <span class="math notranslate nohighlight">\(n\)</span> observations into <span class="math notranslate nohighlight">\(k\)</span> clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid).</p>
<p>Most sklearn algorithms use a similar calling pattern:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">result</span> <span class="o">=</span> <span class="n">module</span><span class="o">.</span><span class="n">ClassName</span><span class="p">(</span><span class="o">..</span><span class="n">args</span><span class="o">..</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p>For the <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans">KMeans algorithm</a>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">a_fit</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">a_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We will use the following function to display 2D cluster results (don’t worry about the <a class="reference external" href="https://seaborn.pydata.org/tutorial/color_palettes.html">details</a> unless you are interested):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">display</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">fit</span><span class="p">):</span>
    <span class="n">n_clusters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">fit</span><span class="o">.</span><span class="n">labels_</span><span class="p">))</span>
    <span class="c1"># Pick good colors to distinguish the different clusters.</span>
    <span class="kn">import</span> <span class="nn">matplotlib.colors</span>
    <span class="n">cmap</span> <span class="o">=</span> <span class="n">matplotlib</span><span class="o">.</span><span class="n">colors</span><span class="o">.</span><span class="n">ListedColormap</span><span class="p">(</span>
        <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">(</span><span class="s2">&quot;husl&quot;</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">)</span><span class="o">.</span><span class="n">as_hex</span><span class="p">())</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">fit</span><span class="o">.</span><span class="n">labels_</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cmap</span><span class="p">)</span>
    <span class="c1"># Use standard axes to match the plot above.</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">9</span><span class="p">,</span> <span class="o">+</span><span class="mi">9</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="o">+</span><span class="mi">5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="mf">1.</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">a_data</span><span class="p">,</span> <span class="n">a_fit</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><em><strong><span style="color:violet">EXERCISE</span></strong></em>: Use KMeans to fit the three other (b,c,d) 2D datasets with <code class="docutils literal notranslate"><span class="pre">n_clusters=2</span></code> and generate similar plots. Which fits give the expected results?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">b_fit</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">b_data</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">b_data</span><span class="p">,</span> <span class="n">b_fit</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">c_fit</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">c_data</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">c_data</span><span class="p">,</span> <span class="n">c_fit</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">d_fit</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">d_data</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">d_data</span><span class="p">,</span> <span class="n">d_fit</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The fit results look reasonable for (b), although the sharp dividing line between the two clusters looks artificial.</p>
<p>The fit results for (c) and (d) do not match what we expect because KMeans only considers one pair at a time, so cannot identify larger scale patterns that are obvious by eye.</p>
<section id="span-style-color-lightgreen-hyperparameters-span">
<h3><span style="color:Lightgreen">Hyperparameters</span><a class="headerlink" href="#span-style-color-lightgreen-hyperparameters-span" title="Permalink to this heading">#</a></h3>
<p>Algorithms have many parameters that influence their results for a given dataset, but these fall into two categories:</p>
<ul class="simple">
<li><p>Parameters whose values are determined by the data during the fitting process.</p></li>
<li><p>Parameters which must be externally set.</p></li>
</ul>
<p>We refer the second group as “hyperparameters” and set their values during the “model selection” process, which we will discuss later.</p>
<p><em><strong><span style="color:violet">DISCUSS</span></strong></em>: Are all of the arguments of the <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans">KMeans constructor</a> hyperparameters?</p>
<p>In principle, yes, but in practice some of these arguments will have no (or minimal) impact on the algorithm result under normal conditions.  The arguments that are most clearly hyperparameters are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">n_clusters</span></code>, <code class="docutils literal notranslate"><span class="pre">algorithm</span></code>, <code class="docutils literal notranslate"><span class="pre">tol</span></code></p></li>
</ul>
<p>The arguments that are most clearly not hyperparameters are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">verbose</span></code>, <code class="docutils literal notranslate"><span class="pre">precompute_distances</span></code>, <code class="docutils literal notranslate"><span class="pre">n_jobs</span></code></p></li>
</ul>
<p>The remaining arugments are in the gray area.  In general, it is prudent to experiment with your actual data to identify which arguments affect your results significantly.</p>
<p><em><strong><span style="color:violet">EXERCISE</span></strong></em>: Fit dataset (b) with the <code class="docutils literal notranslate"><span class="pre">n_clusters</span></code> hyperparameter set to 3 and display the results. Comparing with the 2-cluster fit above, by eye, what do think is the “true” number of clusters?  How might you decide between 2 and 3 more objectively?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">b_fit_3</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">b_data</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">b_data</span><span class="p">,</span> <span class="n">b_fit_3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The plot above makes a convincing case (to me, at least) that there are three clusters.  However, the “truth” in this case is two clusters.</p>
<p>This illustrates the dangers of superimposing a fit result on your data: it inevitably “draws your eye” and makes the fit more credible. Look out for examples of this when reading papers or listening to talks!</p>
</section>
<section id="span-style-color-lightgreen-clustering-in-many-dimensions-span">
<h3><span style="color:Lightgreen">Clustering in many dimensions</span><a class="headerlink" href="#span-style-color-lightgreen-clustering-in-many-dimensions-span" title="Permalink to this heading">#</a></h3>
<p>An algorithm to find clusters in 2D data is just automating what you could already by eye.  However, most clustering algorithms also work well with higher dimensional data, where the clusters might not be visible in any single 2D projection.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fit_3d</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">cluster_3d</span><span class="p">)</span>
<span class="n">cluster_3d</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">fit_3d</span><span class="o">.</span><span class="n">labels_</span>
<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">cluster_3d</span><span class="p">,</span> <span class="nb">vars</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;x0&#39;</span><span class="p">,</span> <span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">),</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;label&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>These clusters look quite arbitrary in each of the 2D scatter plots. However, they are actually very well separated, as we can see if we rotate the axes:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[[</span> <span class="mf">0.5</span>  <span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span>  <span class="p">,</span> <span class="o">-</span><span class="mf">0.707</span><span class="p">],</span>
     <span class="p">[</span> <span class="mf">0.707</span><span class="p">,</span>  <span class="mf">0.707</span><span class="p">,</span>  <span class="mf">0.</span>   <span class="p">],</span>
     <span class="p">[</span> <span class="mf">0.5</span>  <span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span>  <span class="p">,</span>  <span class="mf">0.707</span><span class="p">]])</span>
<span class="n">rotated_3d</span> <span class="o">=</span> <span class="n">cluster_3d</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">rotated_3d</span><span class="p">[[</span><span class="s1">&#39;x0&#39;</span><span class="p">,</span> <span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">]]</span> <span class="o">=</span> <span class="n">cluster_3d</span><span class="p">[[</span><span class="s1">&#39;x0&#39;</span><span class="p">,</span> <span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">R</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">rotated_3d</span><span class="p">,</span> <span class="nb">vars</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;x0&#39;</span><span class="p">,</span> <span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">),</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;label&#39;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>This example is contrived, but the lesson is that clustering algorithms can discover higher-dimensional structure that you might miss with visualization.</p>
</section>
</section>
<section id="span-style-color-orange-general-comments-on-ml-algorithms-span">
<h2><span style="color:Orange">General comments on ML Algorithms</span><a class="headerlink" href="#span-style-color-orange-general-comments-on-ml-algorithms-span" title="Permalink to this heading">#</a></h2>
<p>Now that we have introduced our first ML algorithm, this is a good time for some general comments.</p>
<p>Most ML algorithms have some common features:</p>
<ul class="simple">
<li><p>They seek to maximize (or minimize) some goal function <span class="math notranslate nohighlight">\(f(\theta, D)\)</span> of the (fixed) data <span class="math notranslate nohighlight">\(D\)</span>, for some (unknown) parameters <span class="math notranslate nohighlight">\(\theta\)</span>.</p></li>
<li><p>The goal function embodies some model (perhaps only implicitly) of what the data is expected to look like.</p></li>
</ul>
<p>Questions to ask about the goal function:</p>
<ul class="simple">
<li><p>Is there a single global optimum by construction? (i.e., is <span class="math notranslate nohighlight">\(\pm f\)</span> a <a class="reference external" href="https://en.wikipedia.org/wiki/Convex_function">convex function</a>?)</p></li>
<li><p>If not, might there be multiple local optima?</p></li>
</ul>
<p>Questions to ask about how the algorithm optimizes its goal function:</p>
<ul class="simple">
<li><p>Is it exact or approximate?</p></li>
<li><p>If it is approximate, is it also iterative?  If so, what are the convergence criteria?</p></li>
<li><p>How does the running time scale with the number of samples and number of features?</p></li>
</ul>
<p>The goal function of the KMeans algorithm is:</p>
<div class="math notranslate nohighlight">
\[ \Large
\sum_{i=1}^n\, \sum_{c_j = i}\, \left| x_j - \mu_i\right|^2
\]</div>
<p>where <span class="math notranslate nohighlight">\(c_j = 1\)</span> if sample <span class="math notranslate nohighlight">\(j\)</span> is assigned to cluster <span class="math notranslate nohighlight">\(i\)</span> or otherwise <span class="math notranslate nohighlight">\(c_j = 0\)</span>, and</p>
<div class="math notranslate nohighlight">
\[ \Large
\mu_i = \sum_{c_j = i}\, x_j
\]</div>
<p>is the mean of samples assigned to cluster <span class="math notranslate nohighlight">\(i\)</span>.  The outer sum is over the number of clusters <span class="math notranslate nohighlight">\(n\)</span> and <span class="math notranslate nohighlight">\(j\)</span> indexes samples. If we consider sample <span class="math notranslate nohighlight">\(x_j\)</span> to be a vector, then its elements are the feature values.</p>
<p><em><strong><span style="color:violet">DISCUSS</span></strong></em>: What are the parameters of the KMeans goal function?  How many parameters are there?</p>
<p>The parameters are the binary values <span class="math notranslate nohighlight">\(c_j\)</span> and there is one per sample (row). Note that the number of parameters is independent of the number of features (columns) in the data.</p>
<p>The number of clusters <span class="math notranslate nohighlight">\(n\)</span> is a hyperparameter since it is externally set and not adjusted by the algorithm in response to the data.</p>
<p>The means <span class="math notranslate nohighlight">\(\mu_i\)</span> are not independent parameters since their values are fixed by the <span class="math notranslate nohighlight">\(c_j\)</span> (given the data).</p>
<section id="span-style-color-lightgreen-supervised-vs-unsupervised-span">
<h3><span style="color:Lightgreen">Supervised vs Unsupervised</span><a class="headerlink" href="#span-style-color-lightgreen-supervised-vs-unsupervised-span" title="Permalink to this heading">#</a></h3>
<p>ML algorithms come in two flavors, depending on whether they require some training data where you already know the answer (“supervised”) or not (“unsupervised”). Clustering algorithms are unsupervised.</p>
<p>An advantage of unsupervised ML is that it works with any input data, and can discover patterns that you might not already know about (as in the 3D example above).  Even when you have training data available, an unsupervised algorithm can still be useful.</p>
<p>The disadvantage of unsupervised learning is that we cannot formulate objective measures for how well an algorithm is performing, so the results are always somewhat subjective.</p>
</section>
</section>
<section id="span-style-color-orange-expectation-maximization-span">
<h2><span style="color:Orange">Expectation-Maximization</span><a class="headerlink" href="#span-style-color-orange-expectation-maximization-span" title="Permalink to this heading">#</a></h2>
<p>The KMeans algorithm uses an iterative solution based on the <a class="reference external" href="https://en.wikipedia.org/wiki/Expectation-maximization_algorithm">Expectation-Maximization (EM)</a> principle. This is an iterative method to find (local) maximum likelihood or maximum a posteriori (MAP) estimates of parameters in statistical models, where the model depends on unobserved latent variables. The EM iteration alternates between performing an expectation (E) step, which creates a function for the expectation of the log-likelihood evaluated using the current estimate for the parameters, and a maximization (M) step, which computes parameters maximizing the expected log-likelihood found on the E step. These parameter-estimates are then used to determine the distribution of the latent variables in the next E step.</p>
<p>See below and example of EM-based Clustering of Old Faithful data. Starting with a random assignment and unit spheres (note that the axes have different scales), EM quickly adapts to the dataset. The <span class="math notranslate nohighlight">\(x\)</span>-axis is the duration of the geyser eruption. The <span class="math notranslate nohighlight">\(y\)</span>-axis is the delay from the previous eruption.</p>
<p><a class="reference internal" href="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Clustering-EM_Clustering_of_Old_Faithful_data.gif"><img alt="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Clustering-EM_Clustering_of_Old_Faithful_data.gif" class="align-left" src="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Clustering-EM_Clustering_of_Old_Faithful_data.gif" style="width: 400px;" /></a></img><br></p>
<p>The EM method a powerful approach used by many algorithms, which we will revist several times during the course.</p>
</section>
<section id="span-style-color-orange-other-clustering-methods-span">
<h2><span style="color:Orange">Other Clustering Methods</span><a class="headerlink" href="#span-style-color-orange-other-clustering-methods-span" title="Permalink to this heading">#</a></h2>
<p>We have focused on KMeans as a prototypical clustering algorithm, but there are <a class="reference external" href="http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html">many others to chose from</a>.</p>
<p>We will finish this section with some brief experimentation with two alternatives that use more global information than KMeans, and are therefore better suited to examples (c) and (d) above:</p>
<ul class="simple">
<li><p>Spectral clustering: <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html">sklearn</a>, <a class="reference external" href="https://en.wikipedia.org/wiki/Spectral_clustering">wikipedia</a>.</p></li>
<li><p>Density-based spatial clustering of applications with noise (DBSCAN): <a class="reference external" href="http://scikit-learn.org/stable/modules/clustering.html#spectral-clustering">sklearn</a>, <a class="reference external" href="https://en.wikipedia.org/wiki/DBSCAN">wikipedia</a>.</p></li>
</ul>
<p><em><strong><span style="color:violet">EXERCISE</span></strong></em>: Use <code class="docutils literal notranslate"><span class="pre">cluster.SpectralClustering</span></code> to fit <code class="docutils literal notranslate"><span class="pre">c_data</span></code> and <code class="docutils literal notranslate"><span class="pre">d_data</span></code> and display the results.  Adjust the default hyperparameters, if necessary, to obtain the expected results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">c_fit</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">SpectralClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">c_data</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">c_data</span><span class="p">,</span> <span class="n">c_fit</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">d_fit</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">SpectralClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">d_data</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">d_data</span><span class="p">,</span> <span class="n">d_fit</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><em><strong><span style="color:violet">EXERCISE</span></strong></em>: Use <code class="docutils literal notranslate"><span class="pre">cluster.DBSCAN</span></code> to fit <code class="docutils literal notranslate"><span class="pre">c_data</span></code> and <code class="docutils literal notranslate"><span class="pre">d_data</span></code> and display the results.  Adjust the default hyperparameters, if necessary, to obtain the expected results.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">c_fit</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">DBSCAN</span><span class="p">(</span><span class="n">eps</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">c_data</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">c_data</span><span class="p">,</span> <span class="n">c_fit</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">d_fit</span> <span class="o">=</span> <span class="n">cluster</span><span class="o">.</span><span class="n">DBSCAN</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">d_data</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">d_data</span><span class="p">,</span> <span class="n">d_fit</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<hr class="docutils" />
<section id="span-style-color-orange-acknowledgments-span">
<h2><span style="color:Orange">Acknowledgments</span><a class="headerlink" href="#span-style-color-orange-acknowledgments-span" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Initial version: Mark Neubauer</p></li>
</ul>
<p>© Copyright 2023</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./_sources/lectures"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="Visualization.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Visualizing Data</p>
      </div>
    </a>
    <a class="right-next"
       href="../homework/Homework_02.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Homework 02: Visualization</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-get-data-span"><span style="color:Orange">Get Data</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-load-data-span"><span style="color:Orange">Load Data</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-scikit-learn-span"><span style="color:Orange">SciKit Learn</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-finding-structure-in-data-span"><span style="color:Orange">Finding Structure in Data</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-distance-between-samples-span"><span style="color:Lightgreen">Distance between samples</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-whitening-transformation-span"><span style="color:Lightgreen">Whitening transformation</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-why-whiten-the-inputs-span"><span style="color:Lightgreen">Why whiten the inputs?</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-what-is-a-cluster-span"><span style="color:Orange">What is a “cluster”?</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-examples-of-clustering-in-physics-span"><span style="color:Orange">Examples of Clustering in Physics</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-physics-at-the-lhc-span"><span style="color:Lightgreen">Physics at the LHC</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-astronomy-span"><span style="color:Lightgreen">Astronomy</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-k-means-clustering-span"><span style="color:Orange">K-means Clustering</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-hyperparameters-span"><span style="color:Lightgreen">Hyperparameters</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-clustering-in-many-dimensions-span"><span style="color:Lightgreen">Clustering in many dimensions</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-general-comments-on-ml-algorithms-span"><span style="color:Orange">General comments on ML Algorithms</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-supervised-vs-unsupervised-span"><span style="color:Lightgreen">Supervised vs Unsupervised</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-expectation-maximization-span"><span style="color:Orange">Expectation-Maximization</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-other-clustering-methods-span"><span style="color:Orange">Other Clustering Methods</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-acknowledgments-span"><span style="color:Orange">Acknowledgments</span></a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Mark Neubauer
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>