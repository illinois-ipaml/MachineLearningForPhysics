

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Stochastic Processes and Markov-Chain Theory &#8212; PHYS 503</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_sources/lectures/Markov';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Variational Inference" href="Variational.html" />
    <link rel="prev" title="Stochastic Processes, Markov Chains &amp; Variational Inference" href="../Week_07.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="PHYS 503 - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="PHYS 503 - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    <span style="color:Blue">Instrumentation Physics: Applications of Machine Learning</span>
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Introduction to Machine Learning and Data Science</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_01.html"><span style="color: blue;"><b>Course Introduction</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1vq4b3zxrhEMJbfeCH52hufBbXvTwhufEXdSs8mWY2ec/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="JupyterNumpy.html">Jupyter Notebooks and Numerical Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="Pandas.html">Handling Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_01.html">Homework 01: Numerical python and data handling</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_02.html"><span style="color: blue;"><b>Visualizing &amp; Finding Structure in Data</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1_LstEfghjdZUheyrqbjx4PK9y1J0cN-_hOdCInTldp8/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="Visualization.html">Visualizing Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="Clustering.html">Finding Structure in Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_02.html">Homework 02: Visualization and Expectation-Maximization</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_03.html"><span style="color: blue;"><b>Dimensionality, Linearity and Kernel Functions</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1x4bWQr7kEAh6Z6L7iaLdaNiY6SDTHtvHxzvjFM1wYnE/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="Dimensionality.html">Measuring and Reducing Dimensionality</a></li>
<li class="toctree-l2"><a class="reference internal" href="Nonlinear.html">Adapting Linear Methods to Non-Linear Data and Kernel Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_03.html">Homework 03: K-means and Principle Component Analysis</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Probability and Statistics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_04.html"><span style="color: blue;"><b>Probability Theory</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1qW-gCHY3bQMmB0-klM0crTD9020UG3DTlT_awlOhy2A/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="ProbabilityTheory.html">Probability Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="ProbabilityDistributions.html">Important Probability Distributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_04.html">Homework 04: Probability Theory and Common Distributions</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_05.html"><span style="color: blue;"><b>Kernel Density Estimation and Statistics</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1XZoeBdXzhcfezIbUrH0a9-4-QmM-5iNksLCB7X4q1wI/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="Density.html">Estimating Probability Density from Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="Statistics.html">Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_05.html">Homework 05: Kernel Density Estimation, Covariance and Correlation</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Bayesian Inference</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_06.html"><span style="color: blue;"><b>Bayesian Statistics and Markov Chain Monte Carlo</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1L_lz0WbrrUu9qDPnKxYu5S_fCXKjl01Mrs2RnHN5_6E/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="Bayes.html">Bayesian Statistics</a></li>
<li class="toctree-l2"><a class="reference internal" href="MCMC.html">Markov Chain Monte Carlo in Practice</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_06.html">Homework 06: Bayesian Statistics and MCMC</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Project_01.html"><span style="color: blue;"><b>Project 01</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_HiggsTauTau.html">Higgs Boson Decaying to Tau Leptons</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_ExoticParticles.html">Searching for Exotic Particles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_GalaxyZoo.html">Galaxy Zoo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_NuclearGeometryQGP.html">Nuclear Geometry and Characterization of the Quark Gluon Plasma</a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_01_DarkEnergySurvey.html">Dark Energy Survey</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="../Week_07.html"><span style="color: blue;"><b>Stochastic Processes, Markov Chains &amp; Variational Inference</b></span></a><input checked="" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/11Mzc9rBUcnEh_D3SKeDUoCW-iwIA9ilcxsx_4yuu32A/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Stochastic Processes and Markov-Chain Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="Variational.html">Variational Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_07.html">Homework 07: Markov Chains</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_08.html"><span style="color: blue;"><b>Optimization and Model Selection</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1KshmOwKTWptL-3PASHrW6WT2PkH2ltU-XwoYOflhKQk/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="Optimization.html">Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="ModelSelection.html">Bayesian Model Selection</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Supervised Learning &amp; Cross Validation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_09.html"><span style="color: blue;"><b>Learning &amp; Cross Validation</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1a2cjkREM0LYxRjrLwrfHPTotM0n_CgVrZ_WQjEyc_Jc/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="Learning.html">Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="CrossValidation.html">Cross Validation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_08.html">Homework 08: Cross Validation</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Artificial Neural Networks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_10.html"><span style="color: blue;"><b>Supervised Learning &amp; Artificial Neural Networks</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1vyg7eSo5XaUAtYDwxmLY5qeUrwKxKqJcEEHPB40yVpE/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="Supervised.html">Supervised Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="NeuralNetworks.html">Artificial Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_09.html">Homework 09: Artificial Neural Networks</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_11.html"><span style="color: blue;"><b>Deep Neural Networks</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1RnFI0k15C_m2j43QtFDGCFRBCcQ-Rx6EG-9U3EumOHc/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="DeepLearning.html">Deep Learning</a></li>



<li class="toctree-l2"><a class="reference internal" href="../homework/Homework_10.html">Homework 10: Forecasting Projectile Motion with Recurrent Neural Networks</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_12.html"><span style="color: blue;"><b>Graph Neural Networks</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1fxZdnCU_8pWocQbjMQ5HUOSUL3MgbCyg3xFWxfeNaeY/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="GraphNeuralNetworks.html">Graph Neural Networks</a></li>





</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Project_02.html"><span style="color: blue;"><b>Project 02</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_02_HiggsTauTau.html"><em><strong><span style="color:Yellow">Higgs Boson Decaying to Tau Leptons</span></strong></em></a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_02_ExoticParticles.html"><em><strong><span style="color:Yellow">Searching for Exotic Particles</span></strong></em></a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_02_GalaxyZoo.html"><em><strong><span style="color:Yellow">Galaxy Zoo</span></strong></em></a></li>
<li class="toctree-l2"><a class="reference internal" href="../projects/Project_02_NuclearGeometryQGP.html">Nuclear Geometry and Characterization of the Quark Gluon Plasma</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_13.html"><span style="color: blue;"><b>Unsupervised Learning, Uncertainties and Anomaly Detection</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1jGxr3j5t7Ahi3Ai6501dVJXOIzvlYMGhe9ZDqHlcfjo/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="UnsupervisedLearning.html">Unsupervised Learning</a></li>

</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Accelerated Machine Learning and Inference</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../Week_14.html"><span style="color: blue;"><b>Accelerated Machine Learning and Inference</b></span></a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference external" href="https://docs.google.com/presentation/d/1-_9DcO71v6fQN1kNhKRH2d2iSjhs_Ddi2wLxiXy6RNg/edit?usp=sharing">Slides</a></li>
<li class="toctree-l2"><a class="reference internal" href="AcceleratedML.html">Accelerated Machine Learning and Inference</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/illinois-ipaml/MachineLearningForPhysics/blob/main/_sources/lectures/Markov.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>



<a href="https://github.com/illinois-ipaml/MachineLearningForPhysics" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/_sources/lectures/Markov.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Stochastic Processes and Markov-Chain Theory</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-stochastic-processes-span"><span style="color:Orange">Stochastic Processes</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-markov-chain-span"><span style="color:Orange">Markov Chain</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-stationary-markov-chains-span"><span style="color:Lightgreen">Stationary Markov Chains</span></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-reversible-markov-chains-span"><span style="color:Orange">Reversible Markov Chains</span></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-equilibrium-distributions-span"><span style="color:Lightgreen">Equilibrium Distributions</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-custom-markov-chain-span"><span style="color:Orange">Custom Markov Chain</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-metropolis-hastings-updates-span"><span style="color:Lightgreen">Metropolis-Hastings Updates</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-gibbs-sampling-span"><span style="color:Lightgreen">Gibbs Sampling</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-hamiltonian-sampling-span"><span style="color:Lightgreen">Hamiltonian Sampling</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-practical-advice-span"><span style="color:Orange">Practical Advice</span></a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="stochastic-processes-and-markov-chain-theory">
<h1>Stochastic Processes and Markov-Chain Theory<a class="headerlink" href="#stochastic-processes-and-markov-chain-theory" title="Permalink to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span><span class="p">;</span> <span class="n">sns</span><span class="o">.</span><span class="n">set</span><span class="p">()</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">os.path</span>
<span class="kn">import</span> <span class="nn">subprocess</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span>
</pre></div>
</div>
</div>
</div>
<section id="span-style-color-orange-stochastic-processes-span">
<h2><span style="color:Orange">Stochastic Processes</span><a class="headerlink" href="#span-style-color-orange-stochastic-processes-span" title="Permalink to this heading">#</a></h2>
<p>A <span style="color:violet">stochastic process</span> is a black-box generator of random sequences</p>
<div class="math notranslate nohighlight">
\[ \Large
x_0, x_1, x_2, \ldots
\]</div>
<p>where, in general, the value <span class="math notranslate nohighlight">\(x_n\)</span> depends on the history of all previous samples, so the black box has long-term memory. The values appearing at the <span class="math notranslate nohighlight">\(n\)</span>-th position of many runs of the black box sample the random variable <span class="math notranslate nohighlight">\(X_n\)</span>. In general, samples can be multi-dimensional, <span class="math notranslate nohighlight">\(\vec{x}_i\)</span>, but this does not present any special challenges or require new concepts so we will stick with the cleaner 1D notation in the following.</p>
<p>We will start with a simple example of a general stochastic process. Below is a helper Class <code class="docutils literal notranslate"><span class="pre">StochasticProcess</span></code> that we will make use of in our study of stochastic processes:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">StochasticProcess</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Base class for a stochastic process.</span>

<span class="sd">    A subclass must implement the :meth:`initial` and :meth:`update` methods.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize a generic stochastic process.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        seed : int or None</span>
<span class="sd">            Random seed to use for reproducible random numbers. A random state</span>
<span class="sd">            initialized with this seed is passed to the initial() and update()</span>
<span class="sd">            methods.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gen</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nsamples_per_run</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">nruns</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">joined</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Plot a few sequences of many samples.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        nsamples_per_run : int</span>
<span class="sd">            Number of samples to plot for each run of the process.</span>
<span class="sd">        nruns : int</span>
<span class="sd">            Number of independent runs to plot. Should usually be a small</span>
<span class="sd">            number.</span>
<span class="sd">        joined : bool</span>
<span class="sd">            Join samples from the same run with lines when True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">cmap</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">color_palette</span><span class="p">()</span><span class="o">.</span><span class="n">as_hex</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nruns</span><span class="p">):</span>
            <span class="n">run</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">nsamples_per_run</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">run</span><span class="p">,</span> <span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">cmap</span><span class="p">[</span><span class="n">i</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">cmap</span><span class="p">)])</span>
            <span class="k">if</span> <span class="n">joined</span><span class="p">:</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">run</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">cmap</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Sequence number $n$&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Value $x_n$&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">pairplot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nsamples_per_run</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">nruns</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">x0cut</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Plot 1D and 2D statistics of a few samples using many runs.</span>

<span class="sd">        Uses a seaborn PairGrid.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        nsamples_per_run : int</span>
<span class="sd">            Number of samples to include in the plot. Should usually be</span>
<span class="sd">            a small number.</span>
<span class="sd">        nruns : int</span>
<span class="sd">            Number of independent runs to use for building up statistics.</span>
<span class="sd">        x0cut : float or None</span>
<span class="sd">            Each plot is color-coded according to whether x0 is below or</span>
<span class="sd">            above this cut value, in order to show how dependencies propagate</span>
<span class="sd">            to later samples. Uses the median x0 value when None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">nruns</span><span class="p">,</span> <span class="n">nsamples_per_run</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nruns</span><span class="p">):</span>
            <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">nsamples_per_run</span><span class="p">)</span>
        <span class="n">names</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;$x_{{</span><span class="si">{}</span><span class="s1">}}$&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">j</span><span class="p">)</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nsamples_per_run</span><span class="p">))</span>
        <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">names</span><span class="p">)</span>
        <span class="c1"># Color samples based on whether x0 &gt; x0cut.</span>
        <span class="n">x0</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">x0cut</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x0cut</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">median</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
        <span class="n">df</span><span class="p">[</span><span class="s1">&#39;sel0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">cut</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">x0</span><span class="p">),</span> <span class="n">x0cut</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x0</span><span class="p">)])</span>
        <span class="n">grid</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">PairGrid</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;sel0&#39;</span><span class="p">)</span>
        <span class="n">grid</span><span class="o">.</span><span class="n">map_diag</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s1">&#39;stepfilled&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">grid</span><span class="o">.</span><span class="n">map_diag</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s1">&#39;step&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">grid</span><span class="o">.</span><span class="n">map_lower</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">tabulate_conditional</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">lo</span><span class="p">,</span> <span class="n">hi</span><span class="p">,</span> <span class="n">nbins</span><span class="p">,</span> <span class="n">nruns</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Tabulate the conditional probability P(Xm|Xn) numerically.</span>

<span class="sd">        n : int</span>
<span class="sd">            Tabulated probabilities are conditioned on n &gt;= 0.</span>
<span class="sd">        m : int</span>
<span class="sd">            Tabulated probabilities are for P(Xm|Xn) with m &gt; m.</span>
<span class="sd">        lo : float</span>
<span class="sd">            Tabulate values of Xn and Xm on the interval [lo, hi].</span>
<span class="sd">        hi : float</span>
<span class="sd">            Tabulate values of Xn and Xm on the interval [lo, hi].</span>
<span class="sd">        nbins : int</span>
<span class="sd">            Number of bins to use for tabulated values in [lo, hi].</span>
<span class="sd">        nruns : int</span>
<span class="sd">            Number of independent runs to perform to tabulate statistics.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        tuple</span>
<span class="sd">            Tuple (bins, P) where bins is an array of nbins+1 bin edge values</span>
<span class="sd">            spanning [lo, hi] and P is an array of shape (nbins, nbins)</span>
<span class="sd">            containing the tabulated probabilities.  P is normalized for</span>
<span class="sd">            each value of the conditional Xn, i.e., P.sum(axis=1) = 1.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">m</span> <span class="o">&gt;</span> <span class="n">n</span> <span class="ow">and</span> <span class="n">n</span> <span class="o">&gt;=</span> <span class="mi">0</span>
        <span class="n">nsteps</span> <span class="o">=</span> <span class="n">m</span> <span class="o">-</span> <span class="n">n</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">nbins</span><span class="p">,</span> <span class="n">nbins</span><span class="p">))</span>
        <span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">lo</span><span class="p">,</span> <span class="n">hi</span><span class="p">,</span> <span class="n">nbins</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">centers</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">bins</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="n">bins</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">Xi</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">centers</span><span class="p">):</span>
            <span class="n">Xj</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nruns</span><span class="p">):</span>
                <span class="n">history</span> <span class="o">=</span> <span class="p">[</span><span class="n">Xi</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nsteps</span><span class="p">):</span>
                    <span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">history</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gen</span><span class="p">))</span>
                <span class="n">Xj</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">result</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">Xj</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">*=</span> <span class="p">(</span><span class="n">hi</span> <span class="o">-</span> <span class="n">lo</span><span class="p">)</span> <span class="o">/</span> <span class="n">nbins</span>
        <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">bins</span><span class="p">,</span> <span class="n">result</span>

    <span class="k">def</span> <span class="nf">plot_conditional</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">table</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                         <span class="n">show_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Plot a single tabulated conditional probability P(Xm|Xn).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        bins : numpy array</span>
<span class="sd">            An array of nbins+1 bin edge values where conditional</span>
<span class="sd">            probabilities are tabulated in table. Usually obtained using</span>
<span class="sd">            :meth:`tabulate_conditional`.</span>
<span class="sd">        table : numy array</span>
<span class="sd">            An array of tabulated conditional probalities.</span>
<span class="sd">            Usually obtained using :meth:`tabulate_conditional`.</span>
<span class="sd">        xlabel : str or None</span>
<span class="sd">            Label to use for the variable Xm in P(Xm|Xn).</span>
<span class="sd">        ylabel : str or None</span>
<span class="sd">            Label to use for the variable Xn in P(Xm|Xn).</span>
<span class="sd">        show_mean : bool</span>
<span class="sd">            Calculate and plot the mean &lt;Xm&gt; under P(Xm|Xn) for each Xn.</span>
<span class="sd">        ax : matplotlib axis or None</span>
<span class="sd">            Use the specified axes for drawing or the current axes.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">lo</span><span class="p">,</span> <span class="n">hi</span> <span class="o">=</span> <span class="n">bins</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bins</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">origin</span><span class="o">=</span><span class="s1">&#39;lower&#39;</span><span class="p">,</span>
                  <span class="n">extent</span><span class="o">=</span><span class="p">[</span><span class="n">lo</span><span class="p">,</span> <span class="n">hi</span><span class="p">,</span> <span class="n">lo</span><span class="p">,</span> <span class="n">hi</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">show_mean</span><span class="p">:</span>
            <span class="n">xy</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">bins</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="n">bins</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">xy</span> <span class="o">*</span> <span class="n">table</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">xy</span> <span class="p">,</span> <span class="s1">&#39;b-&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">xlabel</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">ylabel</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">plot_conditionals</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lo</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">hi</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">nbins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">nruns</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span>
                          <span class="n">which</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Plot one or more sequential conditional probabilities.</span>

<span class="sd">        The initial probability P(X1|X0) is calculated using</span>
<span class="sd">        :meth:`tabulate_conditional` and each probability is plotted using</span>
<span class="sd">        :meth:`plot_conditional`. P(Xn|X0) is calculated as P(X1|X0) ** n.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        lo : float</span>
<span class="sd">            Tabulate values of Xn and Xm on the interval [lo, hi].</span>
<span class="sd">        hi : float</span>
<span class="sd">            Tabulate values of Xn and Xm on the interval [lo, hi].</span>
<span class="sd">        nbins : int</span>
<span class="sd">            Number of bins to use for tabulated values in [lo, hi].</span>
<span class="sd">        nruns : int</span>
<span class="sd">            Number of independent runs to perform to tabulate statistics.</span>
<span class="sd">        which : iterable or ints</span>
<span class="sd">            Which conditional(s) to plot.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">bins</span><span class="p">,</span> <span class="n">T0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tabulate_conditional</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">lo</span><span class="p">,</span> <span class="n">hi</span><span class="p">,</span> <span class="n">nbins</span><span class="p">,</span> <span class="n">nruns</span><span class="p">)</span>
        <span class="n">T</span> <span class="o">=</span> <span class="n">T0</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">which</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">which</span> <span class="o">=</span> <span class="p">(</span><span class="n">which</span><span class="p">,)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">which</span><span class="p">)</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span>
            <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mf">4.2</span> <span class="o">*</span> <span class="n">n</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">squeeze</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">ylabel</span> <span class="o">=</span> <span class="s1">&#39;$X_0$&#39;</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">which</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">which</span><span class="p">:</span>
                <span class="n">xlabel</span> <span class="o">=</span> <span class="s1">&#39;$X_{{</span><span class="si">{}</span><span class="s1">}}$&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">plot_conditional</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">xlabel</span><span class="p">,</span> <span class="n">ylabel</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">idx</span><span class="p">])</span>
                <span class="n">idx</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">T</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">T0</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nsamples_per_run</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Perform a single run of the stochastic process.</span>

<span class="sd">        Calls :meth:`initial` to get the initial value then calls</span>
<span class="sd">        :meth:`update` `nsamples_per_run-1` times to complete the run.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        nsamples_per_run : int</span>
<span class="sd">            Number of samples to generate in this run, including the</span>
<span class="sd">            initial value.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        numpy array</span>
<span class="sd">            1D array of generated values, of length `nsamples_per_run`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">history</span> <span class="o">=</span> <span class="p">[</span> <span class="bp">self</span><span class="o">.</span><span class="n">initial</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">gen</span><span class="p">)</span> <span class="p">]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nsamples_per_run</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">history</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">gen</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">initial</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gen</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the initial value to use for a run.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        gen : numpy.RandomState</span>
<span class="sd">            Use this object to generate any random numbers, for reproducibility.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">            The initial value to use.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">history</span><span class="p">,</span> <span class="n">gen</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return the next value to update a run.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        history : list</span>
<span class="sd">            List of values generated so far.  Will always include at least</span>
<span class="sd">            one element (the initial value).</span>
<span class="sd">        gen : numpy.RandomState</span>
<span class="sd">            Use this object to generate any random numbers, for reproducibility.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">            The next value to use.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</pre></div>
</div>
</div>
</div>
<p>Here is a simple example of a general stochastic process implemented using the <code class="docutils literal notranslate"><span class="pre">StochasticProcess</span></code> base class just defined. We will overrive the <code class="docutils literal notranslate"><span class="pre">initial</span></code> and <code class="docutils literal notranslate"><span class="pre">update</span></code> methods in <code class="docutils literal notranslate"><span class="pre">StochasticProcess</span></code> with our specific example:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">StochasticExample</span><span class="p">(</span><span class="n">StochasticProcess</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">initial</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gen</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gen</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">history</span><span class="p">,</span> <span class="n">gen</span><span class="p">):</span>
        <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">history</span><span class="p">)</span> <span class="o">+</span> <span class="n">gen</span><span class="o">.</span><span class="n">uniform</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<p>Two useful visualizations of a stochastic process are:</p>
<ul class="simple">
<li><p>Plots of a few long runs output by the black box: how does it evolve in “time” <span class="math notranslate nohighlight">\(n\)</span>?</p></li>
<li><p>A pair plot of the first few random variables (from many short runs) for a more detailed look at short-range correlations.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">StochasticExample</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">nsamples_per_run</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">nruns</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/7a6e6e1e1f6a919a65700a3843b502937fdbf7dd02294258e6b9a07862afdc00.png" src="../../_images/7a6e6e1e1f6a919a65700a3843b502937fdbf7dd02294258e6b9a07862afdc00.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">StochasticExample</span><span class="p">()</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">nsamples_per_run</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">nruns</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">x0cut</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/0da824d68d1048d631a7419a7d236a79d1e74dbefddfb57dd8e201ef15a29fc3.png" src="../../_images/0da824d68d1048d631a7419a7d236a79d1e74dbefddfb57dd8e201ef15a29fc3.png" />
</div>
</div>
<p><em><strong><span style="color:violet">EXERCISE</span></strong></em>  For each panel of the pairplot above:</p>
<ul class="simple">
<li><p>What distribution of random variables does each panel show?</p></li>
<li><p>What correlated random variables are marginalized out, if any?</p></li>
<li><p>What conditional probability do the two colors indicate?</p></li>
<li><p>Explain how the pairplot answers the question “Are <span class="math notranslate nohighlight">\(X_3\)</span> and <span class="math notranslate nohighlight">\(X_0\)</span> independent?”, i.e. <span class="math notranslate nohighlight">\(P(X_3\mid X_0) = P(X_3)\)</span>?</p></li>
</ul>
<p>Hint: the top-left panel shows <span class="math notranslate nohighlight">\(P(X_0\mid X_0 \le 0.5)\)</span> and <span class="math notranslate nohighlight">\(P(X_0\mid X_0 &gt; 0.5)\)</span>, with no marginalization since <span class="math notranslate nohighlight">\(X_0\)</span> starts the random sequence.</p>
<p>The histograms show the distributions <span class="math notranslate nohighlight">\(P(X_n)\)</span> which are marginalized over <span class="math notranslate nohighlight">\(X_{n-1},\ldots, X_0\)</span>. The scatter plots show the joint distributions <span class="math notranslate nohighlight">\(P(X_i, X_j)\)</span> which are marginalized over <span class="math notranslate nohighlight">\(X_{n-1},\ldots, X_0\)</span> with <span class="math notranslate nohighlight">\(n = \max(i,j)\)</span> and excluding <span class="math notranslate nohighlight">\(X_{\min(i,j)}\)</span>. Note that these are distributions of random variables <span class="math notranslate nohighlight">\(X_n\)</span>, not random values <span class="math notranslate nohighlight">\(x_n\)</span>.</p>
<p>More explicitly:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(X_0)\)</span> has no correlated random variables marginalized out since it starts the sequence.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(X_1)\)</span> is marginalized over <span class="math notranslate nohighlight">\(X_0\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(X_2)\)</span> is marginalized over <span class="math notranslate nohighlight">\(X_1, X_0\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(X_3)\)</span> is marginalized over <span class="math notranslate nohighlight">\(X_2, X_1, X_0\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(X_0, X_1)\)</span> has no correlated random variables marginalized out.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(X_1, X_2)\)</span> is marginalized over <span class="math notranslate nohighlight">\(X_0\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(X_2, X_3)\)</span> is marginalized over <span class="math notranslate nohighlight">\(X_0, X_1\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(P(X_1, X_3)\)</span> is marginalized over <span class="math notranslate nohighlight">\(X_0, X_2\)</span>.</p></li>
</ul>
<p>The two colors apply the conditions <span class="math notranslate nohighlight">\(X_0 \le 0.5\)</span> and <span class="math notranslate nohighlight">\(X_0 &gt; 0.5\)</span>, so, for example:</p>
<ul class="simple">
<li><p>The <span class="math notranslate nohighlight">\((x_2, x_3)\)</span> scatter plot shows <span class="math notranslate nohighlight">\(P(X_2, X_3\mid X_0 \le 0.5)\)</span> and <span class="math notranslate nohighlight">\(P(X_2, X_3\mid X_0 &gt; 0.5)\)</span>.</p></li>
<li><p>The <span class="math notranslate nohighlight">\(x_3\)</span> histogram shows <span class="math notranslate nohighlight">\(P(X_3\mid X_0 \le 0.5)\)</span> and <span class="math notranslate nohighlight">\(P(X_3\mid X_0 &gt; 0.5)\)</span>.</p></li>
</ul>
<p>The difference between the two <span class="math notranslate nohighlight">\(x_3\)</span> histograms demonstrates that <span class="math notranslate nohighlight">\(P(X_3\mid X_0) \ne P(X_3)\)</span>, therefore <span class="math notranslate nohighlight">\(X_3\)</span> and <span class="math notranslate nohighlight">\(X_0\)</span> are <em>dependent</em>. In other words, <span class="math notranslate nohighlight">\(X_3\)</span> “remembers” <span class="math notranslate nohighlight">\(X_0\)</span>.</p>
<p>Note that dependence nearly always implies correlation, but it is possible to construct <a class="reference external" href="https://en.wikipedia.org/wiki/Uncorrelated_random_variables#Example_of_dependence_without_correlation">artificial counter-examples</a>.</p>
<hr class="docutils" />
<p>An observer watching many different sequences generated from the same black box would need to measure all these conditional probabilities to fully describe the process:
$<span class="math notranslate nohighlight">\(
P(X_0) \;,\;
P(X_1\mid X_0) \;,\;
P(X_2\mid X_1, X_0) \;,\; \ldots \;,\;
P(X_n\mid P_{n-1}, P_{n-2}\ldots, P_0) \; .
\)</span>$</p>
<p>The <span style="color:violet">equivalent Bayesian network</span> (up to <span class="math notranslate nohighlight">\(n=3\)</span>) is:</p>
<p><a class="reference internal" href="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Markov-stochastic_graph.png"><img alt="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Markov-stochastic_graph.png" class="align-left" src="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Markov-stochastic_graph.png" style="width: 400px;" /></a></img><br></p>
</section>
<section id="span-style-color-orange-markov-chain-span">
<h2><span style="color:Orange">Markov Chain</span><a class="headerlink" href="#span-style-color-orange-markov-chain-span" title="Permalink to this heading">#</a></h2>
<p>A <span style="color:violet">Markov chain</span> is a special type of stochastic process where <span class="math notranslate nohighlight">\(X_{n}\)</span> <span style="color:violet">only depends directly</span> on <span class="math notranslate nohighlight">\(X_{n-1}\)</span> and not on any earlier samples. In this case, we say that <span class="math notranslate nohighlight">\(X_n\)</span> and <span class="math notranslate nohighlight">\(X_{n-2}\)</span> are <a class="reference external" href="https://en.wikipedia.org/wiki/Conditional_independence">conditionally independent</a>.</p>
<p>In other words, a Markov chain is a black box with <span style="color:violet">very short-term memory</span>. The samples <span class="math notranslate nohighlight">\(x_0, x_1, \ldots\)</span> produced by a single run of a Markov chain are referred to as a <span style="color:violet">Markov-chain Monte Carlo (MCMC)</span>.</p>
<p>Our observer now only needs to measure:</p>
<div class="math notranslate nohighlight">
\[ \Large
P(X_0) \;,\; P(X_1\mid X_0) \;,\; P(X_2\mid X_1) \;,\; \ldots \;,\; P(X_n\mid X_{n-1}) \; .
\]</div>
<p>The <span style="color:violet">equivalent Bayesian network</span> (up to <span class="math notranslate nohighlight">\(n=3\)</span>) is:</p>
<p><a class="reference internal" href="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Markov-markov_graph.png"><img alt="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Markov-markov_graph.png" class="align-left" src="https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/Markov-markov_graph.png" style="width: 600px;" /></a></img><br></p>
<p>Random variables without a direct connection (arrow) are conditionally independent.</p>
<section id="span-style-color-lightgreen-stationary-markov-chains-span">
<h3><span style="color:Lightgreen">Stationary Markov Chains</span><a class="headerlink" href="#span-style-color-lightgreen-stationary-markov-chains-span" title="Permalink to this heading">#</a></h3>
<p>An important subset of Markov chains are <span style="color:violet">stationary</span>, which makes our observer’s job even easier since they have the property that</p>
<div class="math notranslate nohighlight">
\[ \Large
P(X_1\mid X_0) = P(X_2\mid X_1) = \ldots = P(X_n\mid X_{n-1}) \; .
\]</div>
<p>In other words, a black box with very <span style="color:violet">short-term memory</span> <strong>and</strong> <span style="color:violet">no sense of time</span>.  Our observer now only has two conditional probability distributions to measure, the initial probability,</p>
<div class="math notranslate nohighlight">
\[ \Large
P(X_0) \; ,
\]</div>
<p>and the update rule for <span class="math notranslate nohighlight">\(n\ge 1\)</span>,</p>
<div class="math notranslate nohighlight">
\[ \Large
P(X_n\mid X_{n-1}) \; .
\]</div>
<p>Here is a simple example of a stationary Markov process:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">StationaryMarkovExample</span><span class="p">(</span><span class="n">StochasticProcess</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">initial</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gen</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gen</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">history</span><span class="p">,</span> <span class="n">gen</span><span class="p">):</span>
        <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">gen</span><span class="o">.</span><span class="n">uniform</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">StationaryMarkovExample</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">nsamples_per_run</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">nruns</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/67e2da54b777ecb01c10c613db657fece49c57b70467e7ff381d23df84f1dde9.png" src="../../_images/67e2da54b777ecb01c10c613db657fece49c57b70467e7ff381d23df84f1dde9.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">StationaryMarkovExample</span><span class="p">()</span><span class="o">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">nsamples_per_run</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">nruns</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">x0cut</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/70e4fa3a2911e0cda351cb465537c00865d372e08efa1919496e7024ea1f1f02.png" src="../../_images/70e4fa3a2911e0cda351cb465537c00865d372e08efa1919496e7024ea1f1f02.png" />
</div>
</div>
<p>The pairplot above demonstrates that <span class="math notranslate nohighlight">\(X_n\)</span> and <span class="math notranslate nohighlight">\(X_0\)</span> are still dependent,</p>
<div class="math notranslate nohighlight">
\[ \Large
P(X_n\mid X_0) \ne P(X_n)
\]</div>
<p>even for a Markov process!</p>
<p>Some probability calculus shows how this happens. Take <span class="math notranslate nohighlight">\(n=2\)</span> for simplicity:</p>
<div class="math notranslate nohighlight">
\[\begin{split} \Large
\begin{aligned}
P(X_2\mid X_0) &amp;= \int dX_1\, P(X_2, X_1\mid X_0) \\
&amp;= \int dX_1\, P(X_2\mid X_1, X_0)\, P(X_1\mid X_0) \\
&amp;= \int dX_1\, P(X_2\mid X_1)\, P(X_1\mid X_0) \; ,
\end{aligned}
\end{split}\]</div>
<p>where the first two lines are completely general, but the last assumes a Markov process, <span class="math notranslate nohighlight">\(P(X_2\mid X_1, X_0) = P(X_2\mid X_1)\)</span>.  Compare this with:</p>
<div class="math notranslate nohighlight">
\[\begin{split} \Large
\begin{aligned}
P(X_2) &amp;= \int dX_1 dX_0\, P(X_2, X_1, X_0) \\
&amp;= \int dX_1 dX_0\, P(X_2\mid X_1, X_0)\, P(X_1, X_0) \\
&amp;= \int dX_1\, P(X_2\mid X_1)\, \int dX_0\, P(X_1, X_0) \\
&amp;= \int dX_1\, P(X_2\mid X_1)\, P(X_1) \; .
\end{aligned}
\end{split}\]</div>
<p>The comparison shows that <span class="math notranslate nohighlight">\(P(X_2\mid X_0) = P(X_2)\)</span> would require that <span class="math notranslate nohighlight">\(P(X_1\mid X_0) = P(X_1)\)</span>.  In other words, the direct dependence of each <span class="math notranslate nohighlight">\(X_n\)</span> on <span class="math notranslate nohighlight">\(X_{n-1}\)</span> is sufficient to generate long-range dependencies all the way back to <span class="math notranslate nohighlight">\(X_0\)</span>.</p>
<section id="span-style-color-orange-reversible-markov-chains-span">
<h4><span style="color:Orange">Reversible Markov Chains</span><a class="headerlink" href="#span-style-color-orange-reversible-markov-chains-span" title="Permalink to this heading">#</a></h4>
<p>Another important property that some Markov chains have is <strong>reversibility</strong>,</p>
<div class="math notranslate nohighlight">
\[ \Large
P(X_n\mid X_{n-1}) = P(X_{n-1}\mid X_n)
\]</div>
<p>which can also be defined in terms of forward conditional probabilities as</p>
<div class="math notranslate nohighlight">
\[ \Large
P(X_n=x\mid X_{n-1}=y) = P(X_{n+1}=y\mid X_n=x) \; ,
\]</div>
<p>and roughly corresponds to time-reversal invariance.</p>
<p><em>A <em><span style="color:Violet">reversible chain is always stationary</span></em>, but not vice versa.</em></p>
<hr class="docutils" />
<p>The update rule for a stationary Markov chain,</p>
<div class="math notranslate nohighlight">
\[ \Large
P(X_n\mid X_{n-1}) \; .
\]</div>
<p>can be conveniently visualized with a 2D plot. For example, taking <span class="math notranslate nohighlight">\(n=1\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">StationaryMarkovExample</span><span class="p">()</span><span class="o">.</span><span class="n">plot_conditionals</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/ad305c7b93e0ec2fe1a0b29336027823c705dfc61413e74f685c0366f2fa0da7.png" src="../../_images/ad305c7b93e0ec2fe1a0b29336027823c705dfc61413e74f685c0366f2fa0da7.png" />
</div>
</div>
<p>The blue line shows the mean <span class="math notranslate nohighlight">\(X_1\)</span> at each <span class="math notranslate nohighlight">\(X_0\)</span>,</p>
<div class="math notranslate nohighlight">
\[ \Large
\langle X_1\rangle = \int dX_1\, X_1\, P(X_1\mid X_0) \; .
\]</div>
<p>Note that this is essentially the <span class="math notranslate nohighlight">\((x_1, x_0)\)</span> scatter plot from above, but with samples now histogrammed to yield conditional probabilities.</p>
<p><em><strong><span style="color:Violet">DISCUSS</span></strong></em></p>
<ul class="simple">
<li><p>The speckling is due to using finite statistics to estimate the probability. How would this plot look different with infinite statistics?</p></li>
<li><p>This plot shows <span class="math notranslate nohighlight">\(P(X_1\mid X_0)\)</span>. Would <span class="math notranslate nohighlight">\(P(X_2\mid X_1)\)</span> look any different? How about <span class="math notranslate nohighlight">\(P(X_2\mid X_0)\)</span>?</p></li>
<li><p>Are these conditional probabilities normalized along <span class="math notranslate nohighlight">\(X_0\)</span>? along <span class="math notranslate nohighlight">\(X_1\)</span>?</p></li>
<li><p>How would this plot change if we changed the definition of <code class="docutils literal notranslate"><span class="pre">initial()</span></code> in <code class="docutils literal notranslate"><span class="pre">StationaryMarkovExample</span></code>?</p></li>
<li><p>What condition on this plot does a reversible Markov chain satisfy? Is this example reversible?</p></li>
</ul>
<p>With infinite statistics, the diagonal band would be a uniform color, since <span class="math notranslate nohighlight">\(P(X_1\mid X_0)\)</span> is uniform (within the diagonal limits shown) for each <span class="math notranslate nohighlight">\(X_0\)</span>.</p>
<p>A plot of <span class="math notranslate nohighlight">\(P(X_2\mid X_1)\)</span>, or any <span class="math notranslate nohighlight">\(P(X_{n+1}\mid X_n)\)</span> would look identical since this is the definition of a stationary Markov chain. However, <span class="math notranslate nohighlight">\(P(X_2\mid X_0)\)</span> involves two updates, so its plot might look different.</p>
<p>A conditional probability <span class="math notranslate nohighlight">\(P(\alpha\mid \beta)\)</span> is normalized along <span class="math notranslate nohighlight">\(\alpha\)</span>, with the value of <span class="math notranslate nohighlight">\(\beta\)</span> considered fixed. In other words, a numpy array of values <code class="docutils literal notranslate"><span class="pre">T[n,m]</span></code> tabulating <span class="math notranslate nohighlight">\(P(X_m\mid X_n)\)</span> on a grid satisfies:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
<p>This plot only shows the update rule and does not depend on how we chose an initial value for the Markov chain.</p>
<p>A reversible Markov chain has <span class="math notranslate nohighlight">\(P(X_1\mid X_0) = P(X_0\mid X_1)\)</span>, which makes this plot symmetric under the interchange of its axes. In other words, mirroring the plot along the diagonal should not change its appearance. Since this is not true in this example, <code class="docutils literal notranslate"><span class="pre">StationaryMarkovExample</span></code> is not reversible.</p>
</section>
</section>
<hr class="docutils" />
<section id="span-style-color-lightgreen-equilibrium-distributions-span">
<h3><span style="color:Lightgreen">Equilibrium Distributions</span><a class="headerlink" href="#span-style-color-lightgreen-equilibrium-distributions-span" title="Permalink to this heading">#</a></h3>
<p>Repeated use of the (same) update rule associated with a stationary Markov chain reveals a useful feature. These plots show 1, 2, 4, and 8 iterations of the same rule:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">StationaryMarkovExample</span><span class="p">()</span><span class="o">.</span><span class="n">plot_conditionals</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/eb82102a4e13491deb63f63b6360c8c307bdc25ebe7c42b6cb119c15e0e5493b.png" src="../../_images/eb82102a4e13491deb63f63b6360c8c307bdc25ebe7c42b6cb119c15e0e5493b.png" />
</div>
</div>
<p><em><strong><span style="color:Violet">NOTE: </span>:</strong></em> A stationary Markov chain eventually reaches an equilibrium <span class="math notranslate nohighlight">\(P(X_n\mid X_0) \rightarrow \tilde{P}(X_n)\)</span> that does not depend on <span class="math notranslate nohighlight">\(X_0\)</span>.</p>
<p>We saw earlier how, in general, <span class="math notranslate nohighlight">\(X_n\)</span> and <span class="math notranslate nohighlight">\(X_0\)</span> are dependent, but we now learn that stationarity tames this behavior and guarantees that <span class="math notranslate nohighlight">\(X_n\)</span> and <span class="math notranslate nohighlight">\(X_0\)</span> are independent for sufficiently large <span class="math notranslate nohighlight">\(n\)</span>.</p>
<p>We will not prove this result, but here is a less trivial example to help build the case:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">StationaryMarkovExample2</span><span class="p">(</span><span class="n">StochasticProcess</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">initial</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gen</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gen</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">history</span><span class="p">,</span> <span class="n">gen</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">fmod</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">gen</span><span class="o">.</span><span class="n">normal</span><span class="p">(),</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">StationaryMarkovExample2</span><span class="p">()</span><span class="o">.</span><span class="n">plot_conditionals</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/abf6a68abec50e5d93505ce83a85732348e95e9cd21f36ab04c758a440c10f2f.png" src="../../_images/abf6a68abec50e5d93505ce83a85732348e95e9cd21f36ab04c758a440c10f2f.png" />
</div>
</div>
<p>For practical applications, there are two issues to deal with:</p>
<ul class="simple">
<li><p>There is no way to know in advance how big <span class="math notranslate nohighlight">\(n\)</span> needs to be to achieve equilibrium.</p></li>
<li><p>Given some stationary Markov chain, we can generate samples from <em>some</em> equilibrium distribution <span class="math notranslate nohighlight">\(\tilde{P}(X_n)\)</span>, but how do we build a chain to sample a specific distribution?</p></li>
</ul>
<p>The second issue requires solving an <a class="reference external" href="https://en.wikipedia.org/wiki/Inverse_problem">inverse problem</a>, which is generally challenging. However, there is a general class of solutions that we will look at below.</p>
<p><em><strong><span style="color:Violet">EXERCISE</span></strong></em>: Define your own Markov chain, following the <code class="docutils literal notranslate"><span class="pre">StationaryMarkovExample</span></code> above, and make similar plots. Is your chain stationary? For a challenge, try to build a reversible chain.</p>
<p>The test for a stationary chain is whether it only uses <code class="docutils literal notranslate"><span class="pre">history[-1]</span></code> in its <code class="docutils literal notranslate"><span class="pre">update()</span></code> method.  The test for a reversible chain is whether its plot of <span class="math notranslate nohighlight">\(P(X_1\mid X_0)\)</span> is symmetric about the diagonal.</p>
<p>Here is an example of a reversible (and therefore stationary) Markov chain:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ReversibleMarkovExample</span><span class="p">(</span><span class="n">StochasticProcess</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">initial</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gen</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">gen</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span>
    
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">history</span><span class="p">,</span> <span class="n">gen</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">fmod</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.2</span> <span class="o">*</span> <span class="n">gen</span><span class="o">.</span><span class="n">normal</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ReversibleMarkovExample</span><span class="p">()</span><span class="o">.</span><span class="n">plot_conditionals</span><span class="p">(</span><span class="n">which</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/9fa3c2f0f5744881815220d97bc485ea8684d874fda57ddaac12e97c544a1db3.png" src="../../_images/9fa3c2f0f5744881815220d97bc485ea8684d874fda57ddaac12e97c544a1db3.png" />
</div>
</div>
<p>Note that we can use the diagonal symmetry of the first plot to confirm that this is a reversible chain.</p>
</section>
</section>
<hr class="docutils" />
<section id="span-style-color-orange-custom-markov-chain-span">
<h2><span style="color:Orange">Custom Markov Chain</span><a class="headerlink" href="#span-style-color-orange-custom-markov-chain-span" title="Permalink to this heading">#</a></h2>
<p>The <span style="color:Violet">Metropolis-Hastings-Green</span> (MHG) algorithm is a general approach to designing a custom Markov chain that has a specified target probability density, <span class="math notranslate nohighlight">\(\tilde{P}(X_n)\)</span>.  All practical algorithms are special cases of MHG:</p>
<ul class="simple">
<li><p>Metropolis-Hastings-Green</p>
<ul>
<li><p>Metropolis-Hastings</p>
<ul>
<li><p>Metropolis</p></li>
<li><p>Gibbs</p></li>
<li><p>Hamiltonian</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>The simpler <span style="color:Violet">Metropolis-Hastings</span> (MH) algorithm contains the essential ideas so we will focus on that.</p>
<p>The history of using Markov chains for practical inference is intimately connected with physics: many of the pioneers were physicists motivated by physics problems, including <a class="reference external" href="https://en.wikipedia.org/wiki/Nicholas_Metropolis">Metropolis</a> and <a class="reference external" href="https://en.wikipedia.org/wiki/Josiah_Willard_Gibbs">Gibbs</a>, and the Hamiltonian method derives from classical mechanics.</p>
<p>See this <a class="reference external" href="http://twiecki.github.io/blog/2014/01/02/visualizing-mcmc/">blog post</a> for helpful animations comparing some of these methods.</p>
<section id="span-style-color-lightgreen-metropolis-hastings-updates-span">
<h3><span style="color:Lightgreen">Metropolis-Hastings Updates</span><a class="headerlink" href="#span-style-color-lightgreen-metropolis-hastings-updates-span" title="Permalink to this heading">#</a></h3>
<p>The MH algorithm relies on a <strong>proposal distribution</strong> <span class="math notranslate nohighlight">\(Q(X_{n+1}\mid X_n)\)</span> that is easier to sample from than the target distribution <span class="math notranslate nohighlight">\(\tilde{P}(X_{n+1}\mid X_n)\)</span>.  (If you knew how to sample <span class="math notranslate nohighlight">\(P\)</span> directly, you would not need MCMC!)</p>
<p>We often use a multivariate Gaussian for <span class="math notranslate nohighlight">\(Q\)</span> since it is easy to sample from. Any proposal distribution is valid, but choosing a <span class="math notranslate nohighlight">\(Q\)</span> “closer” to <span class="math notranslate nohighlight">\(P\)</span> generally reaches the desired equilibrium faster.</p>
<p>The proposal distribution can either be used to update to the current state (“random walk”) or to generate a new state:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sample_proposal</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">gen</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">mode</span><span class="p">):</span>
    <span class="n">sample</span> <span class="o">=</span> <span class="n">gen</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x0</span> <span class="o">+</span> <span class="n">sample</span> <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;random_walk&#39;</span> <span class="k">else</span> <span class="n">sample</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_proposals</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">):</span>
    <span class="n">gen</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">((</span><span class="mf">.3</span><span class="p">,</span> <span class="mf">.1</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">xy0</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]):</span>
        <span class="n">xy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">sample_proposal</span><span class="p">(</span><span class="n">xy0</span><span class="p">,</span> <span class="n">gen</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="s1">&#39;random_walk&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">xy</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;random_walk&#39;</span><span class="p">)</span>
        <span class="n">xy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">sample_proposal</span><span class="p">(</span><span class="n">xy0</span><span class="p">,</span> <span class="n">gen</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="s1">&#39;independent&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)])</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">xy</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;independent&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">xy0</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;+&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
    
<span class="n">plot_proposals</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/613b23b9cc3fc6a326d7ea80a0754beb3e351750a107d062187599e6844d1de8.png" src="../../_images/613b23b9cc3fc6a326d7ea80a0754beb3e351750a107d062187599e6844d1de8.png" />
</div>
</div>
<p>During each update we evaluate a proposed move to <span class="math notranslate nohighlight">\(x_{n+1}\)</span> by calculating the <strong>Hastings ratio</strong>,</p>
<div class="math notranslate nohighlight">
\[ \Large
r(x_{n+1}, x_n) = \frac{\tilde{P}(x_{n+1})}{\tilde{P}(x_n)}\, \frac{Q(x_n\mid x_{n+1})}{Q(x_{n+1}\mid x_n)} \; ,
\]</div>
<p>where <span class="math notranslate nohighlight">\(\tilde{P}\)</span> is the desired equilibrium distribution. Since <span class="math notranslate nohighlight">\(\tilde{P}\)</span> only appears in a ratio, it does not need to be normalized: we saw earlier how this freedom is very useful for performing Bayesian inference, where the normalization is generally not calculable.</p>
<p>In general, the Hastings ratio is <span class="math notranslate nohighlight">\(\ge 0\)</span> but it can otherwise be arbitrarily large. We always accept a proposed move when <span class="math notranslate nohighlight">\(r(x_{n+1}, x_n) \ge 1\)</span>.  Otherwise, we accept it with a probability of <span class="math notranslate nohighlight">\(0\le r(x_{n+1}, x_n) &lt; 1\)</span>.  When a proposed move is rejected, the update returns the original value (so repetitions are possible and quite normal).</p>
<p>In practice, we work with</p>
<div class="math notranslate nohighlight">
\[ \Large
\log r(x_{n+1}, x_n) = \log \tilde{P}(x_{n+1}) - \log \tilde{P}(x_n)
+ \log Q(x_n\mid x_{n+1}) - \log Q(x_{n+1}\mid x_n)
\]</div>
<p>rather than <span class="math notranslate nohighlight">\(r(x_{n+1}, x_n)\)</span> in order to minimize the effects of round-off errors.</p>
<p>We can now build a simple custom Markov chain for an arbitrary target equilibrium distribution:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MetropolisHastings</span><span class="p">(</span><span class="n">StochasticProcess</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">Qrms</span><span class="p">,</span> <span class="n">logP</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Q</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span>
            <span class="n">mean</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x0</span><span class="p">),</span> <span class="n">cov</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">Qrms</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">x0</span><span class="p">)))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">logP</span> <span class="o">=</span> <span class="n">logP</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>
    
    <span class="k">def</span> <span class="nf">initial</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gen</span><span class="p">):</span>
        <span class="c1"># Start from the origin.</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">x0</span>
    
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">history</span><span class="p">,</span> <span class="n">gen</span><span class="p">):</span>
        <span class="n">x0</span> <span class="o">=</span> <span class="n">history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># Sample the proposal distribution Q to generate x1 and calculate</span>
        <span class="c1"># the log of the proposal ratio.</span>
        <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Q</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">gen</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;random_walk&#39;</span><span class="p">:</span>
            <span class="n">x1</span> <span class="o">=</span> <span class="n">x0</span> <span class="o">+</span> <span class="n">sample</span>
            <span class="n">log_Q_ratio</span> <span class="o">=</span> <span class="mf">0.</span> <span class="c1"># self.Q.logpdf(x0-x1) - self.Q.logpdf(x1-x0)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">x1</span> <span class="o">=</span> <span class="n">sample</span>
            <span class="n">log_Q_ratio</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Q</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">Q</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
        <span class="c1"># Calculate log of the Hastings ratio.</span>
        <span class="n">log_ratio</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">logP</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">logP</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span> <span class="o">+</span> <span class="n">log_Q_ratio</span>
        <span class="c1"># Accept x1 or keep x0?</span>
        <span class="k">if</span> <span class="n">log_ratio</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">accept_prob</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_ratio</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">x1</span> <span class="k">if</span> <span class="n">gen</span><span class="o">.</span><span class="n">uniform</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">accept_prob</span> <span class="k">else</span> <span class="n">x0</span>
</pre></div>
</div>
</div>
</div>
<p><em><strong><span style="color:Violet">EXERCISE</span></strong></em>: Define the un-normalized PDF for samples that are uniformly distributed within a (hyper)cube spanning <span class="math notranslate nohighlight">\([-1,+1]\)</span> along each axis:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">logP</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">1.</span> <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>
</pre></div>
</div>
</div>
</div>
<p>Generate samples in 2D using a 2D Gaussian with zero mean and unit variance for the proposal distribution <span class="math notranslate nohighlight">\(Q\)</span>. Use the following utiliity function to make a scatter plot of the results using:</p>
<ul class="simple">
<li><p>color to indicate the last position <span class="math notranslate nohighlight">\(n\)</span> in the chain,</p></li>
<li><p>a superimposed plus (<span class="math notranslate nohighlight">\(+\)</span>) to indicate samples repeated twice,</p></li>
<li><p>a superimposed asterisk (<span class="math notranslate nohighlight">\(\ast\)</span>) to indicate samples repeated three or more times,</p></li>
<li><p>a larger circle to indicate the initial position, and</p></li>
<li><p>a dashed box showing the boundary of the target (square) distribution.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_square</span><span class="p">(</span><span class="n">xy</span><span class="p">):</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
    <span class="n">xy_unique</span><span class="p">,</span> <span class="n">xy_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">xy</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">return_counts</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">repeated</span> <span class="o">=</span> <span class="n">xy_counts</span> <span class="o">&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">xy</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">xy</span><span class="p">)),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gist_rainbow&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">xy</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">s</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">edgecolors</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">facecolors</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">xy_unique</span><span class="p">[</span><span class="n">repeated</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;+&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">xy_unique</span><span class="p">[</span><span class="n">repeated</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Chain has </span><span class="si">{}</span><span class="s1"> / </span><span class="si">{}</span><span class="s1"> unique samples with </span><span class="si">{}</span><span class="s1"> repeated&#39;</span>
                 <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">xy_unique</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">xy</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">repeated</span><span class="p">[</span><span class="mi">1</span><span class="p">])),</span> <span class="n">fontsize</span><span class="o">=</span><span class="s1">&#39;x-large&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">1.1</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">);</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">1.1</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">add_artist</span><span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">Rectangle</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_square</span><span class="p">(</span><span class="n">MetropolisHastings</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="mf">1.</span><span class="p">,</span> <span class="n">logP</span><span class="p">,</span> <span class="s1">&#39;random_walk&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="mi">500</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/72169a4ef848da1802655e5c31e8a124352616d3618d51522180f8619ee93639.png" src="../../_images/72169a4ef848da1802655e5c31e8a124352616d3618d51522180f8619ee93639.png" />
</div>
</div>
<p>Note that the unique points in the sample do cover the square uniformly and there is no obvious imprint of the Gaussian proposal distribution. However, there are also many repetitions and, more generally, successive points are highly correlated with each other.</p>
<p>The example above worked out reasonably well, but there are many pitfalls with the MH algorithm, some obvious and others more subtle:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_square</span><span class="p">(</span><span class="n">MetropolisHastings</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">logP</span><span class="p">,</span> <span class="s1">&#39;independent&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="mi">500</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/da8f93ecb4b29ee90daefe20f491cfe87ae30fd35cb75667c952fad609c7e7eb.png" src="../../_images/da8f93ecb4b29ee90daefe20f491cfe87ae30fd35cb75667c952fad609c7e7eb.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_square</span><span class="p">(</span><span class="n">MetropolisHastings</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="mf">0.05</span><span class="p">,</span> <span class="n">logP</span><span class="p">,</span> <span class="s1">&#39;random_walk&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="mi">500</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/e32c131561e086516bc5257e688d1bd173e66fb420ea24ecb1179401ef5a15eb.png" src="../../_images/e32c131561e086516bc5257e688d1bd173e66fb420ea24ecb1179401ef5a15eb.png" />
</div>
</div>
<p><em><strong><span style="color:Violet">EXERCISE</span></strong></em>: Study the two examples above and describe how and why they are failing to sample the desired target distribution. Do the locations of repeated samples make sense?</p>
<p>The first example uses independent updates with a proposal distribution that is too narrow (<span class="math notranslate nohighlight">\(\sigma = 0.3\)</span>) to sample the edges of the box efficiently.  As a result, points far from the initial point (the origin) are repeated often and the chain would need to be much longer to populate the corners. Note that, although the density of samples is higher close to the origin, when weighted by the number of repetitions, the generated chain correctly samples the target (flat) distribution.</p>
<p>The second example use random-walk updates with a proposal distribution that is much narrower than the target (<span class="math notranslate nohighlight">\(\sigma = 0.05\)</span>) so tends to explore the target space slowly with long range correlations between samples. We have effectively simulated the <a class="reference external" href="https://en.wikipedia.org/wiki/Brownian_motion">Brownian motion</a> of a particle in a 2D fluid. With a long enough chain, our particle will explore the full square, spending about the same amount of time in each part of it, but this is not true of shorter sections of the chain. Note how repeated samples occur only at the edges of square, where there is a high probability of a proposed sample falling outside the square and therefore being rejected.</p>
<p>Both of these examples are “correct” implementations of MH updates, but also have peculiar features that you might care about when using MCMC for pratical work. The lesson is that you should generally not assume that an MCMC chain has any desirable properties beyond its minimum guarantee of asymptotically sampling <span class="math notranslate nohighlight">\(\tilde{P}(X_n)\)</span>.</p>
<hr class="docutils" />
<p>When the proposal distribution <span class="math notranslate nohighlight">\(Q\)</span> is reversible, it cancels in the Hastings ratio,</p>
<div class="math notranslate nohighlight">
\[ \Large
r(x_{n+1}, x_n) = \frac{\tilde{P}(x_{n+1})}{\tilde{P}(x_n)}\, \frac{Q(x_n\mid x_{n+1})}{Q(x_{n+1}\mid x_n)} \;\rightarrow\; \frac{\tilde{P}(x_{n+1})}{\tilde{P}(x_n)} \; .
\]</div>
<p>The resulting <span style="color:Violet">Metropolis updates</span> are a special case of MH updates and eliminate the need to evaluate <span class="math notranslate nohighlight">\(Q\)</span>.</p>
</section>
<section id="span-style-color-lightgreen-gibbs-sampling-span">
<h3><span style="color:Lightgreen">Gibbs Sampling</span><a class="headerlink" href="#span-style-color-lightgreen-gibbs-sampling-span" title="Permalink to this heading">#</a></h3>
<p>When sampling a multidimensional target distribution <span class="math notranslate nohighlight">\(\tilde{P}\)</span>, some additional constraints on <span class="math notranslate nohighlight">\(\tilde{P}\)</span>, allow us to exploit a different special case of MH updates and are the basis of <span style="color:Violet">Gibbs sampling</span>.</p>
<p>For example, suppose we want to sample in 3D from <span class="math notranslate nohighlight">\(\tilde{P}(x, y, z)\)</span>, then Gibbs updates require that we can sample from each of the 1D conditional distributions:</p>
<div class="math notranslate nohighlight">
\[ \Large
\tilde{P}(x\mid y, z) \quad ,\quad
\tilde{P}(y\mid x, z) \quad ,\quad
\tilde{P}(z\mid x, y) \; .
\]</div>
<p>This condition is trivially satisfied when the random variables are mutually independent,</p>
<div class="math notranslate nohighlight">
\[ \Large
\tilde{P}(x,y,z) = P_X(x) P_Y(y) P_Z(z) \; ,
\]</div>
<p>but is more useful in cases where this is not true and simpler alternative methods are not available.</p>
<p>The rules for a single Gibbs update starting from sample <span class="math notranslate nohighlight">\((x_{n-1}, y_{n-1}, z_{n-1})\)</span> are:</p>
<ul class="simple">
<li><p>Sample <span class="math notranslate nohighlight">\(x_n\)</span> from <span class="math notranslate nohighlight">\(\tilde{P}(x\mid y_{n-1}, z_{n-1})\)</span></p></li>
<li><p>Sample <span class="math notranslate nohighlight">\(y_n\)</span> from <span class="math notranslate nohighlight">\(\tilde{P}(y\mid x_n, z_{n-1})\)</span></p></li>
<li><p>Sample <span class="math notranslate nohighlight">\(z_n\)</span> from <span class="math notranslate nohighlight">\(\tilde{P}(z\mid x_n, y_n)\)</span></p></li>
<li><p>Accept the new sample <span class="math notranslate nohighlight">\((x_n, y_n, z_n)\)</span> with probability one (!)</p></li>
</ul>
<p>We will not prove the correctness of this approach, but the key insight is that each sub-step samples from a conditional PDF that is proportional to the full joint PDF, for example:</p>
<div class="math notranslate nohighlight">
\[ \Large
\tilde{P}(y\mid x, z) = \frac{\tilde{P}(x, y, z)}{\tilde{P}(x, z)} \propto \tilde{P}(x, y, z) \; .
\]</div>
<p>The 3D example above generalizes in the obvious way to higher dimensions.</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Gibbs_sampling">Gibbs sampling</a> places extra conditions on <span class="math notranslate nohighlight">\(\tilde{P}\)</span>, so is not a general-purpose algorithm, but is efficient and eliminates repeated samples when its conditions are met.  Gibbs sampling is often a good fit to target distributions that can be expressed using a graphical model with few dependencies.</p>
</section>
<section id="span-style-color-lightgreen-hamiltonian-sampling-span">
<h3><span style="color:Lightgreen">Hamiltonian Sampling</span><a class="headerlink" href="#span-style-color-lightgreen-hamiltonian-sampling-span" title="Permalink to this heading">#</a></h3>
<p>Another special case of MH sampling requires that we can calculate all partial derivatives of our target <span class="math notranslate nohighlight">\(\log\tilde{P}\)</span>,</p>
<div class="math notranslate nohighlight">
\[ \Large
\frac{\partial}{\partial z_i}\, \log\tilde{P}(\vec{x}) \; .
\]</div>
<p>The resulting <strong>Hamiltonian sampling</strong> method relies on a nifty physics analogy.</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Hamiltonian_mechanics">Recall</a> that the equations of motion for a classical system of particles with Hamiltonian <span class="math notranslate nohighlight">\(H\)</span> are:</p>
<div class="math notranslate nohighlight">
\[ \Large
\frac{dq_i}{dt} = + \frac{\partial H}{\partial p_i} \quad , \quad
\frac{dp_i}{dt} = - \frac{\partial H}{\partial q_i} \; ,
\]</div>
<p>where <span class="math notranslate nohighlight">\(q_i\)</span> and <span class="math notranslate nohighlight">\(p_i\)</span> are (generalized) position and momentum coordinates for particle <span class="math notranslate nohighlight">\(i\)</span>.</p>
<p>We identify <span class="math notranslate nohighlight">\(H\)</span> with the total energy of the system and can often split it into separate kinetic and potential terms,</p>
<div class="math notranslate nohighlight">
\[ \Large
H(q,p) = K(p) + U(q) \; ,
\]</div>
<p>where, generically,</p>
<div class="math notranslate nohighlight">
\[ \Large
K(p) = \sum_i\, \frac{p_i^2}{2 m_i} \; ,
\]</div>
<p>with particle “masses” <span class="math notranslate nohighlight">\(m_i\)</span>, and <span class="math notranslate nohighlight">\(U(q)\)</span> encapsulates all the specifics of a particular system. Using this split, we can simplify the equations of motion to:</p>
<div class="math notranslate nohighlight">
\[ \Large
\frac{dq_i}{dt} = +\frac{p_i}{m_i} \quad ,\quad \frac{dp_i}{dt} = -\frac{\partial U}{\partial q_i} \; .
\]</div>
<p>We turn Hamiltonian dynamics into a stationary Markov chain with the following recipe:</p>
<ul class="simple">
<li><p>Identify positions <span class="math notranslate nohighlight">\(q_i\)</span> with the random variables we wish to sample.</p></li>
<li><p>Create new random variables <span class="math notranslate nohighlight">\(p_i\)</span> for the corresponding momenta. We will treat these as nuisance parameters, but this does not look promising since we just doubled the dimension of our sampling space!</p></li>
<li><p>Assign fixed (arbitrary) masses <span class="math notranslate nohighlight">\(m_i\)</span> to each “particle”.</p></li>
<li><p>Use <span class="math notranslate nohighlight">\(U(q) = -\log\tilde{P}(q)\)</span> for our “potential energy”.</p></li>
</ul>
<p>Plugging <span class="math notranslate nohighlight">\(U(q) = -\log\tilde{P}(q)\)</span> into the <span class="math notranslate nohighlight">\(dp_i/dt\)</span> equation of motion above reveals why we need to be able to calculate partial derivatives of <span class="math notranslate nohighlight">\(\log\tilde{P}\)</span>.</p>
<p>A single Hamiltonian Monte Carlo (HMC) update then consists of:</p>
<ul class="simple">
<li><p>Pick a random starting point in <span class="math notranslate nohighlight">\((q, p)\)</span> space, to specify the initial conditions for our “particles”.</p></li>
<li><p>Follow the evolution of our “particles” for some fixed time interval using Hamiltonian dynamics.</p></li>
<li><p>Use the final positions of our “particles” as a new sample added to the chain.</p></li>
</ul>
<p>How does this sample the target <span class="math notranslate nohighlight">\(\tilde{P}(q)\)</span>? The answer comes from statistical mechanics, which tells us that the probability that our system of particles is in a state with positions <span class="math notranslate nohighlight">\(q\)</span> is given by the <a class="reference external" href="https://en.wikipedia.org/wiki/Canonical_ensemble">canonical distribution</a>:</p>
<div class="math notranslate nohighlight">
\[ \Large
P(q) \propto \exp\left( -\frac{U(q)}{k_B T} \right) \; ,
\]</div>
<p>where <span class="math notranslate nohighlight">\(k_B\)</span> is Boltzmann’s constant and <span class="math notranslate nohighlight">\(T\)</span> is the system’s absolute temperature.</p>
<p>In practice, you can usually set <span class="math notranslate nohighlight">\(k_B T = 1\)</span> and all masses <span class="math notranslate nohighlight">\(m_i = 1\)</span> and this works surprisingly well!  The disadvantages of this approach are that:</p>
<ul class="simple">
<li><p>It is relatively complex to implement, compared with the much simpler (and general purpose) MH sampling, so let someone else do this work for you.</p></li>
<li><p>It requires that you can evaluate all the necessary partial derivatives of your target <span class="math notranslate nohighlight">\(\tilde{P}\)</span>.</p></li>
</ul>
<p>However, the main advantage is that HMC can often explore the target space much more efficiently than other methods, since it uses the additional information provided by the derivatives.  We will soon discuss computational graphs, which are a general-purpose framework for automating the necessary derivate calculations.</p>
<p>See this <a class="reference external" href="http://arogozhnikov.github.io/2016/12/19/markov_chain_monte_carlo.html">blog post</a> for a more detailed explanation of HMC with some helpful interactive visualizations.</p>
</section>
</section>
<section id="span-style-color-orange-practical-advice-span">
<h2><span style="color:Orange">Practical Advice</span><a class="headerlink" href="#span-style-color-orange-practical-advice-span" title="Permalink to this heading">#</a></h2>
<p>It is tempting to assume that MCMC samples have desirable properties beyond their minimum guarantees, since this is often true, but avoid this temptation.</p>
<p>In particular, MCMC samples are only guaranteed to sample your target <span class="math notranslate nohighlight">\(\tilde{P}(X_n)\)</span> for <span class="math notranslate nohighlight">\(n\)</span> sufficiently large. Therefore:</p>
<ul class="simple">
<li><p>There is no way to know how big <span class="math notranslate nohighlight">\(n\)</span> needs to be for a particular <span class="math notranslate nohighlight">\(\tilde{P}\)</span>.</p>
<ul>
<li><p><em><strong><span style="color:Violet">Burn-in?</span></strong></em> Should I throw away the first <span class="math notranslate nohighlight">\(B\)</span> samples to ensure that my chain is independent of its initial starting point?</p></li>
<li><p><em><strong><span style="color:LightGreen">No:</span></strong></em> There is no practical way to know how big <span class="math notranslate nohighlight">\(B\)</span> should be. Instead, ensure that your starting point is reasonably probable (according to <span class="math notranslate nohighlight">\(\tilde{P}\)</span>) and use all samples. If you do not know how to chose a reasonably probable starting point, you need to solve a separate optimization problem before you are ready to use MCMC (which is notoriously inefficient at discovering new regions of high probability).</p></li>
</ul>
</li>
<li><p>There are no useful guarantees about <span class="math notranslate nohighlight">\(\tilde{P}(X_n, X_m)\)</span> and, in general, you should assume that the consecutive samples in any stretch of the chain are highly correlated.</p>
<ul>
<li><p><em><strong><span style="color:Violet">Thinning?</span></strong></em> Should I just keep every <span class="math notranslate nohighlight">\(T\)</span>-th sample so that my chain is uncorrelated?</p></li>
<li><p><em><strong><span style="color:LightGreen">No:</span></strong></em> There is no practical way to know in advance how big <span class="math notranslate nohighlight">\(T\)</span> should be, and you can never get a better answer (for a fixed amount of computation) by throwing away valid information. Just accept that samples are correlated.</p></li>
</ul>
</li>
</ul>
<p>How long should your chain be?  You should ideally use empirical measurements to determine <span class="math notranslate nohighlight">\(k\)</span> such that the <a class="reference external" href="https://en.wikipedia.org/wiki/Autocorrelation">autocorrelation</a></p>
<div class="math notranslate nohighlight">
\[ \Large
\frac{\langle (X_{n+k} - \mu) (X_n - \mu)\rangle}{\sigma^2} \simeq 0 \; ,
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> are the long-term mean and standard deviation of <span class="math notranslate nohighlight">\(\tilde{P}(X_n)\)</span>, then generate a chain whose length is at least 10-100 times this <a class="reference external" href="https://en.wikipedia.org/wiki/Autocorrelation">autocorrelation</a> length <span class="math notranslate nohighlight">\(k\)</span>.</p>
<p>Which update rule should you use?</p>
<ul class="simple">
<li><p>Determine which special cases apply to your target <span class="math notranslate nohighlight">\(\tilde{P}\)</span>, so you know which algorithms are possible.</p>
<ul>
<li><p>Can you sample from a complete set of conditional distributions?  If so, add Gibbs sampling to your list.</p></li>
<li><p>Can you compute all partial derivatives? If so, add HMC to your list.</p></li>
</ul>
</li>
<li><p>There is no “best” algorithm, so you will need to benchmark your problem against the available methods.</p></li>
</ul>
<p>Although it is instructive (and fun!) to implement simple update rules yourself, for serious work you should generally let someone else do the hard work for you by using an existing package.</p>
<p>Which package should you use?</p>
<ul class="simple">
<li><p>For initial exploratory work, start with <a class="reference external" href="http://dfm.io/emcee/">emcee</a>, which implements <a class="reference external" href="http://dx.doi.org/10.2140/camcos.2010.5.65">ensemble sampling</a> where many independent “walkers” simultaneously crawl around your target space, and has a nice <a class="reference external" href="https://en.wikipedia.org/wiki/Affine_geometry">affine invariance</a> property, where the efficiency is not affected by any linear (aka “affine”) transformation of your target space.</p></li>
<li><p>Look into <a class="reference external" href="http://docs.pymc.io/notebooks/getting_started.html">PyMC3</a> or <a class="reference external" href="http://edwardlib.org/">Edward</a> to explore HMC and other more advanced updating rules. These are generally more complex to use and have rigid rules for specifying your target <span class="math notranslate nohighlight">\(\tilde{P}\)</span>.</p></li>
<li><p>Consider an alternative approximate method for Bayesian inference, such as <a class="reference external" href="https://en.wikipedia.org/wiki/Variational_Bayesian_methods">variational inference</a>, with different tradeoffs.</p></li>
</ul>
<p>This <a class="reference external" href="http://twiecki.github.io/blog/2013/09/23/emcee-pymc/">blog post</a> compares emcee and PyMC3.</p>
<p>You will see examples of performing MCMC and variational inference with <a class="reference external" href="http://edwardlib.org/">Edward</a> soon.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./_sources/lectures"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../Week_07.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span style="color: blue;"><b>Stochastic Processes, Markov Chains &amp; Variational Inference</b></span></p>
      </div>
    </a>
    <a class="right-next"
       href="Variational.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Variational Inference</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-stochastic-processes-span"><span style="color:Orange">Stochastic Processes</span></a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-markov-chain-span"><span style="color:Orange">Markov Chain</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-stationary-markov-chains-span"><span style="color:Lightgreen">Stationary Markov Chains</span></a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-reversible-markov-chains-span"><span style="color:Orange">Reversible Markov Chains</span></a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-equilibrium-distributions-span"><span style="color:Lightgreen">Equilibrium Distributions</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-custom-markov-chain-span"><span style="color:Orange">Custom Markov Chain</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-metropolis-hastings-updates-span"><span style="color:Lightgreen">Metropolis-Hastings Updates</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-gibbs-sampling-span"><span style="color:Lightgreen">Gibbs Sampling</span></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-lightgreen-hamiltonian-sampling-span"><span style="color:Lightgreen">Hamiltonian Sampling</span></a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#span-style-color-orange-practical-advice-span"><span style="color:Orange">Practical Advice</span></a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Mark Neubauer
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>