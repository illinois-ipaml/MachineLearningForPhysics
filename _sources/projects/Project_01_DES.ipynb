{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PHYS 503: Project 1 - Dark Energy Survey"
      ],
      "metadata": {
        "id": "V5ppSGgISDAy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <span style=\"color:Orange\">Overview</span>\n",
        "\n",
        "The standard model of the universe, the $Λ$-CDM model, estimates that around 70% of the total energy-matter density of the universe is in the form of dark energy. The primary effect of dark energy is to acceleratingly expand the universe, hence measuring it accurately is vital to our understanding of the universe.\n",
        "\n",
        "The Dark Energy Survey (DES) is an internationally collaborative large sky survey to map hundreds of millions of galaxies, detect thousands of supernovae, and find patterns of cosmic structure to better understand dark energy and the measure the cosmic acceleration of our expanding universe with high precision.\n",
        "\n",
        "The instrument used by DES is the Dark Energy Camera (DECam), which is mounted on the Victor M. Blanco 4-meter Telescope at the Cerro Tololo Inter-American Observatory (CTIO) in the Chilean Andes. DECam has several major components: five optical lenses, a Hexapod positioning and alignment system, a shutter, a set of color filters, and a digital imager."
      ],
      "metadata": {
        "id": "1jeD_lEeqLBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <span style=\"color:Orange\">Data Sources</span>\n",
        "\n",
        "This project is based on the Data Release 1 (DR1) of the DES. We will use the `des_dr1.main` table directly from NOIRLAB's Astro Data Lab server which catalogs the DES data releases.\n",
        "\n",
        "NOIRLAB's Astro Data Lab: https://urldefense.com/v3/__https://datalab.noirlab.edu/des/access.php__;!!DZ3fjg!-VVx5uQqQ6ZzOgr-EjFgoLc8lr9NMhNBQvahQLwOY5HAZ8lWfzbxhbpxn8e7OlM44QFoWvd5J20qKEVxC4I$ "
      ],
      "metadata": {
        "id": "SprcSrHttoNZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <span style=\"color:Orange\">Importing and Setup</span>\n",
        "\n",
        "You will need to install and import the `astro-datalab` module for data acquisition.\n",
        "\n",
        "Please note, you will have to restart runtime to run your code after pip installing the `astro-datalab` module."
      ],
      "metadata": {
        "id": "Vdwb8eSyOvac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --ignore-installed --no-cache-dir astro-datalab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://urldefense.com/v3/__https://localhost:8080/__;!!DZ3fjg!-VVx5uQqQ6ZzOgr-EjFgoLc8lr9NMhNBQvahQLwOY5HAZ8lWfzbxhbpxn8e7OlM44QFoWvd5J20qdHydWeg$ ",
          "height": 1000
        },
        "id": "-6IF5tyhOmw5",
        "outputId": "e16ec388-db61-4f1f-d433-57f444045dc0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting astro-datalab\n",
            "  Downloading astro_datalab-2.20.1-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.3/200.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests>=2.7 (from astro-datalab)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httplib2 (from astro-datalab)\n",
            "  Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy>=1.13 (from astro-datalab)\n",
            "  Downloading numpy-1.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting astropy (from astro-datalab)\n",
            "  Downloading astropy-5.3.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyvo (from astro-datalab)\n",
            "  Downloading pyvo-1.4.2-py3-none-any.whl (888 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m888.9/888.9 kB\u001b[0m \u001b[31m131.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib (from astro-datalab)\n",
            "  Downloading matplotlib-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m122.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas (from astro-datalab)\n",
            "  Downloading pandas-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycurl-requests (from astro-datalab)\n",
            "  Downloading pycurl_requests-0.5.0-py3-none-any.whl (30 kB)\n",
            "Collecting specutils (from astro-datalab)\n",
            "  Downloading specutils-1.12.0-py3-none-any.whl (203 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m196.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<4,>=2 (from requests>=2.7->astro-datalab)\n",
            "  Downloading charset_normalizer-3.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m153.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna<4,>=2.5 (from requests>=2.7->astro-datalab)\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m132.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<3,>=1.21.1 (from requests>=2.7->astro-datalab)\n",
            "  Downloading urllib3-2.0.7-py3-none-any.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 kB\u001b[0m \u001b[31m156.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi>=2017.4.17 (from requests>=2.7->astro-datalab)\n",
            "  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m186.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyerfa>=2.0 (from astropy->astro-datalab)\n",
            "  Downloading pyerfa-2.0.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.5/739.5 kB\u001b[0m \u001b[31m207.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyYAML>=3.13 (from astropy->astro-datalab)\n",
            "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.5/705.5 kB\u001b[0m \u001b[31m205.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=19.0 (from astropy->astro-datalab)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m127.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2->astro-datalab)\n",
            "  Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m169.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting contourpy>=1.0.1 (from matplotlib->astro-datalab)\n",
            "  Downloading contourpy-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.7/301.7 kB\u001b[0m \u001b[31m206.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler>=0.10 (from matplotlib->astro-datalab)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib->astro-datalab)\n",
            "  Downloading fonttools-4.43.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m130.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib->astro-datalab)\n",
            "  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow>=6.2.0 (from matplotlib->astro-datalab)\n",
            "  Downloading Pillow-10.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.7 (from matplotlib->astro-datalab)\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m196.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz>=2020.1 (from pandas->astro-datalab)\n",
            "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.5/502.5 kB\u001b[0m \u001b[31m200.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tzdata>=2022.1 (from pandas->astro-datalab)\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m148.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycurl (from pycurl-requests->astro-datalab)\n",
            "  Downloading pycurl-7.45.2.tar.gz (234 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.2/234.2 kB\u001b[0m \u001b[31m161.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting chardet (from pycurl-requests->astro-datalab)\n",
            "  Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m142.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy>=1.3 (from specutils->astro-datalab)\n",
            "  Downloading scipy-1.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gwcs>=0.18 (from specutils->astro-datalab)\n",
            "  Downloading gwcs-0.19.0-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.4/110.4 kB\u001b[0m \u001b[31m149.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asdf-astropy>=0.3 (from specutils->astro-datalab)\n",
            "  Downloading asdf_astropy-0.4.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.1/73.1 kB\u001b[0m \u001b[31m143.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asdf>=2.14.4 (from specutils->astro-datalab)\n",
            "  Downloading asdf-3.0.0-py3-none-any.whl (955 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m955.8/955.8 kB\u001b[0m \u001b[31m138.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ndcube>=2.0 (from specutils->astro-datalab)\n",
            "  Downloading ndcube-2.1.3-py3-none-any.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.0/124.0 kB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asdf-standard>=1.0.1 (from asdf>=2.14.4->specutils->astro-datalab)\n",
            "  Downloading asdf_standard-1.0.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.8/71.8 kB\u001b[0m \u001b[31m146.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asdf-transform-schemas>=0.3 (from asdf>=2.14.4->specutils->astro-datalab)\n",
            "  Downloading asdf_transform_schemas-0.4.0-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m274.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asdf-unit-schemas>=0.1 (from asdf>=2.14.4->specutils->astro-datalab)\n",
            "  Downloading asdf_unit_schemas-0.1.0-py3-none-any.whl (11 kB)\n",
            "Collecting importlib-metadata>=4.11.4 (from asdf>=2.14.4->specutils->astro-datalab)\n",
            "  Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
            "Collecting jmespath>=0.6.2 (from asdf>=2.14.4->specutils->astro-datalab)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting semantic-version>=2.8 (from asdf>=2.14.4->specutils->astro-datalab)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting attrs>=20.1.0 (from asdf>=2.14.4->specutils->astro-datalab)\n",
            "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m129.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asdf-coordinates-schemas>=0.1 (from asdf-astropy>=0.3->specutils->astro-datalab)\n",
            "  Downloading asdf_coordinates_schemas-0.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting asdf-wcs-schemas (from gwcs>=0.18->specutils->astro-datalab)\n",
            "  Downloading asdf_wcs_schemas-0.2.0-py3-none-any.whl (30 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib->astro-datalab)\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting zipp>=0.5 (from importlib-metadata>=4.11.4->asdf>=2.14.4->specutils->astro-datalab)\n",
            "  Downloading zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
            "Building wheels for collected packages: pycurl\n",
            "  Building wheel for pycurl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycurl: filename=pycurl-7.45.2-cp310-cp310-linux_x86_64.whl size=310477 sha256=2d024bbf79a1df481d4f57964fe03cab397416f4ade85de4e2269bb4c682924d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-a8v9z4zc/wheels/c7/41/22/c9eb70fde387ea0f16531256570754671f9c8571571982a4c0\n",
            "Successfully built pycurl\n",
            "Installing collected packages: pytz, zipp, urllib3, tzdata, six, semantic-version, PyYAML, pyparsing, pycurl, pillow, packaging, numpy, kiwisolver, jmespath, idna, fonttools, cycler, charset-normalizer, chardet, certifi, attrs, asdf-standard, scipy, requests, python-dateutil, pyerfa, pycurl-requests, importlib-metadata, httplib2, contourpy, asdf-unit-schemas, asdf-transform-schemas, pandas, matplotlib, astropy, asdf-wcs-schemas, asdf, pyvo, asdf-coordinates-schemas, asdf-astropy, gwcs, ndcube, specutils, astro-datalab\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.26.1 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.1.1 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.26.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyYAML-6.0.1 asdf-3.0.0 asdf-astropy-0.4.0 asdf-coordinates-schemas-0.2.0 asdf-standard-1.0.3 asdf-transform-schemas-0.4.0 asdf-unit-schemas-0.1.0 asdf-wcs-schemas-0.2.0 astro-datalab-2.20.1 astropy-5.3.4 attrs-23.1.0 certifi-2023.7.22 chardet-5.2.0 charset-normalizer-3.3.0 contourpy-1.1.1 cycler-0.12.1 fonttools-4.43.1 gwcs-0.19.0 httplib2-0.22.0 idna-3.4 importlib-metadata-6.8.0 jmespath-1.0.1 kiwisolver-1.4.5 matplotlib-3.7.1 ndcube-2.1.3 numpy-1.23.5 packaging-23.2 pandas-1.5.3 pillow-10.1.0 pycurl-7.45.2 pycurl-requests-0.5.0 pyerfa-2.0.1.1 pyparsing-3.1.1 python-dateutil-2.8.2 pytz-2023.3.post1 pyvo-1.4.2 requests-2.31.0 scipy-1.11.3 semantic-version-2.10.0 six-1.16.0 specutils-1.12.0 tzdata-2023.3 urllib3-2.0.7 zipp-3.17.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "certifi",
                  "cycler",
                  "dateutil",
                  "httplib2",
                  "kiwisolver",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "from sklearn import cluster\n",
        "%matplotlib inline\n",
        "\n",
        "# Data Lab imports\n",
        "from dl import queryClient as qc, storeClient as sc\n",
        "from dl.helpers.utils import convert"
      ],
      "metadata": {
        "id": "0UBSoU8nO567"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <span style=\"color:Orange\">Questions</span>"
      ],
      "metadata": {
        "id": "bVGeqweYvvh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <span style=\"color:LightGreen\">Question 01</span>\n",
        "\n",
        " What is the Dark Energy Survey? What are it's main goals? What part of the night sky does the DES cover?"
      ],
      "metadata": {
        "id": "rYEE9PEHw772"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <span style=\"color:LightGreen\">Question 02</span>\n",
        "\n",
        "Read the DES DR1 paper [[1]](https://urldefense.com/v3/__https://arxiv.org/abs/1801.03181__;!!DZ3fjg!-VVx5uQqQ6ZzOgr-EjFgoLc8lr9NMhNBQvahQLwOY5HAZ8lWfzbxhbpxn8e7OlM44QFoWvd5J20qch77Aqg$ ). What are the four completementary measurements that DES does to probe the universe? To achieve these goals, what surveys in which wave bands does DES conduct?"
      ],
      "metadata": {
        "id": "-F8WubbKzlP6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <span style=\"color:LightGreen\">Question 03</span>\n",
        "\n",
        "What is variable or feature of the data does DES use to classify its' objects  morphologically (stars or galaxies), as described in the DR1 paper [[1]](https://urldefense.com/v3/__https://arxiv.org/abs/1801.03181)?__;!!DZ3fjg!-VVx5uQqQ6ZzOgr-EjFgoLc8lr9NMhNBQvahQLwOY5HAZ8lWfzbxhbpxn8e7OlM44QFoWvd5J20q1fa89Js$ "
      ],
      "metadata": {
        "id": "FLM_25pxyXVI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <span style=\"color:Orange\">Accessing Data from Data Lab</span>\n",
        "\n",
        "Below is a sample query statement to acquire the relevant data of the `des_dr1.main` table from Astro Data Lab [[2]](https://urldefense.com/v3/__https://github.com/astro-datalab/notebooks-latest/blob/master/03_ScienceExamples/StarGalQSOSeparation/StarGalQsoDESDR1.ipynb__;!!DZ3fjg!-VVx5uQqQ6ZzOgr-EjFgoLc8lr9NMhNBQvahQLwOY5HAZ8lWfzbxhbpxn8e7OlM44QFoWvd5J20qD2flJpc$ ) .\n",
        "\n"
      ],
      "metadata": {
        "id": "a9VgzmClywsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write query statement (sql) as a string\n",
        "# NOTE: triple quotes allow us to break the string on multiple lines\n",
        "query = \"\"\"\n",
        "        SELECT mag_auto_g as gmag, mag_auto_r as rmag, mag_auto_z as zmag,\n",
        "               mag_auto_i as imag, mag_auto_y as ymag,\n",
        "               kron_radius, spread_model_g, class_star_g, spread_model_r, class_star_r,\n",
        "               spread_model_z, class_star_z,\n",
        "               snr_g, snr_r, snr_z, ra, dec\n",
        "        FROM des_dr1.main\n",
        "        WHERE (fluxerr_auto_g>0 and fluxerr_auto_r>0 and fluxerr_auto_z>0)\n",
        "        LIMIT 1000\"\"\"\n",
        "\n",
        "# mag_auto_g,r,i,z,y = AB magnitudes in DECam g,r,i,z,y bands\n",
        "# kron_radius        = Kron radius from SExtractor (pixels)\n",
        "# spread_model_g,r,z = star/galaxy classifier quantifying light profile relative to PSF\n",
        "# class_star_g,r,z   = star/extended source classifier (from 0 to 1)\n",
        "# snr_g,r,z          = computed signal-to-noise ratios (S/N) in g,r,z bands\n",
        "# ra,dec             = celestial coordinates\n",
        "#\n",
        "# WHERE: requirement that error>0 (to avoid dividing by zero) in g,r,z bands\n",
        "# LIMIT: returns 1,000 rows that satisfy the query"
      ],
      "metadata": {
        "id": "LPV1wIFPTAnt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the query synchronously, if short (e.g., LIMIT<=300,000)\n",
        "# We then convert the returned result, a CSV-formatted string, to a Pandas data frame,\n",
        "# making sure that any potential 'Infinity' values are converted to NaN.\n",
        "sample_res = qc.query(sql=query)\n",
        "sample_df = convert(sample_res,'pandas',na_values=('Infinity','-Infinity'))"
      ],
      "metadata": {
        "id": "3TRu_HdpTI2-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <span style=\"color:LightGreen\">Question 04</span>\n",
        "\n",
        "Write a query to get the following data from the `des_dr1.main` table:\n",
        "\n",
        "*  `mag_auto_g,r,i,z,y` = AB magnitudes in DECam g,r,i,z,y bands\n",
        "*  `kron_radius`        = Kron radius from SExtractor (pixels)\n",
        "* `spread_model_g,r,z` = star/galaxy classifier quantifying light profile relative to PSF\n",
        "* `class_star_g,r,z`   = star/extended source classifier (from 0 to 1)\n",
        "* `snr_g,r,z`          = computed signal-to-noise ratios (S/N) in g,r,z bands\n",
        "* `ra`,`dec`             = celestial coordinates\n",
        "\n",
        "Apply the following conditions and limit your query results to 100,000 samples:\n",
        "\n",
        "*   `fluxerr_auto_X` > 0 for X in g, r, and z bands\n",
        "*   -50 <= `snr_X` <= 50 for X in g, r, and z bands\n",
        "\n",
        "\n",
        "Convert the acquired data into a Pandas data frame.\n"
      ],
      "metadata": {
        "id": "LKvnPq_GzJaC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <span style=\"color:LightGreen\">Question 05</span>\n",
        "\n",
        "The images produced by DES are used to distinguish between stars (point sources), galaxies (resolved, if not too distant), and QSOs (which may have both point-like and resolved components).\n",
        "\n",
        "* `kron_radius`: Kron radius in pixels\n",
        "* `spread_model_X`: star-galaxy classifier comparing extended model to PSF model. Value is given for each band X = *g, r, i, z, y*\n",
        "* `class_star_X`: value ranging from 0.0 (not point-like) to 1.0 (point-like), for each band X = *g, r, i, z, y*\n",
        "\n",
        "The value of `spread_model_X` is near zero for a point source (star or QSO), positive for an extended source (galaxy), negative for an artifact smaller than the PSF (e.g., bad pixel or cosmic ray).\n",
        "\n",
        "Let's define an object as a star if `spread_model_g`<=0.5, and a galaxy if `spread_model_g` > 0.5. In our sample data, count the number of objects that are stars and the number of objects that are galaxies."
      ],
      "metadata": {
        "id": "AIOgqJLIVSUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <span style=\"color:LightGreen\">Question 06</span>\n",
        "\n",
        "Suppose we wish to divide the imaging data observed by the DES into roughly equal subsets of data for more efficient parallel data processing and analysis. We will do so by using K-Means clustering on the data points of the area of the night sky observed by DES.\n",
        "\n",
        "In astronomy, RA (right ascension) and Dec (declination) are the coordinates on the sky that correspond to longitude and latitude on Earth and are used to describe the position of an object. Define a subset of the data with two columns: `ra` and `dec`. Using K-Means clustering, fit the data into 2 distinct clusters.\n",
        "\n",
        "Here, each cluster will represent a subset of data, so we want the number data points of all clusters to be roughly the same. Display the fit using the helper function `display()`. Is the result what you expected? Is this a suitable method to equally divide our data?"
      ],
      "metadata": {
        "id": "zLMJBHtrWmMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display(data, fit):\n",
        "    n_clusters = len(np.unique(fit.labels_))\n",
        "    # Pick good colors to distinguish the different clusters.\n",
        "    import matplotlib.colors\n",
        "    cmap = matplotlib.colors.ListedColormap(\n",
        "        sns.color_palette(\"husl\", n_clusters).as_hex())\n",
        "    plt.scatter(data.iloc[:, 0], data.iloc[:, 1], s=5, c=fit.labels_, cmap=cmap)\n",
        "    # Use standard axes to match the plot above.\n",
        "#    plt.xlim(0, 360)\n",
        "    plt.ylim(-90, +90)\n",
        "    plt.xlabel('RA [degrees]')\n",
        "    plt.ylabel('Dec [degrees]')\n",
        "    plt.gca().set_aspect(1.)"
      ],
      "metadata": {
        "id": "d-jU374Bs8OX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <span style=\"color:LightGreen\">Question 07</span>\n",
        "\n",
        "Modify the `ra` column such that if `ra` >= 180 deg, we subtract 360 deg from `ra` for our observed sky map to be continuous. Now, change the number of clusters so that each cluster covers roughly equal area of the observed sky? For what `n_clusters` does the K-means clustering make the most sense to you?\n",
        "\n",
        "However, you shouldn't increase `n_clusters` to an arbitrarily large number just to get equally covered area of the observed sky - each cluster would represent a subset of data we use for parallel processing, and requiring more processors is not always feasible or sensible."
      ],
      "metadata": {
        "id": "2NwRUT6nWpoG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "* [1] Jupyter Notebook Example from Astro Data Lab using DES DR1: https://urldefense.com/v3/__https://github.com/astro-datalab/notebooks-latest/blob/master/03_ScienceExamples/StarGalQSOSeparation/StarGalQsoDESDR1.ipynb*5Cn__;JQ!!DZ3fjg!-VVx5uQqQ6ZzOgr-EjFgoLc8lr9NMhNBQvahQLwOY5HAZ8lWfzbxhbpxn8e7OlM44QFoWvd5J20q_O-vHkw$ ",
        "* [2] DES Collaboration \"The Dark Energy Survey Data Release 1\" ApJS 239, 18, 2018, https://urldefense.com/v3/__https://iopscience.iop.org/article/10.3847/1538-4365*5Cn__;JQ!!DZ3fjg!-VVx5uQqQ6ZzOgr-EjFgoLc8lr9NMhNBQvahQLwOY5HAZ8lWfzbxhbpxn8e7OlM44QFoWvd5J20qS6tGQi0$ ",
        "\n",
        "* Data Lab concept paper: Fitzpatrick et al., \"The NOAO Data Laboratory: a conceptual overview\", SPIE, 9149, 2014, https://urldefense.com/v3/__http://dx.doi.org/10.1117/12.2057445*5Cn__;JQ!!DZ3fjg!-VVx5uQqQ6ZzOgr-EjFgoLc8lr9NMhNBQvahQLwOY5HAZ8lWfzbxhbpxn8e7OlM44QFoWvd5J20qDwQMk2A$ ",
        "* Data Lab disclaimer: https://urldefense.com/v3/__https://datalab.noirlab.edu/disclaimers.php__;!!DZ3fjg!-VVx5uQqQ6ZzOgr-EjFgoLc8lr9NMhNBQvahQLwOY5HAZ8lWfzbxhbpxn8e7OlM44QFoWvd5J20q17NG-J4$ "
      ],
      "metadata": {
        "id": "jBUTSqcNN4ee"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Acknowledgements\n",
        "\n",
        "The initial version of this Jupyter Notebook was made by Ferzem Khan (University of Illinois) and Mark Neubauer (University of Illinois) for PHYS 503."
      ],
      "metadata": {
        "id": "BF8HKnQWwcTs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cMm0l1NMNj8v"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}