{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 08: Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helpers for Getting, Loading and Locating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wget_data(url: str):\n",
    "    local_path = './tmp_data'\n",
    "    p = subprocess.Popen([\"wget\", \"-nc\", \"-P\", local_path, url], stderr=subprocess.PIPE, encoding='UTF-8')\n",
    "    rc = None\n",
    "    while rc is None:\n",
    "      line = p.stderr.readline().strip('\\n')\n",
    "      if len(line) > 0:\n",
    "        print(line)\n",
    "      rc = p.poll()\n",
    "\n",
    "def locate_data(name, check_exists=True):\n",
    "    local_path='./tmp_data'\n",
    "    path = os.path.join(local_path, name)\n",
    "    if check_exists and not os.path.exists(path):\n",
    "        raise RuxntimeError('No such data file: {}'.format(path))\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Orange\">Problem 1</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default score function used by sklearn to evaluate how well a regression model predicts data is the [coefficient of determination](https://en.wikipedia.org/wiki/Coefficient_of_determination) $R^2$. Implement the function below to calculate $R^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-11235479a624a1eb",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def calculate_R2(y_data, y_pred):\n",
    "    \"\"\"Calculate the coefficient of determination R2 for two arrays.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_data : array\n",
    "        Array of data values, must have the same shape as y_pred.\n",
    "    y_pred : array\n",
    "        Array of predicted values, must have the same shape as y_data.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Calculated coefficient of determination R2.\n",
    "    \"\"\"\n",
    "    assert y_data.shape == y_pred.shape\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-98a3e782013f56f8",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# A correct solution should pass the tests below.\n",
    "gen = np.random.RandomState(seed=123)\n",
    "N = 100\n",
    "x = gen.uniform(size=N)\n",
    "y_pred = 2 * x - 1\n",
    "y_data = y_pred + gen.normal(scale=0.1, size=N)\n",
    "assert np.round(calculate_R2(y_data, y_pred), 3) == 0.961\n",
    "assert np.round(calculate_R2(y_data, -y_pred), 3) == -2.935\n",
    "assert np.round(calculate_R2(y_pred, y_pred), 3) == 1.000\n",
    "assert np.round(calculate_R2(y_pred, -y_pred), 3) == -3.000\n",
    "assert np.round(calculate_R2(y_data, np.full(N, np.mean(y_pred))), 3) == 0.000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Orange\">Problem 2</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the function below to perform a [grid-search cross validation](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) of a [random forest regression](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) over the following grid:\n",
    " - `min_samples_leaf` = 1, 10, 20\n",
    " - `n_estimators` = 5, 10, 15\n",
    " \n",
    "Hint: you will need to ensure reproducible \"random\" behavior in order to pass all the tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_summary(cv):\n",
    "    \"\"\"Summarize the results from a GridSearchCV fit.\n",
    "\n",
    "    Summarize a cross-validation grid search in a pandas DataFrame with the\n",
    "    following transformations of the full results:\n",
    "      - Remove all columns with timing measurements.\n",
    "      - Remove the 'param_' prefix from column names.\n",
    "      - Remove the '_score' suffix from column names.\n",
    "      - Round scores to 3 decimal places.\n",
    "\n",
    "     If the parameter grid is 1D, then this function also plots the test\n",
    "     and training R2 scores versus the parameter.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cv : sklearn.model_selection.GridSearchCV\n",
    "        Instance of a GridSearchCV object that has been fit to some data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Summary table of cross-validation results.\n",
    "    \"\"\"\n",
    "    # Look up the list of parameters used in the grid.\n",
    "    params = list(cv.cv_results_['params'][0].keys())\n",
    "    # Index results by the test score rank.\n",
    "    index = cv.cv_results_['rank_test_score']\n",
    "    df = pd.DataFrame(cv.cv_results_, index=index).drop(columns=['params', 'rank_test_score'])\n",
    "    # Remove columns that measure running time.\n",
    "    df = df.drop(columns=[n for n in df.columns.values if n.endswith('_time')])\n",
    "    # Remove param_ prefix from column names.\n",
    "    df = df.rename(lambda n: n[6:] if n.startswith('param_') else n, axis='columns')\n",
    "    # Remove _score suffix from column names.\n",
    "    df = df.rename(lambda n: n[:-6] if n.endswith('_score') else n, axis='columns')\n",
    "    if len(params) == 1:\n",
    "        # Plot the test and training scores vs the grid parameter when there is only one.\n",
    "        plt.plot(df[params[0]], df['mean_train'], 'o:', label='train')\n",
    "        plt.plot(df[params[0]], df['mean_test'], 'o-', label='test')\n",
    "        plt.legend(fontsize='x-large')\n",
    "        plt.xlabel('Hyperparameter value')\n",
    "        plt.ylabel('Score $R^2$')\n",
    "        plt.ylim(max(-2, np.min(df['mean_test'])), 1)\n",
    "    return df.sort_index().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-35b56d4c6f0830d5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def cross_validate(X, Y, gen):\n",
    "    \"\"\"Perform cross validation of a random forest regression.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array\n",
    "        Array with shape (N, DX) of N samples with DX features.\n",
    "    Y : array\n",
    "        Array with shape (N, DY) of N samples with DY features.\n",
    "    gen : np.random.RandomState\n",
    "        Random state to use for reproducible random numbers.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Cross-validation summary table produced by cv_summary().\n",
    "    \"\"\"\n",
    "    assert len(X) == len(Y)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wget_data('https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/data/spectra_data.hf5')\n",
    "wget_data('https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/data/spectra_targets.hf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3d5234f36e9bd587",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X = pd.read_hdf(locate_data('spectra_data.hf5')).values\n",
    "Y = pd.read_hdf(locate_data('spectra_targets.hf5')).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b1f9c4e7840ec102",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# A correct solution should pass the tests below.\n",
    "gen = np.random.RandomState(seed=123)\n",
    "cvs = cross_validate(X, Y, gen)\n",
    "assert np.all(cvs.columns.values == [\n",
    "    'min_samples_leaf', 'n_estimators', 'split0_test', 'split1_test', \n",
    "    'mean_test', 'std_test', 'split0_train', 'split1_train', 'mean_train', \n",
    "    'std_train'])\n",
    "assert np.all(cvs['min_samples_leaf'].values == [1, 1, 1, 10, 10, 10, 20, 20, 20])\n",
    "assert np.all(cvs['n_estimators'].values == [15, 10, 5, 15, 10, 5, 15, 10, 5])\n",
    "assert np.allclose(\n",
    "    cvs['mean_test'].values,\n",
    "    [0.961, 0.955, 0.942, 0.896, 0.891, 0.879, 0.496, 0.490, 0.480], atol=1e-3)\n",
    "assert np.allclose(\n",
    "    cvs['mean_train'].values,\n",
    "    [0.993, 0.992, 0.990, 0.909, 0.908, 0.905, 0.512, 0.515, 0.507], atol=1e-3)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
