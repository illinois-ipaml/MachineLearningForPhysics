{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "from sklearn import mixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using MCMC for our Bayesian model evaluations, so we include the MCMC helper functions we had before in our [MCMC notebook](https://illinois-ipaml.github.io/MachineLearningForPhysics/_sources/lectures/MCMC.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import inspect\n",
    "import emcee\n",
    "\n",
    "def wrap(func, **kwargs):\n",
    "    \"\"\"Prepare an arbitrary function to use with emcee sampling.\n",
    "\n",
    "    Emcee expects its parameters in a single list, but it is sometimes more\n",
    "    convenient to write a function in terms of named parameters and\n",
    "    hyperparameters. This method uses introspection to wrap an arbitrary\n",
    "    function with named parameters so that it has the signature expected\n",
    "    by emcee.\n",
    "\n",
    "    For example:\n",
    "\n",
    "        def f(x,y,a,b): ...\n",
    "        wrap(f, x=[1], y=[2], a=3, b=4, c=3, d=4)\n",
    "\n",
    "    returns a tuple (wrapped, ['x','y'], [1,2], {'c':3, 'd':4}) where:\n",
    "\n",
    "      - wrapped([p,q]) calls f(x=p,y=q,a=3,b=4)\n",
    "      - [1,2] are the initial values to use for parameters named ['x','y'].\n",
    "      - {'c':3, 'd':4} are the input kwargs with args of f() removed.\n",
    "\n",
    "    The square brackets identify floating arguments and specify their initial\n",
    "    value. An optional callable to evaluate a log-prior can also be passed,\n",
    "    for example:\n",
    "\n",
    "        wrap(f, x=[1,px], y=[2,py], a=3, b=4, c=3, d=4)\n",
    "\n",
    "    where px(x) and py(y) return the (un-normalized) log of the priors on\n",
    "    x and y to use during posterior sampling.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    func : callable\n",
    "        The function that should be prepared. It is assumed to have only\n",
    "        numerical arguments that accept any floating point values.\n",
    "    **kwargs : keyword arguments\n",
    "        All arguments of func must be included and assigned a value.\n",
    "        Arguments assigned a floating point value are considered fixed\n",
    "        during sampling.  Arguments assigned a floating point value\n",
    "        within a list, e.g., [1.2], will be sampled using the initial\n",
    "        value provided.  Sampled arguments can optionally also specify\n",
    "        a log-prior distribution using, e.g. [1.2, lnprior], where lnprior\n",
    "        is a function of the sampled argument that returns the log prior\n",
    "        probability density (which does not need to be normalized).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        Tuple (wrapped, names, values, kwargs). See example above for details.\n",
    "    \"\"\"\n",
    "    fixed = {}\n",
    "    names, values, lnpriors = [], [], []\n",
    "    funcsig = inspect.signature(func)\n",
    "    try:\n",
    "        funcargs = {name: kwargs[name] for name in funcsig.parameters}\n",
    "    except KeyError:\n",
    "        raise ValueError('Missing arguments.')\n",
    "    bound = funcsig.bind(**funcargs)\n",
    "    bound.apply_defaults()\n",
    "    NoPrior = lambda x: 0.\n",
    "    for name, value in bound.arguments.items():\n",
    "        if isinstance(value, list):\n",
    "            names.append(name)\n",
    "            values.append(value.pop(0))\n",
    "            lnpriors.append(value.pop(0) if value else NoPrior)\n",
    "            if value:\n",
    "                raise ValueError('Invalid syntax for argument {}.'.format(name))\n",
    "        else:\n",
    "            fixed[name] = value\n",
    "    partial = functools.partial(func, **fixed)\n",
    "    def wrapped(theta):\n",
    "        if len(theta) != len(names):\n",
    "            raise ValueError('expected list of {} values.'.format(len(names)))\n",
    "        result = 0.\n",
    "        for lnprior, value in zip(lnpriors, theta):\n",
    "            result += lnprior(value)\n",
    "            if not np.isfinite(result):\n",
    "                # theta is not allowed by this prior.\n",
    "                return -np.inf\n",
    "        args = dict(zip(names, theta))\n",
    "        result += partial(**args)\n",
    "        return result\n",
    "    # Remove function args from kwargs.\n",
    "    for name in funcargs:\n",
    "        kwargs.pop(name, None)\n",
    "    return wrapped, names, values, kwargs\n",
    "\n",
    "\n",
    "def sample(func, names, values, nwalkers=20, nsamples=1000, abs_rms=1e-4,\n",
    "           frac_rms=1e-3, burnin=100, random_state=None):\n",
    "    \"\"\"Generate MCMC samples of the un-normalized PDF func() using emcee.\n",
    "\n",
    "    Can be used standalone but intended to work with :func:`wrap`.\n",
    "\n",
    "    Initial values for each walker are Gaussian samples centered on the\n",
    "    input values with an RMS of max(abs_rms, frac_rms * values).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    func : callable\n",
    "        Evaluate the log PDF to sample. Passed a single list of parameter\n",
    "        values. Can be prepared using :func:`wrap`.\n",
    "    names : iterable\n",
    "        List of names for each floating parameter.  Used to label columns\n",
    "        in the returned DataFrame. Can be prepared using :func:`wrap`.\n",
    "    values : iterable\n",
    "        List of initial values for each floating parameter.  Used to center\n",
    "        random initial values for each walker. Can be prepared using\n",
    "        :func:`wrap`.\n",
    "    nwalkers : int\n",
    "        The number of emcee walkers to use.\n",
    "    nsamples : int\n",
    "        The total number of samples to return, after combining walkers\n",
    "        and trimming initial burnin.\n",
    "    abs_rms : float\n",
    "        Used to set walker initial values.  See above for details.\n",
    "    rel_rms : float\n",
    "        Used to set walker initial values.  See above for details.\n",
    "    burnin : int\n",
    "        The number of samples to remove from each walker's chain.\n",
    "    random_state : np.random.RandomState or None\n",
    "        The random state to use for reproducible chains.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Generated samples in a dataframe, using the inputs names for columns.\n",
    "    \"\"\"\n",
    "    if random_state is None:\n",
    "        random_state = np.random.RandomState()\n",
    "    # Generate sampler starting points.\n",
    "    ndim = len(names)\n",
    "    values = np.array(values, float)\n",
    "    initial = np.tile(values, (nwalkers, 1))\n",
    "    rms = np.maximum(abs_rms, frac_rms * values)\n",
    "    initial += rms * random_state.normal(size=(nwalkers, ndim))\n",
    "    # Initialize and run sampler.\n",
    "    sampler = emcee.EnsembleSampler(nwalkers, ndim, func)\n",
    "    n_per_chain = 1 + nsamples // nwalkers + burnin\n",
    "    sampler.run_mcmc(initial, n_per_chain, rstate0=random_state.get_state())\n",
    "    # Remove burnin and return results in a DataFrame.\n",
    "    chain = sampler.chain[:, burnin:].reshape(-1, ndim)[:nsamples]\n",
    "    return pd.DataFrame(chain, columns=names)\n",
    "\n",
    "\n",
    "def MCMC_sample(func, **kwargs):\n",
    "    \"\"\"Generate random samples from an un-normalized PDF.\n",
    "\n",
    "    See :func:`wrap` and :func:`sample` for details.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    func : callable\n",
    "        Function to evaluate log(f(...)) where f(...) is proportional\n",
    "        to the desired probability density.  Will be wrapped to\n",
    "        determine which arguments are sampled and which are fixed.\n",
    "    **kwargs : keyword arguments\n",
    "        Used to configure the wrapping of func and the sampler.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Generated samples in a dataframe, with one named column per\n",
    "        sampled argument of the input function.\n",
    "    \"\"\"\n",
    "    # Wrap the input function.\n",
    "    wrapped, names, values, kwargs = wrap(func, **kwargs)\n",
    "    # Generate emcee samples.\n",
    "    return sample(wrapped, names, values, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:Orange\">Bayesian Model Selection</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We [originally stated](Bayes.ipynb) Bayes' learning rule as:\n",
    "\n",
    "$$ \\Large\n",
    "P(\\Theta_M\\mid D, M) = \\frac{P(D\\mid \\Theta_M, M)\\,P(\\Theta_M\\mid M)}{P(D\\mid M)}\n",
    "$$\n",
    "\n",
    "in terms of the:\n",
    " 1. ___<span style=\"color:Violet\">Posterior</span>___: $P(\\Theta_M\\mid D, M)$ is the probability of the parameter values $\\Theta_M$ given the data and the choice of hyperparameters.\n",
    "\n",
    " 2.  ___<span style=\"color:Violet\">Likelihood</span>:___ $P(D\\mid \\Theta_M, M)$ is the probability of the data given the model.\n",
    "\n",
    " 3.  ___<span style=\"color:Violet\">Prior</span>:___ $P(\\Theta_M\\mid M)$ is the probability of the model parameters given the hyperparameters and *marginalized over all possible data*.\n",
    "\n",
    " 4.  ___<span style=\"color:Violet\">Evidence</span>___: $P(D\\mid M)$ is the probability of the data given the hyperparameters and *marginalized over all possible parameter values given the hyperparameters*.\n",
    "\n",
    "We often omit the model $M$ in our notation when we are only considering a single model. However, unless there is only one possible model, then we still have to solve a meta-inference problem of comparing possible models. Although this step is often referred to as \"<span style=\"color:Violet\">model selection</span>\", it is better to think of it as  ___<span style=\"color:Violet\">model comparison</span>___, since it can only assign relative probabilities to different models.\n",
    "\n",
    "Recalling <span style=\"color:Violet\">Bayes' Rule</span> (see [Probability](https://nbviewer.jupyter.org/github/illinois-mla/syllabus/blob/master/notebooks/Probability.ipynb)), The posterior probability of a model $M$ given the observed data $D$ is:\n",
    "\n",
    "$$ \\Large\n",
    "P(M\\mid D) = \\frac{P(D\\mid M)\\,P(M)}{P(D)} \\; ,\n",
    "$$\n",
    "\n",
    "where the \"evidence\" given $M$, $P(D\\mid M)$, is now in the numerator, and the denominator is now a \"<span style=\"color:Violet\">super evidence</span>\":\n",
    "\n",
    "$$ \\Large\n",
    "P(D) = \\int dM\\, P(D\\mid M)\\,P(M) \\; .\n",
    "$$\n",
    "\n",
    "In case of a countable (perhaps infinite) set of possible models, the integral becomes a sum,\n",
    "\n",
    "$$ \\Large\n",
    "P(D) = \\sum_k \\, P(D\\mid M_k)\\, P(M_k) \\; ,\n",
    "$$\n",
    "\n",
    "and each \"model likelihood\" $P(D\\mid M_k)$ is a probability in the range $[0,1]$. We have also introduced a prior $P(M)$ on the model itself, marginalized over its parameter space:\n",
    "\n",
    "$$ \\Large\n",
    "P(M) = \\int d\\Theta_M\\, P(\\Theta_M, M) \\; .\n",
    "$$\n",
    "\n",
    "Note the similarity between this \"Bayes' rule for models\" and the original Bayes' rule.\n",
    "\n",
    "We can now anticipate two problems for practical model comparisons:\n",
    " - We were able to perform inference for a given model without ever calculating its evidence $P(D\\mid M)$, but that is no longer possible for model comparison.\n",
    "\n",
    " - To calculate the \"super evidence\" we must be able to specify *all possible models*.\n",
    " \n",
    "However, we can sidestep the second problem if we only want to compare two possible models, $M_1$ and $M_2$, without specifying (or perhaps even knowing) the set of possible models. We use the  ___<span style=\"color:Violet\">odds ratio</span> for this comparison,\n",
    "\n",
    "$$ \\Large\n",
    "\\boxed{\n",
    "\\text{odds ratio =}\\quad\n",
    "\\frac{P(M_1\\mid D)}{P(M_2\\mid D)} = \\frac{P(D\\mid M_1)\\, P(M_1)}{P(D\\mid M_2)\\,P(M_2)} \\; ,\n",
    "}\n",
    "$$\n",
    "\n",
    "where, conveniently, the \"super evidence\" $P(D)$ cancels in the ratio. The ratio of \"model likelihoods\" appearing on the right-hand side is known as the **Bayes factor**:\n",
    "\n",
    "$$ \\Large\n",
    "\\boxed{\n",
    "\\text{Bayes factor =}\\quad\n",
    "\\frac{P(D\\mid M_1)}{P(D\\mid M_2)} \\; .\n",
    "}\n",
    "$$\n",
    "\n",
    "It is easy to lose sight of the big picture with all of this probability calculus, so let's zoom out to a simple example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/img/ModelSelection-OccamFactor.jpg\" width=800 align=left></img><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "___<span style=\"color:Violet\">DISCUSS</span>___ Study the observed image $D$ above with two models in mind:\n",
    " - $M_1$: The image shows a single piece of paper.\n",
    "\n",
    " - $M_2$: The image shows two pieces of paper.\n",
    "\n",
    "Are both models possible? Give some arguments for why $M_2$ is unlikely. Are your arguments based on prior knowledge?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "Both models are certainly possible since the ruler could be hiding the fact that these are two pieces of paper side by side.\n",
    "\n",
    "However, $M_2$ is unlikely because:\n",
    " - This looks like a standard (US) sheet of paper, as supported its dimensions according to the ruler.\n",
    "\n",
    " - It would be a remarkable coincidence for two sheets of paper to be perfectly lined up like this.\n",
    " \n",
    "The first argument is based on our prior knowledge, such as:\n",
    " - Standard (US) paper has the proportions 8.5 to 11.\n",
    "\n",
    " - Most (US) rulers are in inches.\n",
    " \n",
    "Therefore, this type of argument shows up in the ratio of model priors, $P(M_1) / P(M_2)$ in the odds ratio above.\n",
    " \n",
    "However, the second argument is a statement about probabilities that does not rely on any prior knowledge. Instead, it shows up in the Bayes factor above. To see how this happens, we need to define the parameters for each model. For each piece of paper, use four parameters:\n",
    " - $(x,y)$ of the top-left corner, which could be anywhere in the image.\n",
    "\n",
    " - width $w$ and height $h$ of the paper, which range over the full image width and height.\n",
    " \n",
    "The likelihoods of $M_1$ and $M_2$ are then integrals over four and eight parameters, respectively:\n",
    "\n",
    "$$ \\Large\n",
    "P(D\\mid M_i) = \\int d\\Theta_i\\, P(D, \\Theta_i\\mid M_i) \\; .\n",
    "$$\n",
    "\n",
    "For $M_2$, the likelihood of the observed image $D$ will be zero except when the parameters of the second piece of paper have it line up perfectly under the ruler. Since this represents a small fraction of the full range of $M_2$ parameters, $P(D\\mid M_2)$ is heavily penalized compared with $P(D\\mid M_1)$, leading to a large Bayes factor.\n",
    "\n",
    "This is an example of [Occam's razor](https://en.wikipedia.org/wiki/Occam's_razor) in action: Bayesian inference prefers the simplest explanation (model), independently of any prior knowledge.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study: How Many Peaks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate some random samples of a single feature $x$ drawn from a mixture of two Gaussians:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mix(n_total, frac1, mu1, mu2, sigma1, sigma2, seed=123, plot_range=(-1.5, 1.5)):\n",
    "    gen = np.random.RandomState(seed=seed)\n",
    "    # Assign each sample to one of the peaks.\n",
    "    idx = scipy.stats.bernoulli.rvs(1 - frac1, size=n_total, random_state=gen)\n",
    "    # Set the Gaussian parameters for each sample.\n",
    "    mu = np.array([mu1, mu2])[idx]\n",
    "    sigma = np.array([sigma1, sigma2])[idx]\n",
    "    # Generate each sample.\n",
    "    X = scipy.stats.norm.rvs(mu, sigma, random_state=gen)\n",
    "    # Optional plot.\n",
    "    if plot_range:\n",
    "        bins = np.linspace(*plot_range, 30)\n",
    "        plt.hist(X, bins, histtype='stepfilled', alpha=0.5, density=True)\n",
    "        plt.hist(X, bins, histtype='step', color='k', lw=1, density=True)\n",
    "        grid = np.linspace(*plot_range, 201)\n",
    "        if frac1 > 0:\n",
    "            pdf1 = scipy.stats.norm.pdf(grid, mu1, sigma1)\n",
    "            plt.plot(grid, frac1 * pdf1, lw=2)\n",
    "        if frac1 < 1:\n",
    "            pdf2 = scipy.stats.norm.pdf(grid, mu2, sigma2)\n",
    "            plt.plot(grid, (1 - frac1) * pdf2, lw=2)\n",
    "        plt.show()\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gen = 200\n",
    "Da = generate_mix(n_gen, 1.0, 0.0, np.nan, 0.5, np.nan) # nan values are never used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Db = generate_mix(n_gen, 0.5, -0.3, 0.3, 0.1, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dc = generate_mix(n_gen, 0.5, -0.3, 0.3, 0.4, 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that each sample has an integer number of entries drawn from each Gaussian, so the true `frac1` is only realized on average.\n",
    "\n",
    "We will compare two models to explain this data:\n",
    " - M1: A single Gaussian with unknown mean $\\mu$ and sigma $\\sigma$.\n",
    "\n",
    " - M2: Two Gaussians with equal proportions (`frac1=0.5`), means with a fixed separation $\\mu_2 - \\mu_1 = 0.6$, and unknown sigmas $\\sigma_1$, $\\sigma_2$.\n",
    " \n",
    "Note that `Da` is drawn from M1 and `Db`, `Dc` are drawn from M2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "**DISCUSS:** For each of these three datasets, predict whether the Bayes' factor for M1 relative to M2 will be:\n",
    " - Much larger than 1, i.e., strongly favoring M1.\n",
    "\n",
    " - About 1, i.e. unable to discriminate between M1 and M2 based on the data alone.\n",
    "\n",
    " - Much smaller than 1, i.e., strongly favoring M2.\n",
    " \n",
    "Explain your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "`Da` should strongly favor M1 since the fixed separation of the M2 means makes it very unlikely to have been generated by M2.\n",
    "\n",
    "`Db` should very strongly favor M2, since no reasonable statistical fluctuation of M1 would ever reproduce it.\n",
    "\n",
    "`Dc` should be unable to discriminate between M1 and M2 since, although it was produced by M2, M1 might produce data like this with the right statistical fluctuations.\n",
    "\n",
    "[Jeffreys proposed a scale](https://en.wikipedia.org/wiki/Bayes_factor#Interpretation) for thresholds in the Bayes' factor:\n",
    " - larger than 100 is \"decisive evidence\" in favor of M1.\n",
    "\n",
    " - larger than 10 is \"strong evidence\" in favor of M1.\n",
    "\n",
    " - smaller than 0.1 is \"strong evidence\" in favor of M2.\n",
    "\n",
    " - smaller than 0.01 is \"decisive evidence\" in favor of M2.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare models for given data $D$, we perform the following steps for each candidate model $M$:\n",
    " - Perform a Bayesian inference with HMC assuming $M$ to obtain samples of $(\\mu, \\sigma)$ drawn from the posterior $P(\\theta\\mid D, M)$.\n",
    "\n",
    " - Construct a density estimate of the posterior using the generated samples.\n",
    "\n",
    " - Estimate the evidence $P(D\\mid M)$ for $D$ given $M$ using the density estimate.\n",
    "\n",
    "Once we have estimated the evidence for each model, we can calculate the Bayes' factor for any pair of models.\n",
    "\n",
    "The final step is to assign relative prior probabilities for each model in order to calculate the odds ratios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following parameter ranges are enforced by setting the prior probability to zero outside these ranges:\n",
    " - M1: $|\\mu| \\le 1$ and $0.05 \\le \\sigma \\le 1.0$.\n",
    "\n",
    " - M2: $|\\mu| \\le 1$ and $0.05 \\le \\sigma_i \\le 1.0$, with $\\mu \\equiv (\\mu_1 + \\mu_2) / 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_range = (-1., +1.)\n",
    "sigma_range = (0.05, 1.0)\n",
    "t_range = np.log(sigma_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below to calculate the evidence assuming M1 is quite involved, and brings together several topics we have met already:\n",
    " - Bayesian inference.\n",
    "\n",
    " - Tensorflow and scipy.stats frameworks.\n",
    "\n",
    " - Hamiltonian Markov-chain Monte Carlo.\n",
    "\n",
    " - Density estimation.\n",
    "\n",
    " - Evidence estimation with MCMC samples.\n",
    " \n",
    "Do not worry about the details, at least until you need to perform a similar calculation yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build this calculation, first define the log-posterior PDFs of both models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M1_logpost(D, mu, t):\n",
    "    # Perform change of variables.\n",
    "    sigma = np.exp(t)\n",
    "    # Apply priors on (mu, sigma)\n",
    "    if np.abs(mu) > 1: return -np.inf\n",
    "    if sigma < 0.05 or sigma > 1.0: return -np.inf\n",
    "    # Calculate and return the log-likelihood.\n",
    "    return scipy.stats.norm.logpdf(D, mu, sigma).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def M2_logpost(D, mu, t1, t2):\n",
    "    # Perform change of variables.\n",
    "    mu1 = mu - 0.3\n",
    "    mu2 = mu + 0.3\n",
    "    sigma1 = np.exp(t1)\n",
    "    sigma2 = np.exp(t2)\n",
    "    # Apply priors on (mu, t1, t2)\n",
    "    if np.abs(mu) > 1: return -np.inf\n",
    "    if sigma1 < 0.05 or sigma1 > 1.0: return -np.inf    \n",
    "    if sigma2 < 0.05 or sigma2 > 1.0: return -np.inf    \n",
    "    # Calculate and return the log-likelihood.\n",
    "    return np.log(0.5 * (\n",
    "       scipy.stats.norm.pdf(D, mu1, sigma1) +\n",
    "       scipy.stats.norm.pdf(D, mu2, sigma2))).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to estimate the evidence for the observed data D assuming model M1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_M1_evidence(D, n_mc=2000, n_grid=50, seed=123):\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Pick intial point for MCMC chains based on the data.\n",
    "    # --------------------------------------------------------------------------\n",
    "    lo, med, hi = np.percentile(D, (16, 50, 84))\n",
    "    mu_init = np.float32(med)\n",
    "    t_init = np.float32(np.log(0.5 * (hi - lo)))\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Use MCMC to generate samples from the M1 posterior.\n",
    "    # --------------------------------------------------------------------------\n",
    "    gen = np.random.RandomState(seed)\n",
    "    samples = MCMC_sample(M1_logpost, D=D,\n",
    "                          mu=[mu_init], t=[t_init],\n",
    "                          nsamples=n_mc, random_state=gen)\n",
    "    # Replace t=log(sigma) with sigma.\n",
    "    samples['sigma'] = np.exp(samples['t'])\n",
    "    samples.drop(columns='t', inplace=True)\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Build a parameter grid for estimating the evidence.\n",
    "    # --------------------------------------------------------------------------\n",
    "    mu_grid = np.linspace(*np.percentile(samples['mu'], (0.5, 99.5)), n_grid)\n",
    "    sigma_grid = np.linspace(*np.percentile(samples['sigma'], (0.5, 99.5)), n_grid)\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Evaluate the posterior numerator P(D|mu,sigma) P(mu,sigma) on the grid.\n",
    "    # --------------------------------------------------------------------------\n",
    "    sigma_ = sigma_grid.reshape(-1, 1)\n",
    "    D_ = D.reshape(-1, 1, 1)\n",
    "    log_numerator_grid = scipy.stats.norm.logpdf(D_, mu_grid, sigma_).sum(axis=0)\n",
    "    log_numerator_grid -= np.log(sigma_)\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Estimate the posterior density from the generated samples with a GMM.\n",
    "    # --------------------------------------------------------------------------\n",
    "    fit = mixture.GaussianMixture(n_components=1).fit(samples.values)\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Evaluate the density on the grid.\n",
    "    # --------------------------------------------------------------------------\n",
    "    log_density_grid = np.empty((n_grid, n_grid))\n",
    "    for i1, mu_value in enumerate(mu_grid):\n",
    "        for i2, sigma_value in enumerate(sigma_grid):\n",
    "            log_density_grid[i2, i1] = fit.score_samples([[mu_value, sigma_value]])[0]\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Use the the 25% of grid points with the largest numerator for the evidence estimate.\n",
    "    # --------------------------------------------------------------------------\n",
    "    log_numerator_cut = np.percentile(log_numerator_grid, 75)\n",
    "    use = log_numerator_grid > log_numerator_cut\n",
    "    log_evidence = np.median((log_numerator_grid - log_density_grid)[use])\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Summarize the results with a plot\n",
    "    # --------------------------------------------------------------------------\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    ax[0].scatter(samples['mu'], samples['sigma'], s=5, lw=0, c='k')\n",
    "    ax[0].contour(mu_grid, sigma_grid, np.max(log_numerator_grid) - log_numerator_grid,\n",
    "                  levels=[1, 2, 4, 8], colors='k', linewidths=2, linestyles='-')\n",
    "    ax[0].contour(mu_grid, sigma_grid, np.max(log_density_grid) - log_density_grid,\n",
    "                  levels=[1, 2, 4, 8], colors='r', linewidths=2, linestyles='--')\n",
    "    ax[0].set_xlim(mu_grid[0], mu_grid[-1])\n",
    "    ax[0].set_ylim(sigma_grid[0], sigma_grid[-1])\n",
    "    ax[0].set_xlabel('$\\\\mu$')\n",
    "    ax[0].set_ylabel('$\\\\sigma$')\n",
    "    ax[1].scatter(log_numerator_grid.flatten(),\n",
    "                  (log_numerator_grid - log_density_grid).flatten(),\n",
    "                  s=5, lw=0, c='r')\n",
    "    ax[1].scatter(log_numerator_grid[use].flatten(),\n",
    "                  (log_numerator_grid - log_density_grid)[use].flatten(),\n",
    "                  s=5, lw=0, c='g')\n",
    "    ax[1].axhline(log_evidence, c='g')\n",
    "    ax[1].set_xlabel('$\\\\log P(D\\\\mid \\\\mu,\\\\sigma, M_1) + \\\\log P(\\\\mu,\\\\sigma\\\\mid M_1)$')\n",
    "    ax[1].set_ylabel('$\\\\log P(D\\\\mid M_1)$')\n",
    "    plt.subplots_adjust(wspace=0.25)\n",
    "    return log_evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_Da_M1 = calculate_M1_evidence(Da)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the left-hand plot above, the solid black contours show the shape of the un-normalized posterior and the dashed red contours show the GMM density model fit to the MCMC samples. These do not need to agree exactly, but better agreement will lead to a more accurate estimate of the evidence $P(Da\\mid M1)$.  In this example, we are using a GMM with a single component but the posterior is slightly non-Gaussian, so we could try increasing the number of MCMC samples and adding another GMM component.\n",
    "\n",
    "The right-hand plot shows many independent estimates of the evidence, calculated as the ratio of the un-normalized posterior (solid black contours) and GMM density model (dashed red contours) on a uniform 2D grid of $(\\mu, \\sigma)$ points.  To combine these independent estimates, we take the median of the green values, where the posterior probability is largest (so this procedure should be more accurate). Review the [MCMC notebook](https://illinois-ipaml.github.io/MachineLearningForPhysics/_sources/lectures/MCMC.html) for a simpler 1D example of evidence estimation with the same approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_Db_M1 = calculate_M1_evidence(Db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_Dc_M1 = calculate_M1_evidence(Dc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculation of the evidence for D assuming model M2 is very similar, but now in the 3D parameter space (mu, t1, t2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_M2_evidence(D, n_mc=5000, n_grid=25, seed=123):\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Pick starting point for MCMC chains based on the data.\n",
    "    # --------------------------------------------------------------------------\n",
    "    lo, med, hi = np.percentile(D, (16, 50, 84))\n",
    "    mu_init = np.float32(med)\n",
    "    t_init = np.float32(np.log(0.3 * (hi - lo)))\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Use MCMC to generate samples from the M1 posterior.\n",
    "    # --------------------------------------------------------------------------\n",
    "    gen = np.random.RandomState(seed)\n",
    "    samples = MCMC_sample(M2_logpost, D=D,\n",
    "                          mu=[mu_init], t1=[t_init], t2=[t_init],\n",
    "                          nsamples=n_mc, random_state=gen)\n",
    "    # Replace ti=log(sigmai) with sigmai.\n",
    "    samples['sigma1'] = np.exp(samples['t1'])\n",
    "    samples['sigma2'] = np.exp(samples['t2'])\n",
    "    samples.drop(columns='t1', inplace=True)\n",
    "    samples.drop(columns='t2', inplace=True)\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Build a parameter grid for estimating the evidence.\n",
    "    # --------------------------------------------------------------------------\n",
    "    mu_grid = np.linspace(*np.percentile(samples['mu'], (0.5, 99.5)), n_grid)\n",
    "    sigma1_grid = np.linspace(*np.percentile(samples['sigma1'], (0.5, 99.5)), n_grid)\n",
    "    sigma2_grid = np.linspace(*np.percentile(samples['sigma2'], (0.5, 99.5)), n_grid)\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Evaluate the posterior numerator P(D|mu,sigma1,sigma2) P(mu,sigma1,sigma2) on the grid.\n",
    "    # --------------------------------------------------------------------------\n",
    "    mu1_, mu2_ = mu_grid - 0.3, mu_grid + 0.3\n",
    "    sigma1_ = sigma1_grid.reshape(-1, 1)\n",
    "    sigma2_ = sigma2_grid.reshape(-1, 1, 1)\n",
    "    D_ = D.reshape(-1, 1, 1, 1)\n",
    "    log_numerator_grid = np.log(0.5 * (\n",
    "        scipy.stats.norm.pdf(D_, mu1_, sigma1_) +\n",
    "        scipy.stats.norm.pdf(D_, mu2_, sigma2_))).sum(axis=0)\n",
    "    log_numerator_grid -= np.log(sigma1_) + np.log(sigma2_)\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Calculate projections onto each pair of parameters with numerical 1D integration.\n",
    "    # --------------------------------------------------------------------------\n",
    "    numerator_grid = np.exp(log_numerator_grid)\n",
    "    proj_mu_sigma1 = np.log(np.trapz(numerator_grid, sigma2_grid, axis=0))\n",
    "    proj_mu_sigma2 = np.log(np.trapz(numerator_grid, sigma1_grid, axis=1))\n",
    "    proj_sigma1_sigma2 = np.log(np.trapz(numerator_grid, mu_grid, axis=2))\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Estimate the posterior density from the generated samples with a GMM.\n",
    "    # --------------------------------------------------------------------------\n",
    "    fit = mixture.GaussianMixture(n_components=3).fit(samples.values)\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Evaluate the density on the grid.\n",
    "    # --------------------------------------------------------------------------\n",
    "    log_density_grid = np.empty((n_grid, n_grid, n_grid))\n",
    "    for i1, mu_value in enumerate(mu_grid):\n",
    "        for i2, sigma1_value in enumerate(sigma1_grid):\n",
    "            for i3, sigma2_value in enumerate(sigma2_grid):\n",
    "                log_density_grid[i3, i2, i1] = fit.score_samples(\n",
    "                    [[mu_value, sigma1_value, sigma2_value]])[0]\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Calculate projections onto each pair of parameters with numerical 1D integration.\n",
    "    # --------------------------------------------------------------------------\n",
    "    density_grid = np.exp(log_density_grid)\n",
    "    dproj_mu_sigma1 = np.log(np.trapz(density_grid, sigma2_grid, axis=0))\n",
    "    dproj_mu_sigma2 = np.log(np.trapz(density_grid, sigma1_grid, axis=1))\n",
    "    dproj_sigma1_sigma2 = np.log(np.trapz(density_grid, mu_grid, axis=2))\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Use the the 5% of grid points with the largest numerator for the evidence estimate.\n",
    "    # --------------------------------------------------------------------------\n",
    "    log_numerator_cut = np.percentile(log_numerator_grid, 95)\n",
    "    use = log_numerator_grid > log_numerator_cut\n",
    "    log_evidence = np.median((log_numerator_grid - log_density_grid)[use])\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Summarize the results with a plot\n",
    "    # --------------------------------------------------------------------------\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    ax = ax.flatten()\n",
    "    ax[0].scatter(samples['mu'], samples['sigma1'], s=3, lw=0, c='k')\n",
    "    ax[0].contour(mu_grid, sigma1_grid, np.max(proj_mu_sigma1) - proj_mu_sigma1,\n",
    "                  levels=[1, 2, 4, 8], colors='k', linewidths=2, linestyles='-')\n",
    "    ax[0].contour(mu_grid, sigma1_grid, np.max(dproj_mu_sigma1) - dproj_mu_sigma1,\n",
    "                  levels=[1, 2, 4, 8], colors='r', linewidths=2, linestyles='--')\n",
    "    ax[0].set_xlim(mu_grid[0], mu_grid[-1])\n",
    "    ax[0].set_ylim(sigma1_grid[0], sigma1_grid[-1])\n",
    "    ax[0].set_xlabel('$\\\\mu$')\n",
    "    ax[0].set_ylabel('$\\\\sigma_1$')\n",
    "    ax[2].scatter(samples['mu'], samples['sigma2'], s=3, lw=0, c='k')\n",
    "    ax[2].contour(mu_grid, sigma2_grid, np.max(proj_mu_sigma2) - proj_mu_sigma2,\n",
    "                  levels=[1, 2, 4, 8], colors='k', linewidths=2, linestyles='-')\n",
    "    ax[2].contour(mu_grid, sigma2_grid, np.max(dproj_mu_sigma2) - dproj_mu_sigma2,\n",
    "                  levels=[1, 2, 4, 8], colors='r', linewidths=2, linestyles='--')\n",
    "    ax[2].set_xlim(mu_grid[0], mu_grid[-1])\n",
    "    ax[2].set_ylim(sigma2_grid[0], sigma2_grid[-1])\n",
    "    ax[2].set_xlabel('$\\\\mu$')\n",
    "    ax[2].set_ylabel('$\\\\sigma_2$')\n",
    "    ax[3].scatter(samples['sigma1'], samples['sigma2'], s=3, lw=0, c='k')\n",
    "    ax[3].contour(sigma1_grid, sigma2_grid, np.max(proj_sigma1_sigma2) - proj_sigma1_sigma2,\n",
    "                  levels=[1, 2, 4, 8], colors='k', linewidths=2, linestyles='-')\n",
    "    ax[3].contour(sigma1_grid, sigma2_grid, np.max(dproj_sigma1_sigma2) - dproj_sigma1_sigma2,\n",
    "                  levels=[1, 2, 4, 8], colors='r', linewidths=2, linestyles='--')\n",
    "    ax[3].set_xlim(sigma1_grid[0], sigma1_grid[-1])\n",
    "    ax[3].set_ylim(sigma2_grid[0], sigma2_grid[-1])\n",
    "    ax[3].set_xlabel('$\\\\sigma_1$')\n",
    "    ax[3].set_ylabel('$\\\\sigma_2$')\n",
    "    ax[1].scatter(log_numerator_grid.flatten(),\n",
    "                  (log_numerator_grid - log_density_grid).flatten(),\n",
    "                  s=5, lw=0, c='r')\n",
    "    ax[1].scatter(log_numerator_grid[use].flatten(),\n",
    "                  (log_numerator_grid - log_density_grid)[use].flatten(),\n",
    "                  s=5, lw=0, c='g')\n",
    "    ax[1].axhline(log_evidence, c='g')\n",
    "    ax[1].set_xlabel('$\\\\log P(D\\\\mid \\\\mu,\\\\sigma_1,\\\\sigma_2, M_2) + \\\\log P(\\\\mu,\\\\sigma_1,\\\\sigma_2\\\\mid M_2)$')\n",
    "    ax[1].set_ylabel('$\\\\log P(D\\\\mid M_2)$')\n",
    "    plt.subplots_adjust(wspace=0.22)\n",
    "    \n",
    "    return log_evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "E_Da_M2 = calculate_M2_evidence(Da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_Db_M2 = calculate_M2_evidence(Db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_Dc_M2 = calculate_M2_evidence(Dc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these involved calculations provides a single number, the estimated log of the evidence for $D$ given $M$,\n",
    "\n",
    "$$ \\Large\n",
    "\\log P(D\\mid M)\n",
    "$$\n",
    "\n",
    "Note these are tiny numbers ($e^{-100} \\simeq 10^{-44}$), but it their difference that matters:\n",
    "\n",
    "$$ \\Large\n",
    "\\boxed{\n",
    "\\text{Bayes' factor} = \\exp\\left[ \\log P(D\\mid M_1) - \\log P(D\\mid M_2)\\right] \\;\n",
    "}\n",
    "$$\n",
    "\n",
    "Finally, we apply our subjective prior weights for relative likelihood of M1 and M2 in the absence of any data to obtain the M1:M2 odds ratio:\n",
    "\n",
    "$$ \\Large\n",
    "\\boxed{\n",
    "\\frac{P(M_1\\mid D)}{P(M_2\\mid D)} = (\\text{Bayes' factor}) \\times \\frac{P(M_1)}{P(M_2)} \\;\n",
    "}\n",
    "$$\n",
    "\n",
    "If we assume that M1 and M2 have equal a-priori weights, then the odds ratio equals the Bayes' factor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(M1_prior=0.5, M2_prior=0.5):\n",
    "    results = pd.DataFrame({\n",
    "        'logM1': [E_Da_M1, E_Db_M1, E_Dc_M1],\n",
    "        'logM2': [E_Da_M2, E_Db_M2, E_Dc_M2]},\n",
    "        index=('Da', 'Db', 'Dc'))\n",
    "    results['log10(Bayes)'] = (results['logM1'] - results['logM2']) / np.log(10.)\n",
    "    results['log10(Odds)'] = results['log10(Bayes)'] + np.log10(M1_prior / M2_prior)\n",
    "    return results.round(1)\n",
    "    \n",
    "summarize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize in words:\n",
    " - M1 is \"strongly\" (but not \"decisively\") supported by `Da`.\n",
    "\n",
    " - M2 is \"decisively\" supported by `Db`\n",
    "\n",
    " - M2 is mildy supported by `Dc`, but the evidence is not \"strong\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a prior bias that M1 is 10x more likely than M1, this would mostly affect our assessment for `Dc`, which now slightly prefers M1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(M1_prior=10, M2_prior=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
